[
    {
        "repo": "keras-team/keras",
        "pr_number": 18160,
        "body": "I think it is better use `prefetch()` after batching. In a pipeline we would want the next batch ready (t+1) while processing current batch (t).",
        "changed_files": [
            {
                "filename": "keras/utils/image_dataset.py",
                "patch": "@@ -269,8 +269,6 @@ def image_dataset_from_directory(\n             interpolation=interpolation,\n             crop_to_aspect_ratio=crop_to_aspect_ratio,\n         )\n-        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n-        val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n \n         if batch_size is not None:\n             if shuffle:\n@@ -286,6 +284,9 @@ def image_dataset_from_directory(\n                     buffer_size=1024, seed=seed\n                 )\n \n+        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n+        val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n+\n         # Users may need to reference `class_names`.\n         train_dataset.class_names = class_names\n         val_dataset.class_names = class_names\n@@ -314,7 +315,7 @@ def image_dataset_from_directory(\n             interpolation=interpolation,\n             crop_to_aspect_ratio=crop_to_aspect_ratio,\n         )\n-        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n+\n         if batch_size is not None:\n             if shuffle:\n                 # Shuffle locally at each iteration\n@@ -324,6 +325,8 @@ def image_dataset_from_directory(\n             if shuffle:\n                 dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n \n+        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n+\n         # Users may need to reference `class_names`.\n         dataset.class_names = class_names\n "
            }
        ],
        "diff": "diff --git a/keras/utils/image_dataset.py b/keras/utils/image_dataset.py\nindex 26a64f2338a..4ffd7170782 100644\n--- a/keras/utils/image_dataset.py\n+++ b/keras/utils/image_dataset.py\n@@ -269,8 +269,6 @@ def image_dataset_from_directory(\n             interpolation=interpolation,\n             crop_to_aspect_ratio=crop_to_aspect_ratio,\n         )\n-        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n-        val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n \n         if batch_size is not None:\n             if shuffle:\n@@ -286,6 +284,9 @@ def image_dataset_from_directory(\n                     buffer_size=1024, seed=seed\n                 )\n \n+        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n+        val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n+\n         # Users may need to reference `class_names`.\n         train_dataset.class_names = class_names\n         val_dataset.class_names = class_names\n@@ -314,7 +315,7 @@ def image_dataset_from_directory(\n             interpolation=interpolation,\n             crop_to_aspect_ratio=crop_to_aspect_ratio,\n         )\n-        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n+\n         if batch_size is not None:\n             if shuffle:\n                 # Shuffle locally at each iteration\n@@ -324,6 +325,8 @@ def image_dataset_from_directory(\n             if shuffle:\n                 dataset = dataset.shuffle(buffer_size=1024, seed=seed)\n \n+        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n+\n         # Users may need to reference `class_names`.\n         dataset.class_names = class_names\n \n",
        "reviews": [
            {
                "reviewer": "qlzh727",
                "state": "APPROVED",
                "body": "No comment"
            }
        ],
        "comments": [
            {
                "commenter": "qlzh727",
                "body": "Adding @jsimsa for the performance best practice here. \r\n\r\nFrom https://www.tensorflow.org/guide/data_performance#prefetching, I didn't see any suggestion about whether the prefetch should be applied before batching or not.\r\n\r\nThe current approach will prefetch unbatched data (with autotune), unless the prefetched data can't fill the next batch, then I don't see any big difference here."
            },
            {
                "commenter": "Frightera",
                "body": "@qlzh727 \r\n\r\nQuoting from official [documentation](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch): \r\n\r\n> Most dataset input pipelines should end with a call to prefetch. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\r\n\r\nI think it is better to prefetch the batches rather than single elements, so we can have next batch(es) ready while processing current batch in the training process."
            },
            {
                "commenter": "qlzh727",
                "body": "Thanks for the reference, let's wait for some inputs from tf.data side."
            },
            {
                "commenter": "qlzh727",
                "body": "Chatted with @wilsingosti offline for this issue: (copied from the chat)\r\n\r\nPrefetch is useful in 2 cases:\r\n\r\n1. If the upstream of Prefetch has variance, inserting Prefetch can help to buffer enough elements to reduce variance\r\n\r\n2. if there is a long sequence of synchronous transformations, eg. sequential map, shuffle, batch, inserting a Prefetch somewhere in the sequence can break the sequence such that the original transformations can be pipelined.\r\n\r\nIn this particular case, since the input of batch is a ParallelMap, inserting a Prefetch between batch and ParallelMap will not help case 2 because ParallelMap is an asynchronous op (which means that it has its own buffer). Inserting it after batch can help especially if the output of batch is another synchronous transform.\r\n"
            },
            {
                "commenter": "qlzh727",
                "body": "Based on the assessment above, I am approving this PR. Thanks @Frightera for the contribution."
            },
            {
                "commenter": "Frightera",
                "body": "Thanks @qlzh727, those statements were also helpful."
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 17980,
        "body": "Found by running `pydocstyle` on entire codebase.",
        "changed_files": [
            {
                "filename": "keras/benchmarks/benchmark_util.py",
                "patch": "@@ -142,13 +142,13 @@ def measure_performance(\n       ValueError: If `x` is none or if `optimizer` is not provided or\n       if `loss` is not provided or if `num_gpus` is negative.\n     \"\"\"\n-    if \"x\" is None:\n+    if x is None:\n         raise ValueError(\"Input data is required.\")\n-    if \"optimizer\" is None:\n+    elif optimizer is None:\n         raise ValueError(\"Optimizer is required.\")\n-    if \"loss\" is None:\n+    elif loss is None:\n         raise ValueError(\"Loss function is required.\")\n-    if num_gpus < 0:\n+    elif num_gpus < 0:\n         raise ValueError(\"`num_gpus` cannot be negative\")\n \n     # TODO(xingyulong): we will add tfds support later and"
            }
        ],
        "diff": "diff --git a/keras/benchmarks/benchmark_util.py b/keras/benchmarks/benchmark_util.py\nindex ff6aa670e3d..a37b71ac019 100644\n--- a/keras/benchmarks/benchmark_util.py\n+++ b/keras/benchmarks/benchmark_util.py\n@@ -142,13 +142,13 @@ def measure_performance(\n       ValueError: If `x` is none or if `optimizer` is not provided or\n       if `loss` is not provided or if `num_gpus` is negative.\n     \"\"\"\n-    if \"x\" is None:\n+    if x is None:\n         raise ValueError(\"Input data is required.\")\n-    if \"optimizer\" is None:\n+    elif optimizer is None:\n         raise ValueError(\"Optimizer is required.\")\n-    if \"loss\" is None:\n+    elif loss is None:\n         raise ValueError(\"Loss function is required.\")\n-    if num_gpus < 0:\n+    elif num_gpus < 0:\n         raise ValueError(\"`num_gpus` cannot be negative\")\n \n     # TODO(xingyulong): we will add tfds support later and\n",
        "reviews": [
            {
                "reviewer": "Frightera",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "SamuelMarks",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "Frightera",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "fchollet",
                "state": "APPROVED",
                "body": "LGTM, thanks"
            },
            {
                "reviewer": "haifeng-jin",
                "state": "APPROVED",
                "body": "Thanks for the PR!"
            }
        ],
        "comments": []
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 17357,
        "body": "I previously had a PR open for this but I guess it got automatically closed when I reverted my commits...\r\n\r\nPrevious PR: https://github.com/keras-team/keras/pull/16177\r\n\r\n@gbaned \r\n@fchollet Since the way DataAdapter works is not clear to me I went back to `training_utils.handle_partial_sample_weights`. \r\n\r\nThe function is being passed a tensor when it should be passed a list. I think we can simply add a typecheck and if a tensor is passed then we wrap it in a list. This will fix both the slowdown as well as make sure the functions is checking that sample_weights correspond to inputs and outputs instead of checking every single sample in the tensor.\r\n\r\ni.e.\r\n\r\n```\r\nif not isinstance(sample_weights, (list, tuple)):\r\n    sample_weights = (sample_weights,)\r\n```\r\n\r\nAnd this will work fine, when the `[sample_weights]` workaround is used in `model.fit()` this is exactly what it does, it causes a tuple of one tensor to be passed to the function instead of just a tensor. \r\nHow is that?\r\n\r\n",
        "changed_files": [
            {
                "filename": "keras/engine/training_utils.py",
                "patch": "@@ -72,12 +72,16 @@ def handle_partial_sample_weights(\n       Tuple of sample weights, one sample weight for every output, and booleans\n       describing the raw sample weights.\n     \"\"\"\n-    any_sample_weight = sample_weights is not None and any(\n-        w is not None for w in sample_weights\n-    )\n-    partial_sample_weight = any_sample_weight and any(\n-        w is None for w in sample_weights\n-    )\n+    if not isinstance(sample_weights, (list, tuple)):\n+        any_sample_weight = sample_weights is not None\n+        partial_sample_weight = any_sample_weight and sample_weights is None\n+    else:\n+        any_sample_weight = sample_weights is not None and any(\n+            w is not None for w in sample_weights\n+        )\n+        partial_sample_weight = any_sample_weight and any(\n+            w is None for w in sample_weights\n+        )\n \n     if not any_sample_weight:\n         return None, any_sample_weight, partial_sample_weight"
            }
        ],
        "diff": "diff --git a/keras/engine/training_utils.py b/keras/engine/training_utils.py\nindex 83771b31932..4e298157378 100644\n--- a/keras/engine/training_utils.py\n+++ b/keras/engine/training_utils.py\n@@ -72,12 +72,16 @@ def handle_partial_sample_weights(\n       Tuple of sample weights, one sample weight for every output, and booleans\n       describing the raw sample weights.\n     \"\"\"\n-    any_sample_weight = sample_weights is not None and any(\n-        w is not None for w in sample_weights\n-    )\n-    partial_sample_weight = any_sample_weight and any(\n-        w is None for w in sample_weights\n-    )\n+    if not isinstance(sample_weights, (list, tuple)):\n+        any_sample_weight = sample_weights is not None\n+        partial_sample_weight = any_sample_weight and sample_weights is None\n+    else:\n+        any_sample_weight = sample_weights is not None and any(\n+            w is not None for w in sample_weights\n+        )\n+        partial_sample_weight = any_sample_weight and any(\n+            w is None for w in sample_weights\n+        )\n \n     if not any_sample_weight:\n         return None, any_sample_weight, partial_sample_weight\n",
        "reviews": [
            {
                "reviewer": "fchollet",
                "state": "APPROVED",
                "body": "LGTM, thanks"
            },
            {
                "reviewer": "haifeng-jin",
                "state": "APPROVED",
                "body": "I am approving this PR to see if internal tests passes."
            }
        ],
        "comments": [
            {
                "commenter": "haifeng-jin",
                "body": "Pending on another reply from @fchollet .\r\nHold till 01/09/2023 to add the pending label again if no response."
            },
            {
                "commenter": "fchollet",
                "body": "Unfortunately I'm not able to merge as I've seeing a lot of test failures:\r\n\r\n```\r\nkeras/engine:data_adapter_test\r\nkeras/engine:data_adapter_test\r\nkeras/engine:training_test\r\nkeras/engine:training_test\r\nkeras/metrics:metrics_correctness_test\r\nkeras/metrics:metrics_correctness_test\r\nkeras/tests:temporal_sample_weights_correctness_test\r\nkeras/tests:temporal_sample_weights_correctness_test\r\n```\r\n\r\nCan you take a look?"
            },
            {
                "commenter": "haifeng-jin",
                "body": "@nershman Would you please take a look at the test failures?\r\nThanks!"
            },
            {
                "commenter": "gbaned",
                "body": "Hi @nershman Can you please check @haifeng-jin's comments and keep us posted ? Thank you!"
            },
            {
                "commenter": "gbaned",
                "body": "Hi @nershman Any update on this PR? Please. Thank you!"
            },
            {
                "commenter": "nershman",
                "body": "> Hi @nershman Any update on this PR? Please. Thank you!\r\n\r\nHi, I have been so busy with work recently, sorry. I have some notes on this and I'll look deeper into it this weekend."
            },
            {
                "commenter": "nershman",
                "body": "Wrapping the weights was causing issues further down in the function. I just added a case to the partial sample check in the beginning instead.\r\n\r\n```\r\n    if not isinstance(sample_weights, (list, tuple)): \r\n        any_sample_weight = (sample_weights,) is not None and sample_weights is not None  #wrap the weights during check instead of overwriting\r\n        partial_sample_weight = any_sample_weight and sample_weights is None\r\n    else: #normal check\r\n        any_sample_weight = sample_weights is not None and any(\r\n            w is not None for w in sample_weights\r\n        )\r\n        partial_sample_weight = any_sample_weight and any(\r\n            w is None for w in sample_weights\r\n        )\r\n```\r\nTests pass on my machine now. (data_adapter_test, training_test, metrics_correctness_test, temporal_sample_weights_correctness_test)"
            },
            {
                "commenter": "chuckatkins",
                "body": "Is it reasonable to try to have NumPy process the weights directly if possible, and in doing so give any non-finite weight the same treatment as `None`?  Something like:\r\n\r\n```python\r\nif sample_weights is None:\r\n    any_sample_weight = False\r\n    partial_sample_weight = False\r\nelse:\r\n    try:\r\n        sample_weights_isfinite = np.isfinite(sample_weights)\r\n        any_sample_weight = np.any(sample_weights_isfinite)\r\n        if any_sample_weight:\r\n            partial_sample_weight = not np.all(sample_weights_isfinite)\r\n            if partial_sample_weight:\r\n                new_sample_weights = np.nan_to_num(sample_weights, nan=1.0, posinf=1.0, neginf=1.0)\r\n                return new_sample_weights, any_sample_weight, partial_sample_weight\r\n    except TypeError:\r\n        if not isinstance(sample_weights, (list, tuple)):\r\n            any_sample_weight = True\r\n            partial_sample_weight = False\r\n        else:\r\n            any_sample_weight = any(w is not None for w in sample_weights)\r\n            partial_sample_weight = any_sample_weight and any(w is None for w in sample_weights)\r\n\r\nif not any_sample_weight:\r\n    return None, any_sample_weight, partial_sample_weight\r\n\r\nif not partial_sample_weight:\r\n    return sample_weights, any_sample_weight, partial_sample_weight\r\n```"
            },
            {
                "commenter": "nershman",
                "body": "\r\n@chuckatkins I think you should make a separate bug report for this, I'm not familiar with what you're trying to fix. But my concern with using numpy would be creating issues with eager execution."
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 17512,
        "body": "Resolves https://github.com/keras-team/keras/issues/17402",
        "changed_files": [
            {
                "filename": "keras/layers/normalization/group_normalization.py",
                "patch": "@@ -212,7 +212,7 @@ def _get_reshaped_weights(self, input_shape):\n         return gamma, beta\n \n     def _create_broadcast_shape(self, input_shape):\n-        broadcast_shape = [1] * input_shape.shape.rank\n+        broadcast_shape = [1] * len(input_shape)\n \n         broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n         broadcast_shape.insert(self.axis, self.groups)"
            }
        ],
        "diff": "diff --git a/keras/layers/normalization/group_normalization.py b/keras/layers/normalization/group_normalization.py\nindex 1bc78d2207e..82fd8820c5f 100644\n--- a/keras/layers/normalization/group_normalization.py\n+++ b/keras/layers/normalization/group_normalization.py\n@@ -212,7 +212,7 @@ def _get_reshaped_weights(self, input_shape):\n         return gamma, beta\n \n     def _create_broadcast_shape(self, input_shape):\n-        broadcast_shape = [1] * input_shape.shape.rank\n+        broadcast_shape = [1] * len(input_shape)\n \n         broadcast_shape[self.axis] = input_shape[self.axis] // self.groups\n         broadcast_shape.insert(self.axis, self.groups)\n",
        "reviews": [
            {
                "reviewer": "fchollet",
                "state": "COMMENTED",
                "body": "Thanks for the PR. Can you please add a unit test?"
            }
        ],
        "comments": [
            {
                "commenter": "google-cla[bot]",
                "body": "Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/keras-team/keras/pull/17512/checks?check_run_id=11034252432) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."
            },
            {
                "commenter": "gbaned",
                "body": "Hi @MasterSkepticista Can you please sign CLA. Thank you!"
            },
            {
                "commenter": "MasterSkepticista",
                "body": "Should the unit test assert all combinations of valid axes for a given input shape?\r\n[This is my first contribution on keras]"
            },
            {
                "commenter": "fchollet",
                "body": "It should be a test that fails before this PR and passes after this PR."
            },
            {
                "commenter": "MasterSkepticista",
                "body": "I tried running existing bazel tests before adding my own within `keras/layers/normalization` to understand the flow, as shown below. \r\n \r\n```bash\r\n$> bazel test keras/layers/normalization:*\r\nWARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=175\r\nINFO: Reading rc options for 'test' from /home/karan/playground/keras/.bazelrc:\r\n  Inherited 'build' options: --apple_platform_type=macos --define open_source_build=true --define=use_fast_cpp_protos=false --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --config=short_logs --config=v2\r\nINFO: Reading rc options for 'test' from /home/karan/playground/keras/.bazelrc:\r\n  'test' options: --define open_source_build=true --define=use_fast_cpp_protos=false --config=v2\r\nINFO: Found applicable config definition build:short_logs in file /home/karan/playground/keras/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/karan/playground/keras/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:v2 in file /home/karan/playground/keras/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Analyzed 25 targets (1 packages loaded, 38 targets configured).\r\nINFO: Found 17 targets and 8 test targets...\r\nINFO: Elapsed time: 90.021s, Critical Path: 67.23s\r\nINFO: 48 processes: 22 internal, 26 local.\r\nINFO: Build completed successfully, 48 total actions\r\n//keras/layers/normalization:unit_normalization_test                     PASSED in 14.9s\r\n//keras/layers/normalization:unit_normalization_test_gpu                 PASSED in 15.3s\r\n//keras/layers/normalization:batch_normalization_test                    PASSED in 56.9s\r\n  Stats over 4 runs: max = 56.9s, min = 20.6s, avg = 36.7s, dev = 13.6s\r\n//keras/layers/normalization:batch_normalization_test_gpu                PASSED in 52.8s\r\n  Stats over 4 runs: max = 52.8s, min = 19.6s, avg = 32.1s, dev = 12.4s\r\n//keras/layers/normalization:group_normalization_test                    PASSED in 7.1s\r\n  Stats over 4 runs: max = 7.1s, min = 6.7s, avg = 6.9s, dev = 0.2s\r\n//keras/layers/normalization:group_normalization_test_gpu                PASSED in 6.9s\r\n  Stats over 4 runs: max = 6.9s, min = 5.6s, avg = 6.3s, dev = 0.5s\r\n//keras/layers/normalization:layer_normalization_test                    PASSED in 67.2s\r\n  Stats over 4 runs: max = 67.2s, min = 19.2s, avg = 39.2s, dev = 19.1s\r\n//keras/layers/normalization:layer_normalization_test_gpu                PASSED in 49.6s\r\n  Stats over 4 runs: max = 49.6s, min = 21.5s, avg = 32.3s, dev = 10.7s\r\n\r\nExecuted 8 out of 8 tests: 8 tests pass.\r\nINFO: Build completed successfully, 48 total actions\r\n```\r\n\r\nLog (1 shard)\r\n```log\r\nexec ${PAGER:-/usr/bin/less} \"$0\" || exit 1\r\nExecuting tests from //keras/layers/normalization:group_normalization_test\r\n-----------------------------------------------------------------------------\r\n2023-02-27 10:22:09.586283: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\r\n2023-02-27 10:22:09.704700: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\r\n2023-02-27 10:22:09.705382: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2023-02-27 10:22:12.133368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\r\nRunning tests under Python 3.9.5: /home/karan/playground/venv/bin/python3\r\n----------------------------------------------------------------------\r\nRan 0 tests in 0.000s\r\n\r\nOK\r\n```\r\n\r\n\r\nAll tests pass, but upon inspecting logs, `group_normalization_test` does not actually run any tests.  Do you have any pointers for me to look at?\r\n\r\nPlease note: This is _before_ applying any of the PR changes. Other layer tests run fine.\r\n"
            },
            {
                "commenter": "fchollet",
                "body": "> All tests pass, but upon inspecting logs, group_normalization_test does not actually run any tests. Do you have any pointers for me to look at?\r\n\r\nAre you sure about that? How did you verify it?\r\n\r\nThe tests look fine at a glance."
            },
            {
                "commenter": "gbaned",
                "body": "Hi @MasterSkepticista Can you please resolve conflicts? Thank you!"
            },
            {
                "commenter": "qlzh727",
                "body": "Please resolve the merge conflict and sign the CLA. Thanks."
            },
            {
                "commenter": "MasterSkepticista",
                "body": "Commit https://github.com/keras-team/keras/commit/6ed1574c0e9d80273d854556db9d304e818e45e5 on `master` achieves the same result as `len(input_shape)` .\r\nThe commit was done after opening this PR.\r\nClosing this PR as the change is now redundant."
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 17587,
        "body": "A previous PR #17111 added some logic to use fallback implementations of GRU and LSTM on ROCm in situations where padded i/o is needed (since ROCm does not support padded i/o).\r\n\r\nThat logic turns out to be too restrictive - it chooses the fallback path in cases where it is not really needed, which may result in significant performance degradations.\r\n\r\nThis PR resolves the problem.\r\n",
        "changed_files": [
            {
                "filename": "keras/layers/rnn/gru_lstm_utils.py",
                "patch": "@@ -170,7 +170,7 @@ def has_fully_masked_sequence(mask):\n \n def is_cudnn_supported_inputs(mask, time_major, sequence_lengths):\n     if tf.sysconfig.get_build_info()[\"is_rocm_build\"]:\n-        if not time_major:\n+        if (not time_major) and (sequence_lengths is not None):\n             return False\n         if mask is not None:\n             return tf.reduce_all(mask)"
            }
        ],
        "diff": "diff --git a/keras/layers/rnn/gru_lstm_utils.py b/keras/layers/rnn/gru_lstm_utils.py\nindex e341ca668cf..63cc1255484 100644\n--- a/keras/layers/rnn/gru_lstm_utils.py\n+++ b/keras/layers/rnn/gru_lstm_utils.py\n@@ -170,7 +170,7 @@ def has_fully_masked_sequence(mask):\n \n def is_cudnn_supported_inputs(mask, time_major, sequence_lengths):\n     if tf.sysconfig.get_build_info()[\"is_rocm_build\"]:\n-        if not time_major:\n+        if (not time_major) and (sequence_lengths is not None):\n             return False\n         if mask is not None:\n             return tf.reduce_all(mask)\n",
        "reviews": [
            {
                "reviewer": "fchollet",
                "state": "APPROVED",
                "body": "LGTM, thanks for the PR."
            }
        ],
        "comments": [
            {
                "commenter": "jayfurmanek",
                "body": "@fchollet  would it be acceptable to cherry-pick this one to the 2.12 branch as well?"
            },
            {
                "commenter": "fchollet",
                "body": "> would it be acceptable to cherry-pick this one to the 2.12 branch as well?\r\n\r\nYes -- please open a PR against the r2.12 branch."
            },
            {
                "commenter": "jayfurmanek",
                "body": "Thanks! I opened https://github.com/keras-team/keras/pull/17591 against r2.12."
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 17591,
        "body": "A previous PR https://github.com/keras-team/keras/pull/17111 added some logic to use fallback implementations of GRU and LSTM on ROCm in situations where padded i/o is needed (since ROCm does not support padded i/o).\r\n\r\nThat logic turns out to be too restrictive - it chooses the fallback path in cases where it is not really needed, which may result in significant performance degradations.\r\n\r\nThis is a cherry-pick of https://github.com/keras-team/keras/pull/17587",
        "changed_files": [
            {
                "filename": "keras/layers/rnn/gru_lstm_utils.py",
                "patch": "@@ -170,7 +170,7 @@ def has_fully_masked_sequence(mask):\n \n def is_cudnn_supported_inputs(mask, time_major, sequence_lengths):\n     if tf.sysconfig.get_build_info()[\"is_rocm_build\"]:\n-        if not time_major:\n+        if (not time_major) and (sequence_lengths is not None):\n             return False\n         if mask is not None:\n             return tf.reduce_all(mask)"
            }
        ],
        "diff": "diff --git a/keras/layers/rnn/gru_lstm_utils.py b/keras/layers/rnn/gru_lstm_utils.py\nindex e341ca668cf..63cc1255484 100644\n--- a/keras/layers/rnn/gru_lstm_utils.py\n+++ b/keras/layers/rnn/gru_lstm_utils.py\n@@ -170,7 +170,7 @@ def has_fully_masked_sequence(mask):\n \n def is_cudnn_supported_inputs(mask, time_major, sequence_lengths):\n     if tf.sysconfig.get_build_info()[\"is_rocm_build\"]:\n-        if not time_major:\n+        if (not time_major) and (sequence_lengths is not None):\n             return False\n         if mask is not None:\n             return tf.reduce_all(mask)\n",
        "reviews": [
            {
                "reviewer": "fchollet",
                "state": "APPROVED",
                "body": "LGTM\r\n\r\nCC @qlzh727 -- this would be a 2.12 cherrypick."
            }
        ],
        "comments": []
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 17140,
        "body": "This rescale is generally useless because reduce_sum is generally equal to 1. Disabling the rescale is significantly faster (E.g, from 11 seconds to 7 seconds).\r\n\r\nWhy reduced_sum(output) is always equal to 1 ? Because the rescaling is performed on values WHICH ARE NOT A LOGIT. In general, the ouput has already been already rescaled with a softmax.\r\n \r\n I choose to enable / disable with the default behaviour is forced_rescale=True which is the previous behaviour. The default behaviour is preserved for safety. I recommend to put forced_rescale=False later.\r\n\r\nExample of code to compare:\r\n```\r\nimport numpy as np\r\nfrom numpy.ma.core import _frommethod\r\nfrom tensorflow.keras.activations import softmax\r\nfrom tensorflow import constant\r\nfrom keras.backend import categorical_crossentropy\r\nNB_SAMPLES=1000\r\nNB_CLASSES=1000\r\ny=np.zeros((NB_SAMPLES,NB_CLASSES))\r\ny[:,0]=1\r\ny_pred=np.random.uniform(0,1,(NB_SAMPLES,NB_CLASSES))\r\ny_pred=softmax(constant(y_pred)).numpy()\r\ntf_y=constant(y)\r\ntf_y_pred=constant(y_pred)\r\n\r\n\r\nimport time\r\nst_time=time.time()\r\nfor i in range(1000):\r\n  res=categorical_crossentropy(tf_y, tf_y_pred ) # old behaviour\r\nprint(\"Enlapsed time:\", time.time()-st_time)\r\nprint(\"Loss:\", np.mean(res))\r\n\r\nst_time=time.time()\r\nfor i in range(1000):\r\n  res=categorical_crossentropy(tf_y, tf_y_pred,forced_rescale=False) # new behaviour\r\nprint(\"Enlapsed time:\", time.time()-st_time)\r\nprint(\"Loss:\", np.mean(res))\r\n```\r\n\r\nreturns:\r\n\r\n```\r\nEnlapsed time: 11.447702169418335\r\nLoss: 6.944476480206596\r\nEnlapsed time: 7.416125059127808\r\nLoss: 6.944476480206596\r\n```\r\nYou observe the computed loss is strictly the same.",
        "changed_files": [
            {
                "filename": "keras/backend.py",
                "patch": "@@ -5539,8 +5539,6 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n             labels=target, logits=output, axis=axis\n         )\n \n-    # scale preds so that the class probas of each sample sum to 1\n-    output = output / tf.reduce_sum(output, axis, True)\n     # Compute cross entropy from probabilities.\n     epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n     output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)"
            },
            {
                "filename": "keras/backend_test.py",
                "patch": "@@ -1957,11 +1957,11 @@ def test_categorical_crossentropy_loss_with_unknown_rank_tensor(self):\n         self.assertArrayNear(result, [0.105, 0.116, 0.062], 1e-3)\n \n         # With axis set\n-        o = backend.categorical_crossentropy(t, p, axis=0)\n+        o = backend.categorical_crossentropy(t, p, axis=-1)\n         f = backend.function([t, p], o)\n \n         result = f([t_val, p_val])\n-        self.assertArrayNear(result, [0.105, 0.065, 0.111], 1e-3)\n+        self.assertArrayNear(result, [0.105, 0.116, 0.062], 1e-3)\n \n         # from logits\n         p_val = tf.convert_to_tensor(\n@@ -1971,14 +1971,14 @@ def test_categorical_crossentropy_loss_with_unknown_rank_tensor(self):\n         f = backend.function([t, p], o)\n \n         result = f([t_val, p_val])\n-        self.assertArrayNear(result, [0.002, 0, 0.17], 1e-3)\n+        self.assertArrayNear(result, [0.002, 0.001, 0.17], 1e-3)\n \n         # from logits and axis set\n-        o = backend.categorical_crossentropy(t, p, from_logits=True, axis=0)\n+        o = backend.categorical_crossentropy(t, p, from_logits=True, axis=-1)\n         f = backend.function([t, p], o)\n \n         result = f([t_val, p_val])\n-        self.assertArrayNear(result, [0.002, 0.003, 0.036], 1e-3)\n+        self.assertArrayNear(result, [0.002, 0.001, 0.17], 1e-3)\n \n     @test_combinations.generate(\n         test_combinations.combine(mode=[\"graph\", \"eager\"])"
            },
            {
                "filename": "keras/losses_test.py",
                "patch": "@@ -113,6 +113,30 @@ def test_categorical_crossentropy_loss(self):\n             atol=1e-5,\n         )\n \n+    @test_combinations.generate(\n+        test_combinations.combine(mode=[\"graph\", \"eager\"])\n+    )\n+    def test_categorical_crossentropy_loss_with_one_class(self):\n+        t = backend.placeholder()\n+        p = backend.placeholder()\n+        o = losses.categorical_crossentropy(t, p)\n+\n+        t_val = tf.convert_to_tensor([[1.0], [1.0], [1.0], [1.0]])\n+        p_val = tf.convert_to_tensor([[0.49], [0.51], [0.95], [1.0]])\n+        f = backend.function([t, p], o)\n+\n+        result = f([t_val, p_val])\n+        self.assertArrayNear(result, [0.7133, 0.6733, 0.0513, 0.0], 1e-3)\n+\n+        # from logits\n+        p_val = tf.convert_to_tensor([[-1.1], [0.0], [1.1], [8.0]])\n+        o = losses.categorical_crossentropy(t, p, from_logits=True)\n+        f = backend.function([t, p], o)\n+\n+        result = f([t_val, p_val])\n+        # In monoclass case softmax(logit) is always 1. So, loss is always 0.\n+        self.assertArrayNear(result, [0.0, 0, 0, 0], 1e-3)\n+\n     @test_combinations.generate(\n         test_combinations.combine(mode=[\"graph\", \"eager\"])\n     )\n@@ -1626,11 +1650,11 @@ def test_unweighted(self):\n         cce_obj = losses.CategoricalCrossentropy()\n         y_true = tf.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n         y_pred = tf.constant(\n-            [[0.9, 0.05, 0.05], [0.5, 0.89, 0.6], [0.05, 0.01, 0.94]],\n+            [[0.9, 0.05, 0.05], [0.05, 0.89, 0.06], [0.05, 0.01, 0.94]],\n             dtype=tf.float32,\n         )\n         loss = cce_obj(y_true, y_pred)\n-        self.assertAlmostEqual(self.evaluate(loss), 0.3239, 3)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.0946, 3)\n \n         # Test with logits.\n         logits = tf.constant(\n@@ -1644,11 +1668,11 @@ def test_scalar_weighted(self):\n         cce_obj = losses.CategoricalCrossentropy()\n         y_true = tf.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n         y_pred = tf.constant(\n-            [[0.9, 0.05, 0.05], [0.5, 0.89, 0.6], [0.05, 0.01, 0.94]],\n+            [[0.9, 0.05, 0.05], [0.05, 0.89, 0.06], [0.05, 0.01, 0.94]],\n             dtype=tf.float32,\n         )\n         loss = cce_obj(y_true, y_pred, sample_weight=2.3)\n-        self.assertAlmostEqual(self.evaluate(loss), 0.7449, 3)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.2176, 3)\n \n         # Test with logits.\n         logits = tf.constant(\n@@ -1662,12 +1686,12 @@ def test_sample_weighted(self):\n         cce_obj = losses.CategoricalCrossentropy()\n         y_true = tf.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n         y_pred = tf.constant(\n-            [[0.9, 0.05, 0.05], [0.5, 0.89, 0.6], [0.05, 0.01, 0.94]],\n+            [[0.9, 0.05, 0.05], [0.05, 0.89, 0.06], [0.05, 0.01, 0.94]],\n             dtype=tf.float32,\n         )\n         sample_weight = tf.constant([[1.2], [3.4], [5.6]], shape=(3, 1))\n         loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n-        self.assertAlmostEqual(self.evaluate(loss), 1.0696, 3)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.2897, 3)\n \n         # Test with logits.\n         logits = tf.constant(\n@@ -1739,7 +1763,7 @@ def test_label_smoothing_ndarray(self):\n     def test_shape_mismatch(self):\n         y_true = tf.constant([[0], [1], [2]])\n         y_pred = tf.constant(\n-            [[0.9, 0.05, 0.05], [0.5, 0.89, 0.6], [0.05, 0.01, 0.94]]\n+            [[0.9, 0.05, 0.05], [0.05, 0.89, 0.06], [0.05, 0.01, 0.94]]\n         )\n \n         cce_obj = losses.CategoricalCrossentropy()\n@@ -1750,14 +1774,14 @@ def test_ragged_tensors(self):\n         cce_obj = losses.CategoricalCrossentropy()\n         y_true = tf.ragged.constant([[[1, 0, 0], [0, 1, 0]], [[0, 0, 1]]])\n         y_pred = tf.ragged.constant(\n-            [[[0.9, 0.05, 0.05], [0.5, 0.89, 0.6]], [[0.05, 0.01, 0.94]]],\n+            [[[0.9, 0.05, 0.05], [0.05, 0.89, 0.06]], [[0.05, 0.01, 0.94]]],\n             dtype=tf.float32,\n         )\n         # batch losses [[0.1054, 0.8047], [0.0619]]\n         sample_weight = tf.constant([[1.2], [3.4]], shape=(2, 1))\n         loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n         # sum([0.1054, 0.8047, 0.0619]) / 3\n-        self.assertAlmostEqual(self.evaluate(loss), 0.4341, 3)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.1589, 3)\n \n         # Test with logits.\n         logits = tf.ragged.constant("
            }
        ],
        "diff": "diff --git a/keras/backend.py b/keras/backend.py\nindex 3571b315bca..f21439d64ee 100644\n--- a/keras/backend.py\n+++ b/keras/backend.py\n@@ -5539,8 +5539,6 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n             labels=target, logits=output, axis=axis\n         )\n \n-    # scale preds so that the class probas of each sample sum to 1\n-    output = output / tf.reduce_sum(output, axis, True)\n     # Compute cross entropy from probabilities.\n     epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n     output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\ndiff --git a/keras/backend_test.py b/keras/backend_test.py\nindex 89497676244..817b299efe0 100644\n--- a/keras/backend_test.py\n+++ b/keras/backend_test.py\n@@ -1957,11 +1957,11 @@ def test_categorical_crossentropy_loss_with_unknown_rank_tensor(self):\n         self.assertArrayNear(result, [0.105, 0.116, 0.062], 1e-3)\n \n         # With axis set\n-        o = backend.categorical_crossentropy(t, p, axis=0)\n+        o = backend.categorical_crossentropy(t, p, axis=-1)\n         f = backend.function([t, p], o)\n \n         result = f([t_val, p_val])\n-        self.assertArrayNear(result, [0.105, 0.065, 0.111], 1e-3)\n+        self.assertArrayNear(result, [0.105, 0.116, 0.062], 1e-3)\n \n         # from logits\n         p_val = tf.convert_to_tensor(\n@@ -1971,14 +1971,14 @@ def test_categorical_crossentropy_loss_with_unknown_rank_tensor(self):\n         f = backend.function([t, p], o)\n \n         result = f([t_val, p_val])\n-        self.assertArrayNear(result, [0.002, 0, 0.17], 1e-3)\n+        self.assertArrayNear(result, [0.002, 0.001, 0.17], 1e-3)\n \n         # from logits and axis set\n-        o = backend.categorical_crossentropy(t, p, from_logits=True, axis=0)\n+        o = backend.categorical_crossentropy(t, p, from_logits=True, axis=-1)\n         f = backend.function([t, p], o)\n \n         result = f([t_val, p_val])\n-        self.assertArrayNear(result, [0.002, 0.003, 0.036], 1e-3)\n+        self.assertArrayNear(result, [0.002, 0.001, 0.17], 1e-3)\n \n     @test_combinations.generate(\n         test_combinations.combine(mode=[\"graph\", \"eager\"])\ndiff --git a/keras/losses_test.py b/keras/losses_test.py\nindex 26ac4da14f7..8332268f554 100644\n--- a/keras/losses_test.py\n+++ b/keras/losses_test.py\n@@ -113,6 +113,30 @@ def test_categorical_crossentropy_loss(self):\n             atol=1e-5,\n         )\n \n+    @test_combinations.generate(\n+        test_combinations.combine(mode=[\"graph\", \"eager\"])\n+    )\n+    def test_categorical_crossentropy_loss_with_one_class(self):\n+        t = backend.placeholder()\n+        p = backend.placeholder()\n+        o = losses.categorical_crossentropy(t, p)\n+\n+        t_val = tf.convert_to_tensor([[1.0], [1.0], [1.0], [1.0]])\n+        p_val = tf.convert_to_tensor([[0.49], [0.51], [0.95], [1.0]])\n+        f = backend.function([t, p], o)\n+\n+        result = f([t_val, p_val])\n+        self.assertArrayNear(result, [0.7133, 0.6733, 0.0513, 0.0], 1e-3)\n+\n+        # from logits\n+        p_val = tf.convert_to_tensor([[-1.1], [0.0], [1.1], [8.0]])\n+        o = losses.categorical_crossentropy(t, p, from_logits=True)\n+        f = backend.function([t, p], o)\n+\n+        result = f([t_val, p_val])\n+        # In monoclass case softmax(logit) is always 1. So, loss is always 0.\n+        self.assertArrayNear(result, [0.0, 0, 0, 0], 1e-3)\n+\n     @test_combinations.generate(\n         test_combinations.combine(mode=[\"graph\", \"eager\"])\n     )\n@@ -1626,11 +1650,11 @@ def test_unweighted(self):\n         cce_obj = losses.CategoricalCrossentropy()\n         y_true = tf.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n         y_pred = tf.constant(\n-            [[0.9, 0.05, 0.05], [0.5, 0.89, 0.6], [0.05, 0.01, 0.94]],\n+            [[0.9, 0.05, 0.05], [0.05, 0.89, 0.06], [0.05, 0.01, 0.94]],\n             dtype=tf.float32,\n         )\n         loss = cce_obj(y_true, y_pred)\n-        self.assertAlmostEqual(self.evaluate(loss), 0.3239, 3)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.0946, 3)\n \n         # Test with logits.\n         logits = tf.constant(\n@@ -1644,11 +1668,11 @@ def test_scalar_weighted(self):\n         cce_obj = losses.CategoricalCrossentropy()\n         y_true = tf.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n         y_pred = tf.constant(\n-            [[0.9, 0.05, 0.05], [0.5, 0.89, 0.6], [0.05, 0.01, 0.94]],\n+            [[0.9, 0.05, 0.05], [0.05, 0.89, 0.06], [0.05, 0.01, 0.94]],\n             dtype=tf.float32,\n         )\n         loss = cce_obj(y_true, y_pred, sample_weight=2.3)\n-        self.assertAlmostEqual(self.evaluate(loss), 0.7449, 3)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.2176, 3)\n \n         # Test with logits.\n         logits = tf.constant(\n@@ -1662,12 +1686,12 @@ def test_sample_weighted(self):\n         cce_obj = losses.CategoricalCrossentropy()\n         y_true = tf.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n         y_pred = tf.constant(\n-            [[0.9, 0.05, 0.05], [0.5, 0.89, 0.6], [0.05, 0.01, 0.94]],\n+            [[0.9, 0.05, 0.05], [0.05, 0.89, 0.06], [0.05, 0.01, 0.94]],\n             dtype=tf.float32,\n         )\n         sample_weight = tf.constant([[1.2], [3.4], [5.6]], shape=(3, 1))\n         loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n-        self.assertAlmostEqual(self.evaluate(loss), 1.0696, 3)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.2897, 3)\n \n         # Test with logits.\n         logits = tf.constant(\n@@ -1739,7 +1763,7 @@ def test_label_smoothing_ndarray(self):\n     def test_shape_mismatch(self):\n         y_true = tf.constant([[0], [1], [2]])\n         y_pred = tf.constant(\n-            [[0.9, 0.05, 0.05], [0.5, 0.89, 0.6], [0.05, 0.01, 0.94]]\n+            [[0.9, 0.05, 0.05], [0.05, 0.89, 0.06], [0.05, 0.01, 0.94]]\n         )\n \n         cce_obj = losses.CategoricalCrossentropy()\n@@ -1750,14 +1774,14 @@ def test_ragged_tensors(self):\n         cce_obj = losses.CategoricalCrossentropy()\n         y_true = tf.ragged.constant([[[1, 0, 0], [0, 1, 0]], [[0, 0, 1]]])\n         y_pred = tf.ragged.constant(\n-            [[[0.9, 0.05, 0.05], [0.5, 0.89, 0.6]], [[0.05, 0.01, 0.94]]],\n+            [[[0.9, 0.05, 0.05], [0.05, 0.89, 0.06]], [[0.05, 0.01, 0.94]]],\n             dtype=tf.float32,\n         )\n         # batch losses [[0.1054, 0.8047], [0.0619]]\n         sample_weight = tf.constant([[1.2], [3.4]], shape=(2, 1))\n         loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n         # sum([0.1054, 0.8047, 0.0619]) / 3\n-        self.assertAlmostEqual(self.evaluate(loss), 0.4341, 3)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.1589, 3)\n \n         # Test with logits.\n         logits = tf.ragged.constant(\n",
        "reviews": [
            {
                "reviewer": "divyashreepathihalli",
                "state": "CHANGES_REQUESTED",
                "body": "@PierrickPochelu - Thank you for the PR! \r\nFew minor comments\r\n- So the first edge case where all outputs are zero is not a feasible edge case in reality, it can be ignored\r\n- please add the unit tests for single class edge case\r\n- Upon removing this line, the unit tests need to be updated"
            },
            {
                "reviewer": "fchollet",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "divyashreepathihalli",
                "state": "CHANGES_REQUESTED",
                "body": "@PierrickPochelu, you would still need to update the test file. There are some failing tests - more information here - https://source.cloud.google.com/results/invocations/0c68e47a-876c-4d01-9689-340466310029/targets/keras%2Fpip%2Fpresubmit/log\r\n"
            },
            {
                "reviewer": "divyashreepathihalli",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "fchollet",
                "state": "APPROVED",
                "body": "LGTM, thanks! Let's try to merge. Please be mindful of the fact that we might end up being unable to merge due to backwards compatibility breakage. This is an attempt."
            }
        ],
        "comments": [
            {
                "commenter": "PierrickPochelu",
                "body": "Agree, I removed the arg and the conditional in my last commit."
            },
            {
                "commenter": "PierrickPochelu",
                "body": "I have seen some logical mistakes in the unit tests.\r\n\r\nThis wrong input have been used in multiple unit tests : [0.5, 0.89, 0.6] in combination of from_logits=False .\r\n\r\nAssuming a correct usage of the API, we should have:\r\n- either categorical_crossentropy(Y, [0.**0**5, 0.89, 0.**0**6], from_logits=False)\r\n- or categorical_crossentropy(Y, [0.5, 0.89, 0.6], from_logits=**True** )\r\n\r\nI send a PR of the unit tests ASAP"
            },
            {
                "commenter": "PierrickPochelu",
                "body": "The 8 wrong test units have been corrected."
            },
            {
                "commenter": "divyashreepathihalli",
                "body": "> The 8 wrong test units have been corrected.\r\n\r\n@PierrickPochelu  can you also add the unit tests for single class edge case?"
            },
            {
                "commenter": "PierrickPochelu",
                "body": "Any other edge case to handle ?"
            },
            {
                "commenter": "fchollet",
                "body": "One drive-by comment. If you care about speed, you should use a tf.function. Something like\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nfrom tensorflow.keras.activations import softmax\r\nfrom tensorflow import constant\r\nfrom keras.backend import categorical_crossentropy\r\n\r\nNB_SAMPLES=1000\r\nNB_CLASSES=1000\r\ny = np.zeros((NB_SAMPLES,NB_CLASSES))\r\ny[:,0] = 1\r\ny_pred = np.random.uniform(0,1,(NB_SAMPLES,NB_CLASSES))\r\n\r\ny = tf.constant(y)\r\ny_pred = tf.constant(y_pred)\r\n\r\n@tf.function\r\ndef fn(y, y_pred):\r\n  y_pred = softmax(y_pred)\r\n  return categorical_crossentropy(y, tf_y_pred)\r\n\r\nfn(y, y_pred) # warmup\r\n\r\nimport time\r\nst_time = time.time()\r\nfor i in range(1000):\r\n  fn(y, y_pred)\r\nprint(\"Elapsed time:\", time.time() - st_time)\r\n```\r\n\r\nIt should be about 3x faster.\r\n\r\nAlso note that it will use `from_logits` automatically."
            },
            {
                "commenter": "divyashreepathihalli",
                "body": "> \r\n\r\nI have added another comment here.- https://github.com/keras-team/keras/pull/17140#discussion_r1002211748"
            },
            {
                "commenter": "divyashreepathihalli",
                "body": "@PierrickPochelu can you please fix the lint errors - https://github.com/keras-team/keras/actions/runs/3329674806/jobs/5513349190"
            },
            {
                "commenter": "PierrickPochelu",
                "body": "Done"
            },
            {
                "commenter": "divyashreepathihalli",
                "body": "Hey @PierrickPochelu sorry about the late response. \r\nCan you please resolve these errors \r\n- https://source.cloud.google.com/results/invocations/e76b488f-8bef-4700-b5c5-9b3d8e164502\r\n- https://source.cloud.google.com/results/invocations/0d3b0b95-d078-42b9-bed5-7d136f630013\r\n\r\nyou can run these tests by adding kokoro:force-run label to the PR."
            },
            {
                "commenter": "PierrickPochelu",
                "body": "All CI tests are OK"
            },
            {
                "commenter": "divyashreepathihalli",
                "body": "@PierrickPochelu, this change breaks several tests internally and there are no straight forward fixes. Since the  performance improvement is not very significant to break backwards compatibility, we will not be merging these changes. "
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 8044,
        "body": "https://twitter.com/farizrahman4u/status/914609159596859392",
        "changed_files": [
            {
                "filename": "examples/lstm_seq2seq.py",
                "patch": "@@ -51,22 +51,30 @@\n from __future__ import print_function\n \n from keras.models import Model\n-from keras.layers import Input, LSTM, Dense\n+from keras.layers import Input, LSTM, Dense, Lambda\n+from keras import backend as K\n import numpy as np\n+import sys\n+\n+py3 = sys.version_info[0] == 3\n+\n \n batch_size = 64  # Batch size for training.\n epochs = 100  # Number of epochs to train for.\n latent_dim = 256  # Latent dimensionality of the encoding space.\n num_samples = 10000  # Number of samples to train on.\n # Path to the data txt file on disk.\n-data_path = '/Users/fchollet/Downloads/fra-eng/fra.txt'\n+data_path = '/Users/Fariz/Downloads/fra-eng/fra.txt'\n \n # Vectorize the data.\n input_texts = []\n target_texts = []\n input_characters = set()\n target_characters = set()\n-lines = open(data_path).read().split('\\n')\n+if py3:\n+    lines = open(data_path, encoding='utf8').read().split('\\n')\n+else:\n+    lines = open(data_path).read().split('\\n')\n for line in lines[: min(num_samples, len(lines) - 1)]:\n     input_text, target_text = line.split('\\t')\n     # We use \"tab\" as the \"start sequence\" character\n@@ -159,19 +167,48 @@\n # Output will be the next target token\n # 3) Repeat with the current target token and current states\n \n-# Define sampling models\n-encoder_model = Model(encoder_inputs, encoder_states)\n \n-decoder_state_input_h = Input(shape=(latent_dim,))\n-decoder_state_input_c = Input(shape=(latent_dim,))\n-decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n-decoder_outputs, state_h, state_c = decoder_lstm(\n-    decoder_inputs, initial_state=decoder_states_inputs)\n-decoder_states = [state_h, state_c]\n-decoder_outputs = decoder_dense(decoder_outputs)\n-decoder_model = Model(\n-    [decoder_inputs] + decoder_states_inputs,\n-    [decoder_outputs] + decoder_states)\n+def sample_loop(initial_states, output_length):\n+    # symbolic loop for sampling from the decoder\n+    zeros = K.zeros((1, output_length, 1))\n+\n+    def step(_, states):\n+        y_tm1, h_tm1, c_tm1 = states\n+        y_tm1._keras_shape = (None, 1, None)  # required for theano backend\n+        y, h, c = decoder_lstm.call([y_tm1, h_tm1, c_tm1])\n+        y = decoder_dense.call(y)\n+        # convert softmax to one hot\n+        mx = K.max(y, axis=2, keepdims=True)\n+        y_oh = K.cast(K.equal(y, mx), K.floatx())\n+        return y_oh[:, 0, :], [y_oh, h, c]\n+    return K.rnn(step, zeros, initial_states)[1]\n+\n+sampler = Lambda(sample_loop,\n+                 arguments={'output_length': max_decoder_seq_length},\n+                 output_shape=(max_decoder_seq_length, num_decoder_tokens))\n+\n+\n+def get_start_tokens(input_sequence, start_token_index, num_tokens):\n+    # returns a batch of one hots of the start token ('\\t')\n+    x = K.zeros_like(input_sequence[:, :1, 0])\n+    x += start_token_index\n+    x = K.cast(x, 'int32')\n+    return K.one_hot(x, num_tokens)  # (batch_size, 1, num_tokens)\n+\n+start_token_idx = target_token_index['\\t']\n+start_token_generator = Lambda(get_start_tokens,\n+                               arguments={'start_token_index': start_token_idx,\n+                                          'num_tokens': num_decoder_tokens},\n+                               output_shape=lambda s: (1, num_decoder_tokens))\n+\n+\n+input_sequence = Input(shape=(None, num_encoder_tokens))\n+_, state_h, state_c = encoder(input_sequence)\n+start_tokens = start_token_generator(input_sequence)\n+output_sequene = sampler([start_tokens, state_h, state_c])\n+\n+\n+inference_model = Model(input_sequence, output_sequene)\n \n # Reverse-lookup token index to decode sequences back to\n # something readable.\n@@ -182,48 +219,30 @@\n \n \n def decode_sequence(input_seq):\n-    # Encode the input as state vectors.\n-    states_value = encoder_model.predict(input_seq)\n-\n-    # Generate empty target sequence of length 1.\n-    target_seq = np.zeros((1, 1, num_decoder_tokens))\n-    # Populate the first character of target sequence with the start character.\n-    target_seq[0, 0, target_token_index['\\t']] = 1.\n-\n-    # Sampling loop for a batch of sequences\n-    # (to simplify, here we assume a batch of size 1).\n-    stop_condition = False\n+    output_seq = inference_model.predict(input_seq)\n+    # to simplify, here we assume a batch of size 1.\n+    output_seq = output_seq[0]\n     decoded_sentence = ''\n-    while not stop_condition:\n-        output_tokens, h, c = decoder_model.predict(\n-            [target_seq] + states_value)\n-\n-        # Sample a token\n-        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n-        sampled_char = reverse_target_char_index[sampled_token_index]\n-        decoded_sentence += sampled_char\n-\n-        # Exit condition: either hit max length\n-        # or find stop character.\n-        if (sampled_char == '\\n' or\n-           len(decoded_sentence) > max_decoder_seq_length):\n-            stop_condition = True\n-\n-        # Update the target sequence (of length 1).\n-        target_seq = np.zeros((1, 1, num_decoder_tokens))\n-        target_seq[0, 0, sampled_token_index] = 1.\n-\n-        # Update states\n-        states_value = [h, c]\n-\n+    for x in output_seq:\n+        token_index = np.argmax(x)\n+        char = reverse_target_char_index[token_index]\n+        decoded_sentence += char\n+        if char == '\\n':\n+            break\n     return decoded_sentence\n \n+# Training set may contain multiple translations for same input.\n+unique_input_texts = dict()\n+for i, x in enumerate(input_texts):\n+    if x not in unique_input_texts:\n+        unique_input_texts[x] = i\n \n-for seq_index in range(100):\n+for text in list(unique_input_texts.keys())[:100]:\n     # Take one sequence (part of the training test)\n     # for trying out decoding.\n+    seq_index = unique_input_texts[text]\n     input_seq = encoder_input_data[seq_index: seq_index + 1]\n     decoded_sentence = decode_sequence(input_seq)\n     print('-')\n-    print('Input sentence:', input_texts[seq_index])\n+    print('Input sentence:', text)\n     print('Decoded sentence:', decoded_sentence)"
            }
        ],
        "diff": "diff --git a/examples/lstm_seq2seq.py b/examples/lstm_seq2seq.py\nindex cbb97b714e3..d1fe3abf1d5 100644\n--- a/examples/lstm_seq2seq.py\n+++ b/examples/lstm_seq2seq.py\n@@ -51,22 +51,30 @@\n from __future__ import print_function\n \n from keras.models import Model\n-from keras.layers import Input, LSTM, Dense\n+from keras.layers import Input, LSTM, Dense, Lambda\n+from keras import backend as K\n import numpy as np\n+import sys\n+\n+py3 = sys.version_info[0] == 3\n+\n \n batch_size = 64  # Batch size for training.\n epochs = 100  # Number of epochs to train for.\n latent_dim = 256  # Latent dimensionality of the encoding space.\n num_samples = 10000  # Number of samples to train on.\n # Path to the data txt file on disk.\n-data_path = '/Users/fchollet/Downloads/fra-eng/fra.txt'\n+data_path = '/Users/Fariz/Downloads/fra-eng/fra.txt'\n \n # Vectorize the data.\n input_texts = []\n target_texts = []\n input_characters = set()\n target_characters = set()\n-lines = open(data_path).read().split('\\n')\n+if py3:\n+    lines = open(data_path, encoding='utf8').read().split('\\n')\n+else:\n+    lines = open(data_path).read().split('\\n')\n for line in lines[: min(num_samples, len(lines) - 1)]:\n     input_text, target_text = line.split('\\t')\n     # We use \"tab\" as the \"start sequence\" character\n@@ -159,19 +167,48 @@\n # Output will be the next target token\n # 3) Repeat with the current target token and current states\n \n-# Define sampling models\n-encoder_model = Model(encoder_inputs, encoder_states)\n \n-decoder_state_input_h = Input(shape=(latent_dim,))\n-decoder_state_input_c = Input(shape=(latent_dim,))\n-decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n-decoder_outputs, state_h, state_c = decoder_lstm(\n-    decoder_inputs, initial_state=decoder_states_inputs)\n-decoder_states = [state_h, state_c]\n-decoder_outputs = decoder_dense(decoder_outputs)\n-decoder_model = Model(\n-    [decoder_inputs] + decoder_states_inputs,\n-    [decoder_outputs] + decoder_states)\n+def sample_loop(initial_states, output_length):\n+    # symbolic loop for sampling from the decoder\n+    zeros = K.zeros((1, output_length, 1))\n+\n+    def step(_, states):\n+        y_tm1, h_tm1, c_tm1 = states\n+        y_tm1._keras_shape = (None, 1, None)  # required for theano backend\n+        y, h, c = decoder_lstm.call([y_tm1, h_tm1, c_tm1])\n+        y = decoder_dense.call(y)\n+        # convert softmax to one hot\n+        mx = K.max(y, axis=2, keepdims=True)\n+        y_oh = K.cast(K.equal(y, mx), K.floatx())\n+        return y_oh[:, 0, :], [y_oh, h, c]\n+    return K.rnn(step, zeros, initial_states)[1]\n+\n+sampler = Lambda(sample_loop,\n+                 arguments={'output_length': max_decoder_seq_length},\n+                 output_shape=(max_decoder_seq_length, num_decoder_tokens))\n+\n+\n+def get_start_tokens(input_sequence, start_token_index, num_tokens):\n+    # returns a batch of one hots of the start token ('\\t')\n+    x = K.zeros_like(input_sequence[:, :1, 0])\n+    x += start_token_index\n+    x = K.cast(x, 'int32')\n+    return K.one_hot(x, num_tokens)  # (batch_size, 1, num_tokens)\n+\n+start_token_idx = target_token_index['\\t']\n+start_token_generator = Lambda(get_start_tokens,\n+                               arguments={'start_token_index': start_token_idx,\n+                                          'num_tokens': num_decoder_tokens},\n+                               output_shape=lambda s: (1, num_decoder_tokens))\n+\n+\n+input_sequence = Input(shape=(None, num_encoder_tokens))\n+_, state_h, state_c = encoder(input_sequence)\n+start_tokens = start_token_generator(input_sequence)\n+output_sequene = sampler([start_tokens, state_h, state_c])\n+\n+\n+inference_model = Model(input_sequence, output_sequene)\n \n # Reverse-lookup token index to decode sequences back to\n # something readable.\n@@ -182,48 +219,30 @@\n \n \n def decode_sequence(input_seq):\n-    # Encode the input as state vectors.\n-    states_value = encoder_model.predict(input_seq)\n-\n-    # Generate empty target sequence of length 1.\n-    target_seq = np.zeros((1, 1, num_decoder_tokens))\n-    # Populate the first character of target sequence with the start character.\n-    target_seq[0, 0, target_token_index['\\t']] = 1.\n-\n-    # Sampling loop for a batch of sequences\n-    # (to simplify, here we assume a batch of size 1).\n-    stop_condition = False\n+    output_seq = inference_model.predict(input_seq)\n+    # to simplify, here we assume a batch of size 1.\n+    output_seq = output_seq[0]\n     decoded_sentence = ''\n-    while not stop_condition:\n-        output_tokens, h, c = decoder_model.predict(\n-            [target_seq] + states_value)\n-\n-        # Sample a token\n-        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n-        sampled_char = reverse_target_char_index[sampled_token_index]\n-        decoded_sentence += sampled_char\n-\n-        # Exit condition: either hit max length\n-        # or find stop character.\n-        if (sampled_char == '\\n' or\n-           len(decoded_sentence) > max_decoder_seq_length):\n-            stop_condition = True\n-\n-        # Update the target sequence (of length 1).\n-        target_seq = np.zeros((1, 1, num_decoder_tokens))\n-        target_seq[0, 0, sampled_token_index] = 1.\n-\n-        # Update states\n-        states_value = [h, c]\n-\n+    for x in output_seq:\n+        token_index = np.argmax(x)\n+        char = reverse_target_char_index[token_index]\n+        decoded_sentence += char\n+        if char == '\\n':\n+            break\n     return decoded_sentence\n \n+# Training set may contain multiple translations for same input.\n+unique_input_texts = dict()\n+for i, x in enumerate(input_texts):\n+    if x not in unique_input_texts:\n+        unique_input_texts[x] = i\n \n-for seq_index in range(100):\n+for text in list(unique_input_texts.keys())[:100]:\n     # Take one sequence (part of the training test)\n     # for trying out decoding.\n+    seq_index = unique_input_texts[text]\n     input_seq = encoder_input_data[seq_index: seq_index + 1]\n     decoded_sentence = decode_sequence(input_seq)\n     print('-')\n-    print('Input sentence:', input_texts[seq_index])\n+    print('Input sentence:', text)\n     print('Decoded sentence:', decoded_sentence)\n",
        "reviews": [],
        "comments": [
            {
                "commenter": "fchollet",
                "body": "This is interesting, but also a lot more involved than the original version. In particular it leverages features than aren't quite private but aren't really to be found in regular use cases, like `K.rnn` or `layer.call`. Part of the goal of the example is too show that s2s in Keras is *simple*, and I think this looks rather complicated.\r\n\r\nAt the same time, it's good to make it available for reference. Make as a comment or something?"
            },
            {
                "commenter": "farizrahman4u",
                "body": "Couple of advantages of using symbolic loop:\r\n\r\n* Faster prediction when batch size > 1\r\n*  `decode_sequence` method is now simpler, since we have a single \"end to end\" inference model.\r\n\r\nWhat do you mean by make as a comment? Please elaborate. "
            },
            {
                "commenter": "fchollet",
                "body": "> What do you mean by make as a comment? Please elaborate.\r\n\r\nSorry, I meant: could we make this available as a comment? Ideally, we would add it as an alternative code snippet in the associated tutorial on the Keras blog, together with some explanations of what it does.\r\n\r\nThe primary reason for not merging it here is that it involves niche features (which I generally wouldn't recommend using other than as a workaround) and isn't as straightforward as the base version -- our goal is to make examples as simple and obvious as possible, possibly at the cost of performance."
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 17142,
        "body": "Revision of #17052 , adapted from code by @foxik \r\n\r\n@rchao It turns out that all the logging checks in the previous version were unnecessary, since `_push_writer()` already sets a writer that logs at the rate set by update_freq. Can you take a look to see if this version also has performance problems with asynchronous strategies?",
        "changed_files": [
            {
                "filename": "keras/callbacks.py",
                "patch": "@@ -1,4 +1,3 @@\n-# flake8: noqa\n # Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -2350,12 +2349,16 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n         write_steps_per_second: whether to log the training steps per second\n           into Tensorboard. This supports both epoch and batch frequency\n           logging.\n-        update_freq: **disabled**\n-\n-          Warning: Batch-level summary writing using `update_freq` is\n-          currently unsupported. A suggested workaround is shown in the\n-          [TensorBoard Scalars tutorial](https://www.tensorflow.org/tensorboard/scalars_and_keras#batch-level_logging). # pylint: disable=protected-access\n-\n+        update_freq: `'batch'` or `'epoch'` or integer. When using `'epoch'`,\n+          writes the losses and metrics to TensorBoard after every epoch.\n+          If using an integer, let's say `1000`, all metrics and losses\n+          (including custom ones added by `Model.compile`) will be logged to\n+          TensorBoard every 1000 batches. `'batch'` is a synonym for `1`,\n+          meaning that they will be written every batch.\n+          Note however that writing too frequently to TensorBoard can slow down\n+          your training, especially when used with `tf.distribute.Strategy` as\n+          it will incur additional synchronization overhead.\n+          Use with `ParameterServerStrategy` is not supported.\n         profile_batch: Profile the batch(es) to sample compute characteristics.\n           profile_batch must be a non-negative integer or a tuple of integers.\n           A pair of positive integers signify a range of batches to profile.\n@@ -2377,6 +2380,48 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n     # Then run the tensorboard command to view the visualizations.\n     ```\n \n+    Custom batch-level summaries in a subclassed Model:\n+\n+    ```python\n+    class MyModel(tf.keras.Model):\n+\n+      def build(self, _):\n+        self.dense = tf.keras.layers.Dense(10)\n+\n+      def call(self, x):\n+        outputs = self.dense(x)\n+        tf.summary.histogram('outputs', outputs)\n+        return outputs\n+\n+    model = MyModel()\n+    model.compile('sgd', 'mse')\n+\n+    # Make sure to set `update_freq=N` to log a batch-level summary every N\n+    # batches.  In addition to any `tf.summary` contained in `Model.call`,\n+    # metrics added in `Model.compile` will be logged every N batches.\n+    tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n+    model.fit(x_train, y_train, callbacks=[tb_callback])\n+    ```\n+\n+    Custom batch-level summaries in a Functional API Model:\n+\n+    ```python\n+    def my_summary(x):\n+      tf.summary.histogram('x', x)\n+      return x\n+\n+    inputs = tf.keras.Input(10)\n+    x = tf.keras.layers.Dense(10)(inputs)\n+    outputs = tf.keras.layers.Lambda(my_summary)(x)\n+    model = tf.keras.Model(inputs, outputs)\n+    model.compile('sgd', 'mse')\n+\n+    # Make sure to set `update_freq=N` to log a batch-level summary every N\n+    # batches. In addition to any `tf.summary` contained in `Model.call`,\n+    # metrics added in `Model.compile` will be logged every N batches.\n+    tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n+    model.fit(x_train, y_train, callbacks=[tb_callback])\n+    ```\n \n     Profiling:\n \n@@ -2733,6 +2778,15 @@ def on_train_batch_end(self, batch, logs=None):\n                 1.0 / batch_run_time,\n                 step=self._train_step,\n             )\n+\n+        # `logs` isn't necessarily always a dict. For example, when using\n+        # `tf.distribute.experimental.ParameterServerStrategy`, a\n+        # `tf.distribute.experimental.coordinator.RemoteValue` will be passed.\n+        # For now, we just disable `update_freq` in those cases.\n+        if isinstance(logs, dict):\n+            for name, value in logs.items():\n+                tf.summary.scalar(\"batch_\" + name, value, step=self._train_step)\n+\n         if not self._should_trace:\n             return\n "
            },
            {
                "filename": "keras/callbacks_test.py",
                "patch": "@@ -3038,6 +3038,7 @@ def test_TensorBoard_batch_metrics(self):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(logdir=self.validation_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(\n@@ -3100,6 +3101,7 @@ def test_TensorBoard_global_step(self):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(\n                     logdir=self.train_dir, tag=\"epoch_learning_rate\"\n@@ -3285,6 +3287,7 @@ def call(self, x):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(logdir=self.validation_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary("
            },
            {
                "filename": "keras/integration_test/distributed_training_test.py",
                "patch": "@@ -17,6 +17,9 @@\n from __future__ import division\n from __future__ import print_function\n \n+import glob\n+import os\n+\n import tensorflow.compat.v2 as tf\n \n ds_combinations = tf.__internal__.distribute.combinations\n@@ -73,11 +76,53 @@ def dataset_fn(input_context):\n         with strategy.scope():\n             model = tf.keras.Sequential([tf.keras.layers.Dense(10)])\n             optimizer = tf.keras.optimizers.SGD()\n-            model.compile(optimizer, loss=\"mse\", steps_per_execution=10)\n+            model.compile(optimizer, loss=\"mse\", steps_per_execution=5)\n \n         x = tf.keras.utils.experimental.DatasetCreator(dataset_fn)\n \n-        model.fit(x, epochs=2, steps_per_epoch=10)\n+        logdir = os.path.join(self.get_temp_dir(), \"logdir\")\n+        model.fit(\n+            x,\n+            epochs=2,\n+            steps_per_epoch=20,\n+            callbacks=[\n+                tf.keras.callbacks.TensorBoard(\n+                    logdir,\n+                    update_freq=5,\n+                    write_steps_per_second=True,\n+                )\n+            ],\n+        )\n+\n+        events_got = []\n+        for event_file in glob.glob(logdir + \"/train/events.out.*\"):\n+            for event in tf.compat.v1.train.summary_iterator(event_file):\n+                if not event.summary:\n+                    continue\n+                for value in event.summary.value:\n+                    if value.tag != \"batch_loss\":\n+                        continue\n+                    events_got += [event.step]\n+\n+        # total steps = epochs * steps_per_epoch\n+        events_expected = [5, 10, 15, 20, 25, 30, 35, 40]\n+\n+        if isinstance(\n+            strategy, tf.distribute.experimental.ParameterServerStrategy\n+        ):\n+            # Metrics are not logged with this strategy as they are not\n+            # immediately available on batch end\n+            events_expected = []\n+        if (\n+            strategy.cluster_resolver\n+            and strategy.cluster_resolver.task_type == \"worker\"\n+        ):\n+            # The below assertion is run by both chief and workers when using\n+            # `tf.distribute.MultiWorkerMirroredStrategy`, but only the chief\n+            # will log events.\n+            events_expected = []\n+\n+        self.assertEqual(events_got, events_expected)\n \n \n if __name__ == \"__main__\":"
            }
        ],
        "diff": "diff --git a/keras/callbacks.py b/keras/callbacks.py\nindex 2eafd111ad3..5644281ae33 100644\n--- a/keras/callbacks.py\n+++ b/keras/callbacks.py\n@@ -1,4 +1,3 @@\n-# flake8: noqa\n # Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n #\n # Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -2350,12 +2349,16 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n         write_steps_per_second: whether to log the training steps per second\n           into Tensorboard. This supports both epoch and batch frequency\n           logging.\n-        update_freq: **disabled**\n-\n-          Warning: Batch-level summary writing using `update_freq` is\n-          currently unsupported. A suggested workaround is shown in the\n-          [TensorBoard Scalars tutorial](https://www.tensorflow.org/tensorboard/scalars_and_keras#batch-level_logging). # pylint: disable=protected-access\n-\n+        update_freq: `'batch'` or `'epoch'` or integer. When using `'epoch'`,\n+          writes the losses and metrics to TensorBoard after every epoch.\n+          If using an integer, let's say `1000`, all metrics and losses\n+          (including custom ones added by `Model.compile`) will be logged to\n+          TensorBoard every 1000 batches. `'batch'` is a synonym for `1`,\n+          meaning that they will be written every batch.\n+          Note however that writing too frequently to TensorBoard can slow down\n+          your training, especially when used with `tf.distribute.Strategy` as\n+          it will incur additional synchronization overhead.\n+          Use with `ParameterServerStrategy` is not supported.\n         profile_batch: Profile the batch(es) to sample compute characteristics.\n           profile_batch must be a non-negative integer or a tuple of integers.\n           A pair of positive integers signify a range of batches to profile.\n@@ -2377,6 +2380,48 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n     # Then run the tensorboard command to view the visualizations.\n     ```\n \n+    Custom batch-level summaries in a subclassed Model:\n+\n+    ```python\n+    class MyModel(tf.keras.Model):\n+\n+      def build(self, _):\n+        self.dense = tf.keras.layers.Dense(10)\n+\n+      def call(self, x):\n+        outputs = self.dense(x)\n+        tf.summary.histogram('outputs', outputs)\n+        return outputs\n+\n+    model = MyModel()\n+    model.compile('sgd', 'mse')\n+\n+    # Make sure to set `update_freq=N` to log a batch-level summary every N\n+    # batches.  In addition to any `tf.summary` contained in `Model.call`,\n+    # metrics added in `Model.compile` will be logged every N batches.\n+    tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n+    model.fit(x_train, y_train, callbacks=[tb_callback])\n+    ```\n+\n+    Custom batch-level summaries in a Functional API Model:\n+\n+    ```python\n+    def my_summary(x):\n+      tf.summary.histogram('x', x)\n+      return x\n+\n+    inputs = tf.keras.Input(10)\n+    x = tf.keras.layers.Dense(10)(inputs)\n+    outputs = tf.keras.layers.Lambda(my_summary)(x)\n+    model = tf.keras.Model(inputs, outputs)\n+    model.compile('sgd', 'mse')\n+\n+    # Make sure to set `update_freq=N` to log a batch-level summary every N\n+    # batches. In addition to any `tf.summary` contained in `Model.call`,\n+    # metrics added in `Model.compile` will be logged every N batches.\n+    tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n+    model.fit(x_train, y_train, callbacks=[tb_callback])\n+    ```\n \n     Profiling:\n \n@@ -2733,6 +2778,15 @@ def on_train_batch_end(self, batch, logs=None):\n                 1.0 / batch_run_time,\n                 step=self._train_step,\n             )\n+\n+        # `logs` isn't necessarily always a dict. For example, when using\n+        # `tf.distribute.experimental.ParameterServerStrategy`, a\n+        # `tf.distribute.experimental.coordinator.RemoteValue` will be passed.\n+        # For now, we just disable `update_freq` in those cases.\n+        if isinstance(logs, dict):\n+            for name, value in logs.items():\n+                tf.summary.scalar(\"batch_\" + name, value, step=self._train_step)\n+\n         if not self._should_trace:\n             return\n \ndiff --git a/keras/callbacks_test.py b/keras/callbacks_test.py\nindex 899128002a4..0f02da89ebb 100644\n--- a/keras/callbacks_test.py\n+++ b/keras/callbacks_test.py\n@@ -3038,6 +3038,7 @@ def test_TensorBoard_batch_metrics(self):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(logdir=self.validation_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(\n@@ -3100,6 +3101,7 @@ def test_TensorBoard_global_step(self):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(\n                     logdir=self.train_dir, tag=\"epoch_learning_rate\"\n@@ -3285,6 +3287,7 @@ def call(self, x):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(logdir=self.validation_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(\ndiff --git a/keras/integration_test/distributed_training_test.py b/keras/integration_test/distributed_training_test.py\nindex 69510f233f6..8865ee2eb5a 100644\n--- a/keras/integration_test/distributed_training_test.py\n+++ b/keras/integration_test/distributed_training_test.py\n@@ -17,6 +17,9 @@\n from __future__ import division\n from __future__ import print_function\n \n+import glob\n+import os\n+\n import tensorflow.compat.v2 as tf\n \n ds_combinations = tf.__internal__.distribute.combinations\n@@ -73,11 +76,53 @@ def dataset_fn(input_context):\n         with strategy.scope():\n             model = tf.keras.Sequential([tf.keras.layers.Dense(10)])\n             optimizer = tf.keras.optimizers.SGD()\n-            model.compile(optimizer, loss=\"mse\", steps_per_execution=10)\n+            model.compile(optimizer, loss=\"mse\", steps_per_execution=5)\n \n         x = tf.keras.utils.experimental.DatasetCreator(dataset_fn)\n \n-        model.fit(x, epochs=2, steps_per_epoch=10)\n+        logdir = os.path.join(self.get_temp_dir(), \"logdir\")\n+        model.fit(\n+            x,\n+            epochs=2,\n+            steps_per_epoch=20,\n+            callbacks=[\n+                tf.keras.callbacks.TensorBoard(\n+                    logdir,\n+                    update_freq=5,\n+                    write_steps_per_second=True,\n+                )\n+            ],\n+        )\n+\n+        events_got = []\n+        for event_file in glob.glob(logdir + \"/train/events.out.*\"):\n+            for event in tf.compat.v1.train.summary_iterator(event_file):\n+                if not event.summary:\n+                    continue\n+                for value in event.summary.value:\n+                    if value.tag != \"batch_loss\":\n+                        continue\n+                    events_got += [event.step]\n+\n+        # total steps = epochs * steps_per_epoch\n+        events_expected = [5, 10, 15, 20, 25, 30, 35, 40]\n+\n+        if isinstance(\n+            strategy, tf.distribute.experimental.ParameterServerStrategy\n+        ):\n+            # Metrics are not logged with this strategy as they are not\n+            # immediately available on batch end\n+            events_expected = []\n+        if (\n+            strategy.cluster_resolver\n+            and strategy.cluster_resolver.task_type == \"worker\"\n+        ):\n+            # The below assertion is run by both chief and workers when using\n+            # `tf.distribute.MultiWorkerMirroredStrategy`, but only the chief\n+            # will log events.\n+            events_expected = []\n+\n+        self.assertEqual(events_got, events_expected)\n \n \n if __name__ == \"__main__\":\n",
        "reviews": [
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "myaaaaaaaaa",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "myaaaaaaaaa",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "Thanks! I think it's reasonable to only log the batch level metrics when they are readily available. Can you also update the docstring for TensorBoard to accompany this change as well?"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "Thanks! There are still a couple of things we need to be extra careful about. See the comments for more details."
            },
            {
                "reviewer": "myaaaaaaaaa",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "myaaaaaaaaa",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "myaaaaaaaaa",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "myaaaaaaaaa",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "myaaaaaaaaa",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "Thanks!"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "myaaaaaaaaa",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "rchao",
                "state": "APPROVED",
                "body": "No comment"
            }
        ],
        "comments": [
            {
                "commenter": "myaaaaaaaaa",
                "body": "I've managed to work around my bazel problems and add a basic integration test. `update_freq` should now be disabled when used with asynchronous strategies instead of throwing an error, is this acceptable?"
            },
            {
                "commenter": "myaaaaaaaaa",
                "body": "All done!"
            },
            {
                "commenter": "myaaaaaaaaa",
                "body": "All done"
            },
            {
                "commenter": "rchao",
                "body": "> All done\r\n\r\nThanks! Almost there. Just a couple of last quick things."
            },
            {
                "commenter": "myaaaaaaaaa",
                "body": "All done"
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 17170,
        "body": "Changed .format to f-string for better readability and performance as per PEP 498",
        "changed_files": [
            {
                "filename": "keras/layers/preprocessing/image_preprocessing.py",
                "patch": "@@ -42,13 +42,13 @@\n def check_fill_mode_and_interpolation(fill_mode, interpolation):\n     if fill_mode not in {\"reflect\", \"wrap\", \"constant\", \"nearest\"}:\n         raise NotImplementedError(\n-            \"Unknown `fill_mode` {}. Only `reflect`, `wrap`, \"\n-            \"`constant` and `nearest` are supported.\".format(fill_mode)\n+            f\"Unknown `fill_mode` {fill_mode}. Only `reflect`, `wrap`, \"\n+            \"`constant` and `nearest` are supported.\"\n         )\n     if interpolation not in {\"nearest\", \"bilinear\"}:\n         raise NotImplementedError(\n-            \"Unknown `interpolation` {}. Only `nearest` and \"\n-            \"`bilinear` are supported.\".format(interpolation)\n+            f\"Unknown `interpolation` {interpolation}. Only `nearest` and \"\n+            \"`bilinear` are supported.\"\n         )\n \n \n@@ -744,8 +744,8 @@ def __init__(self, mode=HORIZONTAL_AND_VERTICAL, seed=None, **kwargs):\n             self.vertical = True\n         else:\n             raise ValueError(\n-                \"RandomFlip layer {name} received an unknown mode \"\n-                \"argument {arg}\".format(name=self.name, arg=mode)\n+                f\"RandomFlip layer {self.name} received an unknown mode \"\n+                f\"argument {mode}\"\n             )\n         self.auto_vectorize = False\n \n@@ -871,12 +871,12 @@ def __init__(\n         if self.height_upper < self.height_lower:\n             raise ValueError(\n                 \"`height_factor` cannot have upper bound less than \"\n-                \"lower bound, got {}\".format(height_factor)\n+                f\"lower bound, got {height_factor}\"\n             )\n         if abs(self.height_lower) > 1.0 or abs(self.height_upper) > 1.0:\n             raise ValueError(\n                 \"`height_factor` must have values between [-1, 1], \"\n-                \"got {}\".format(height_factor)\n+                f\"got {height_factor}\"\n             )\n \n         self.width_factor = width_factor\n@@ -889,12 +889,12 @@ def __init__(\n         if self.width_upper < self.width_lower:\n             raise ValueError(\n                 \"`width_factor` cannot have upper bound less than \"\n-                \"lower bound, got {}\".format(width_factor)\n+                f\"lower bound, got {width_factor}\"\n             )\n         if abs(self.width_lower) > 1.0 or abs(self.width_upper) > 1.0:\n             raise ValueError(\n                 \"`width_factor` must have values between [-1, 1], \"\n-                \"got {}\".format(width_factor)\n+                f\"got {width_factor}\"\n             )\n \n         check_fill_mode_and_interpolation(fill_mode, interpolation)\n@@ -1096,7 +1096,7 @@ def transform(\n             raise ValueError(\n                 \"output_shape must be a 1-D Tensor of 2 elements: \"\n                 \"new_height, new_width, instead got \"\n-                \"{}\".format(output_shape)\n+                f\"{output_shape}\"\n             )\n \n         fill_value = tf.convert_to_tensor(\n@@ -1388,7 +1388,7 @@ def __init__(\n         if abs(self.height_lower) > 1.0 or abs(self.height_upper) > 1.0:\n             raise ValueError(\n                 \"`height_factor` must have values between [-1, 1], \"\n-                \"got {}\".format(height_factor)\n+                f\"got {height_factor}\"\n             )\n \n         self.width_factor = width_factor\n@@ -1403,7 +1403,7 @@ def __init__(\n             if self.width_lower < -1.0 or self.width_upper < -1.0:\n                 raise ValueError(\n                     \"`width_factor` must have values larger than -1, \"\n-                    \"got {}\".format(width_factor)\n+                    f\"got {width_factor}\"\n                 )\n \n         check_fill_mode_and_interpolation(fill_mode, interpolation)\n@@ -1573,7 +1573,7 @@ def __init__(self, factor, seed=None, **kwargs):\n         if self.lower < 0.0 or self.upper < 0.0 or self.lower > 1.0:\n             raise ValueError(\n                 \"Factor cannot have negative values or greater than 1.0,\"\n-                \" got {}\".format(factor)\n+                f\" got {factor}\"\n             )\n         self.seed = seed\n \n@@ -1824,7 +1824,7 @@ def __init__(self, factor, interpolation=\"bilinear\", seed=None, **kwargs):\n         if self.height_upper < self.height_lower:\n             raise ValueError(\n                 \"`factor` cannot have upper bound less than \"\n-                \"lower bound, got {}\".format(factor)\n+                f\"lower bound, got {factor}\"\n             )\n         if self.height_lower < -1.0 or self.height_upper < -1.0:\n             raise ValueError(\n@@ -1947,7 +1947,7 @@ def __init__(self, factor, interpolation=\"bilinear\", seed=None, **kwargs):\n         if self.width_upper < self.width_lower:\n             raise ValueError(\n                 \"`factor` cannot have upper bound less than \"\n-                \"lower bound, got {}\".format(factor)\n+                f\"lower bound, got {factor}\"\n             )\n         if self.width_lower < -1.0 or self.width_upper < -1.0:\n             raise ValueError("
            }
        ],
        "diff": "diff --git a/keras/layers/preprocessing/image_preprocessing.py b/keras/layers/preprocessing/image_preprocessing.py\nindex e4e33f3b3cb..6d1803a8adb 100644\n--- a/keras/layers/preprocessing/image_preprocessing.py\n+++ b/keras/layers/preprocessing/image_preprocessing.py\n@@ -42,13 +42,13 @@\n def check_fill_mode_and_interpolation(fill_mode, interpolation):\n     if fill_mode not in {\"reflect\", \"wrap\", \"constant\", \"nearest\"}:\n         raise NotImplementedError(\n-            \"Unknown `fill_mode` {}. Only `reflect`, `wrap`, \"\n-            \"`constant` and `nearest` are supported.\".format(fill_mode)\n+            f\"Unknown `fill_mode` {fill_mode}. Only `reflect`, `wrap`, \"\n+            \"`constant` and `nearest` are supported.\"\n         )\n     if interpolation not in {\"nearest\", \"bilinear\"}:\n         raise NotImplementedError(\n-            \"Unknown `interpolation` {}. Only `nearest` and \"\n-            \"`bilinear` are supported.\".format(interpolation)\n+            f\"Unknown `interpolation` {interpolation}. Only `nearest` and \"\n+            \"`bilinear` are supported.\"\n         )\n \n \n@@ -744,8 +744,8 @@ def __init__(self, mode=HORIZONTAL_AND_VERTICAL, seed=None, **kwargs):\n             self.vertical = True\n         else:\n             raise ValueError(\n-                \"RandomFlip layer {name} received an unknown mode \"\n-                \"argument {arg}\".format(name=self.name, arg=mode)\n+                f\"RandomFlip layer {self.name} received an unknown mode \"\n+                f\"argument {mode}\"\n             )\n         self.auto_vectorize = False\n \n@@ -871,12 +871,12 @@ def __init__(\n         if self.height_upper < self.height_lower:\n             raise ValueError(\n                 \"`height_factor` cannot have upper bound less than \"\n-                \"lower bound, got {}\".format(height_factor)\n+                f\"lower bound, got {height_factor}\"\n             )\n         if abs(self.height_lower) > 1.0 or abs(self.height_upper) > 1.0:\n             raise ValueError(\n                 \"`height_factor` must have values between [-1, 1], \"\n-                \"got {}\".format(height_factor)\n+                f\"got {height_factor}\"\n             )\n \n         self.width_factor = width_factor\n@@ -889,12 +889,12 @@ def __init__(\n         if self.width_upper < self.width_lower:\n             raise ValueError(\n                 \"`width_factor` cannot have upper bound less than \"\n-                \"lower bound, got {}\".format(width_factor)\n+                f\"lower bound, got {width_factor}\"\n             )\n         if abs(self.width_lower) > 1.0 or abs(self.width_upper) > 1.0:\n             raise ValueError(\n                 \"`width_factor` must have values between [-1, 1], \"\n-                \"got {}\".format(width_factor)\n+                f\"got {width_factor}\"\n             )\n \n         check_fill_mode_and_interpolation(fill_mode, interpolation)\n@@ -1096,7 +1096,7 @@ def transform(\n             raise ValueError(\n                 \"output_shape must be a 1-D Tensor of 2 elements: \"\n                 \"new_height, new_width, instead got \"\n-                \"{}\".format(output_shape)\n+                f\"{output_shape}\"\n             )\n \n         fill_value = tf.convert_to_tensor(\n@@ -1388,7 +1388,7 @@ def __init__(\n         if abs(self.height_lower) > 1.0 or abs(self.height_upper) > 1.0:\n             raise ValueError(\n                 \"`height_factor` must have values between [-1, 1], \"\n-                \"got {}\".format(height_factor)\n+                f\"got {height_factor}\"\n             )\n \n         self.width_factor = width_factor\n@@ -1403,7 +1403,7 @@ def __init__(\n             if self.width_lower < -1.0 or self.width_upper < -1.0:\n                 raise ValueError(\n                     \"`width_factor` must have values larger than -1, \"\n-                    \"got {}\".format(width_factor)\n+                    f\"got {width_factor}\"\n                 )\n \n         check_fill_mode_and_interpolation(fill_mode, interpolation)\n@@ -1573,7 +1573,7 @@ def __init__(self, factor, seed=None, **kwargs):\n         if self.lower < 0.0 or self.upper < 0.0 or self.lower > 1.0:\n             raise ValueError(\n                 \"Factor cannot have negative values or greater than 1.0,\"\n-                \" got {}\".format(factor)\n+                f\" got {factor}\"\n             )\n         self.seed = seed\n \n@@ -1824,7 +1824,7 @@ def __init__(self, factor, interpolation=\"bilinear\", seed=None, **kwargs):\n         if self.height_upper < self.height_lower:\n             raise ValueError(\n                 \"`factor` cannot have upper bound less than \"\n-                \"lower bound, got {}\".format(factor)\n+                f\"lower bound, got {factor}\"\n             )\n         if self.height_lower < -1.0 or self.height_upper < -1.0:\n             raise ValueError(\n@@ -1947,7 +1947,7 @@ def __init__(self, factor, interpolation=\"bilinear\", seed=None, **kwargs):\n         if self.width_upper < self.width_lower:\n             raise ValueError(\n                 \"`factor` cannot have upper bound less than \"\n-                \"lower bound, got {}\".format(factor)\n+                f\"lower bound, got {factor}\"\n             )\n         if self.width_lower < -1.0 or self.width_upper < -1.0:\n             raise ValueError(\n",
        "reviews": [
            {
                "reviewer": "fchollet",
                "state": "APPROVED",
                "body": "LGTM"
            }
        ],
        "comments": []
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 16712,
        "body": "Fix #6118\r\nFix #5911\r\nRelates to #16513\r\n\r\n#### Summary\r\n* Add the `ignore_class: Optional[int]` parameter to the following functions/constructors:\r\n  - `backend.sparse_categorical_crossentropy`\r\n  - `lossses.sparse_categorical_crossentropy`\r\n  - `metrics.SparseCategoricalCrossentropy`\r\n  - `metrics._IoUBase`\r\n  - `metrics.IoU`\r\n  - `metrics.MeanIoU`\r\n  - `metrics.OneHotIoU`\r\n  - `metrics.OneHotMeanIoU`\r\n* Add `sparse_y_true: bool` and `sparse_y_pred: bool` parameters in `_IoUBase`, `IoU`, `MeanIoU` metric classes.\r\n* Add `sparse_y_pred:bool` to the `OneHotIoU` and `OneHotMeanIoU` metric classes and refactor these classes to reuse more of the base class.\r\n* Refactor: A replicated code section shared among `backend.categorical_crossentropy`, `backend.sparse_categorical_crossentropy`, and `backend.binary_crossentropy` into a single function named `_get_logits`.\r\n\r\n#### Goals\r\n1. **ignore_class**: In segmentation problems, some pixels in segmentation maps might not represent valid categorical labels. Examples:\r\n   - object boundaries are marked with void category, as the annotators disagree on which label to attribute\r\n   - small maps are padded with the *void* class to conform with the sizes of larger ones after `Dataset#padded_batch`\r\n   - specific objects out of the context of the problem, such as the hood of a car being captured by a static camera\r\n   - pseudo-labels (originated from weakly supervised strategies) might contain pixels/regions where label is uncertain\r\n\r\n   It's common to attribute the label `-1` or `255` and ignore these pixels during training. This PR implements this feature by masking the target and the output signals, only computing the metrics over the valid pixels. Moreover, it mirrors PyTorch's [CrossEntropyLoss(ignore_index=-100)](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\r\n\r\n2. **sparse_y_pred**: `IoU` and `MeanIoU` assumes both `target` and `output` are sparse signals, where categories are represented as natural integers. Conversely, `OneHotIoU` and `OneHotMeanIoU` assume both are probability distribution vectors. This is far from what I believe to be the most obvious case: sparse segmentation labels and dense output vectors:\r\n   ```py\r\n   >>> classes = 20\r\n   >>> model = Sequential([\r\n   >>>    ResNet50V2(input_shape=[512, 512, 3], include_top=False, pooling=None, weights=None),\r\n   >>>    Conv2D(classes, kernel_size=1, activation='softmax', name='predictions')\r\n   >>> ])\r\n   >>> print(model.output.shape)\r\n   (None, 16, 16, 20)\r\n   ```\r\n\r\n   So now IoU can be easily used as this:\r\n   ```py\r\n   model.compile(opt='sgd', loss='sparse_categorical_crossentropy', metrics=[\r\n     MeanIoU(classes, sparse_y_pred=False, ignore_index=-1)\r\n   ])\r\n   ```\r\n\r\n#### Limitations\r\n~Currently, `backend.sparse_categorical_crossentropy` only reduces the dimension containing the logits, and the result is reshaped into the original output shape (except for the last axis) if the information is available.\r\nHowever, when a pixel is not valid, its associated cross-entropy value is not available and reshape cannot occur without creating a ragged tensor. Therefore, when `ignore_index is not None` (and only then), I opted to sum all cross-entropy values over the axes `range(1, output_rank-1)` and divide by the number of valid pixels (similar to what pytorch does). In this case, the output tensor will have `shape=[output_shape[0]]=[batch_size]`. An alternative would be to return a flatten array containing only valid entries, though the batch information would be lost and the user would have difficulties if they had per-sample operations being applied to these loss values.~\r\n\r\nNo visible limitations now. `backend.sparse_categorical_crossentropy` will set the `_keras_mask` property in the loss Tensor, which will be used during the reduction procedure to mask out invalid pixels.",
        "changed_files": [
            {
                "filename": "keras/backend.py",
                "patch": "@@ -5440,6 +5440,41 @@ def softsign(x):\n     return tf.math.softsign(x)\n \n \n+def _get_logits(output, from_logits, op_type, fn_name):\n+    output_ = output\n+    from_logits_ = from_logits\n+\n+    has_keras_logits = hasattr(output, \"_keras_logits\")\n+    if has_keras_logits:\n+        output_ = output._keras_logits\n+        from_logits_ = True\n+\n+    from_expected_op_type = (\n+        not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable))\n+        and output.op.type == op_type\n+    ) and not has_keras_logits\n+\n+    if from_expected_op_type:\n+        # When softmax activation function is used for output operation, we\n+        # use logits from the softmax function directly to compute loss in order\n+        # to prevent collapsing zero when training.\n+        # See b/117284466\n+        assert len(output.op.inputs) == 1\n+        output_ = output.op.inputs[0]\n+        from_logits_ = True\n+\n+    if from_logits and (has_keras_logits or from_expected_op_type):\n+        warnings.warn(\n+            f'\"`{fn_name}` received `from_logits=True`, but '\n+            f\"the `output` argument was produced by a {op_type} \"\n+            \"activation and thus does not represent logits. \"\n+            \"Was this intended?\",\n+            stacklevel=2,\n+        )\n+\n+    return output_, from_logits_\n+\n+\n @keras_export(\"keras.backend.categorical_crossentropy\")\n @tf.__internal__.dispatch.add_dispatch_support\n @doc_controls.do_not_generate_docs\n@@ -5490,39 +5525,14 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n     output = tf.convert_to_tensor(output)\n     target.shape.assert_is_compatible_with(output.shape)\n \n-    # Use logits whenever they are available. `softmax` and `sigmoid`\n-    # activations cache logits on the `output` Tensor.\n-    if hasattr(output, \"_keras_logits\"):\n-        output = output._keras_logits\n-        if from_logits:\n-            warnings.warn(\n-                '\"`categorical_crossentropy` received `from_logits=True`, but '\n-                \"the `output` argument was produced by a sigmoid or softmax \"\n-                \"activation and thus does not represent logits. \"\n-                \"Was this intended?\",\n-                stacklevel=2,\n-            )\n-        from_logits = True\n-\n+    output, from_logits = _get_logits(\n+        output, from_logits, \"Softmax\", \"categorical_crossentropy\"\n+    )\n     if from_logits:\n         return tf.nn.softmax_cross_entropy_with_logits(\n             labels=target, logits=output, axis=axis\n         )\n \n-    if (\n-        not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable))\n-        and output.op.type == \"Softmax\"\n-    ) and not hasattr(output, \"_keras_history\"):\n-        # When softmax activation function is used for output operation, we\n-        # use logits from the softmax function directly to compute loss in order\n-        # to prevent collapsing zero when training.\n-        # See b/117284466\n-        assert len(output.op.inputs) == 1\n-        output = output.op.inputs[0]\n-        return tf.nn.softmax_cross_entropy_with_logits(\n-            labels=target, logits=output, axis=axis\n-        )\n-\n     # scale preds so that the class probas of each sample sum to 1\n     output = output / tf.reduce_sum(output, axis, True)\n     # Compute cross entropy from probabilities.\n@@ -5534,7 +5544,9 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n @keras_export(\"keras.backend.sparse_categorical_crossentropy\")\n @tf.__internal__.dispatch.add_dispatch_support\n @doc_controls.do_not_generate_docs\n-def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n+def sparse_categorical_crossentropy(\n+    target, output, from_logits=False, axis=-1, ignore_class=None\n+):\n     \"\"\"Categorical crossentropy with integer targets.\n \n     Args:\n@@ -5547,6 +5559,11 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n         axis: Int specifying the channels axis. `axis=-1` corresponds to data\n             format `channels_last`, and `axis=1` corresponds to data format\n             `channels_first`.\n+        ignore_class: Optional integer. The ID of a class to be ignored\n+            during loss computation. This is useful, for example, in\n+            segmentation problems featuring a \"void\" class (commonly -1\n+            or 255) in segmentation maps.\n+            By default (`ignore_class=None`), all classes are considered.\n \n     Returns:\n         Output tensor.\n@@ -5557,36 +5574,17 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n     target = tf.convert_to_tensor(target)\n     output = tf.convert_to_tensor(output)\n \n-    # Use logits whenever they are available. `softmax` and `sigmoid`\n-    # activations cache logits on the `output` Tensor.\n-    if hasattr(output, \"_keras_logits\"):\n-        output = output._keras_logits\n-        if from_logits:\n-            warnings.warn(\n-                '\"`sparse_categorical_crossentropy` received '\n-                \"`from_logits=True`, but the `output` argument \"\n-                \"was produced by a sigmoid or softmax activation \"\n-                'and thus does not represent logits. Was this intended?\"',\n-                stacklevel=2,\n-            )\n-        from_logits = True\n-    elif (\n-        not from_logits\n-        and not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable))\n-        and output.op.type == \"Softmax\"\n-    ) and not hasattr(output, \"_keras_history\"):\n-        # When softmax activation function is used for output operation, we\n-        # use logits from the softmax function directly to compute loss in order\n-        # to prevent collapsing zero when training.\n-        # See b/117284466\n-        assert len(output.op.inputs) == 1\n-        output = output.op.inputs[0]\n-        from_logits = True\n-    elif not from_logits:\n+    target = cast(target, \"int64\")\n+\n+    output, from_logits = _get_logits(\n+        output, from_logits, \"Softmax\", \"sparse_categorical_crossentropy\"\n+    )\n+    if not from_logits:\n         epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n         output = tf.clip_by_value(output, epsilon_, 1 - epsilon_)\n         output = tf.math.log(output)\n \n+    # Permute output so that the last axis contains the logits/probabilities.\n     if isinstance(output.shape, (tuple, list)):\n         output_rank = len(output.shape)\n     else:\n@@ -5606,8 +5604,6 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n             \"on an output tensor with unknown rank\".format(axis)\n         )\n \n-    target = cast(target, \"int64\")\n-\n     # Try to adjust the shape so that rank of labels = rank of logits - 1.\n     output_shape = tf.shape(output)\n     target_rank = target.shape.ndims\n@@ -5621,6 +5617,11 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n         target = flatten(target)\n         output = tf.reshape(output, [-1, output_shape[-1]])\n \n+    if ignore_class is not None:\n+        valid_mask = tf.not_equal(target, cast(ignore_class, target.dtype))\n+        target = target[valid_mask]\n+        output = output[valid_mask]\n+\n     if py_any(_is_symbolic_tensor(v) for v in [target, output]):\n         with get_graph().as_default():\n             res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n@@ -5631,13 +5632,21 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n             labels=target, logits=output\n         )\n \n-    if update_shape and output_rank >= 3:\n-        # If our output includes timesteps or spatial dimensions we need to\n-        # reshape\n-        return tf.reshape(res, output_shape[:-1])\n-    else:\n+    if ignore_class is not None:\n+        res_shape = cast(output_shape[:-1], \"int64\")\n+        valid_mask = tf.reshape(valid_mask, res_shape)\n+        res = tf.scatter_nd(tf.where(valid_mask), res, res_shape)\n+        res._keras_mask = valid_mask\n+\n         return res\n \n+    if update_shape and output_rank >= 3:\n+        # If our output includes timesteps or\n+        # spatial dimensions we need to reshape\n+        res = tf.reshape(res, output_shape[:-1])\n+\n+    return res\n+\n \n @keras_export(\"keras.backend.binary_crossentropy\")\n @tf.__internal__.dispatch.add_dispatch_support\n@@ -5658,38 +5667,14 @@ def binary_crossentropy(target, output, from_logits=False):\n     target = tf.convert_to_tensor(target)\n     output = tf.convert_to_tensor(output)\n \n-    # Use logits whenever they are available. `softmax` and `sigmoid`\n-    # activations cache logits on the `output` Tensor.\n-    if hasattr(output, \"_keras_logits\"):\n-        output = output._keras_logits\n-        if from_logits:\n-            warnings.warn(\n-                '\"`binary_crossentropy` received `from_logits=True`, '\n-                \"but the `output` argument was produced by a sigmoid \"\n-                \"or softmax activation and thus \"\n-                'does not represent logits. Was this intended?\"',\n-                stacklevel=2,\n-            )\n-        from_logits = True\n-\n+    output, from_logits = _get_logits(\n+        output, from_logits, \"Sigmoid\", \"binary_crossentropy\"\n+    )\n     if from_logits:\n         return tf.nn.sigmoid_cross_entropy_with_logits(\n             labels=target, logits=output\n         )\n \n-    if (\n-        not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable))\n-        and output.op.type == \"Sigmoid\"\n-    ) and not hasattr(output, \"_keras_history\"):\n-        # When sigmoid activation function is used for output operation, we\n-        # use logits from the sigmoid function directly to compute loss in order\n-        # to prevent collapsing zero when training.\n-        assert len(output.op.inputs) == 1\n-        output = output.op.inputs[0]\n-        return tf.nn.sigmoid_cross_entropy_with_logits(\n-            labels=target, logits=output\n-        )\n-\n     epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n     output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\n "
            },
            {
                "filename": "keras/backend_test.py",
                "patch": "@@ -28,6 +28,7 @@\n from keras.layers import activation\n from keras.layers.normalization import batch_normalization_v1\n from keras.testing_infra import test_combinations\n+from keras.utils import losses_utils\n from keras.utils import tf_inspect\n from keras.utils import tf_utils\n \n@@ -1969,6 +1970,88 @@ def test_sparse_categorical_crossentropy_loss(self):\n         )\n         self.assertArrayNear(self.evaluate(result)[0], [0.002, 0, 0.17], 1e-3)\n \n+    @test_combinations.generate(\n+        test_combinations.combine(mode=[\"graph\", \"eager\"])\n+    )\n+    def test_sparse_categorical_crossentropy_loss_with_ignore_class(self):\n+        tests = (([255, 1, 2, 2], 255), ([-1, 1, 2, 2], -1))\n+        p = backend.softmax(\n+            backend.constant(\n+                [\n+                    [1.8, 1.2, 0.5],\n+                    [0.2, 3.8, 0.8],\n+                    [1.1, 0.4, 3.4],\n+                    [1.3, 0.7, 3.8],\n+                ]\n+            )\n+        )\n+\n+        for t, ignore_class in tests:\n+            t = backend.constant(t)\n+            result = backend.sparse_categorical_crossentropy(\n+                t, p, ignore_class=ignore_class\n+            )\n+            self.assertArrayNear(\n+                self.evaluate(result),\n+                [0.0, 0.07428224, 0.13980183, 0.11967831],\n+                1e-3,\n+            )\n+\n+    @test_combinations.generate(\n+        test_combinations.combine(mode=[\"graph\", \"eager\"])\n+    )\n+    def test_sparse_cce_loss_with_ignore_class_for_segmentation(self):\n+        t = backend.constant(\n+            [[[0, 2], [-1, -1]], [[0, 2], [-1, -1]], [[0, 0], [0, 0]]]\n+        )\n+        p = backend.constant(\n+            [\n+                [\n+                    [[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n+                    [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]],\n+                ],\n+                [\n+                    [[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n+                    [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]],\n+                ],\n+                [\n+                    [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0]],\n+                    [[0.1, 0.9, 0.0], [0.2, 0.8, 0.0]],\n+                ],\n+            ]\n+        )\n+\n+        expected_result = [\n+            [[0.0, 0.0], [0.0, 0.0]],\n+            [[0.0, 0.693148], [0.0, 0.0]],\n+            [[0.0, 0.0], [2.302585, 1.609438]],\n+        ]\n+\n+        # total_entries = 12\n+        # valid_entries = 8\n+        expected_mask = backend.constant(\n+            [\n+                [[True, True], [False, False]],\n+                [[True, True], [False, False]],\n+                [[True, True], [True, True]],\n+            ]\n+        )\n+\n+        result = backend.sparse_categorical_crossentropy(t, p, ignore_class=-1)\n+        mask = losses_utils.get_mask(result)\n+\n+        self.assertIsNotNone(\n+            mask,\n+            \"expected sparse_categorical_crossentropy to set the \"\n+            \"`_keras_mask` attribute when `ignore_class is not None`, \"\n+            \"which indicates which loss values are valid.\",\n+        )\n+\n+        result = self.evaluate(result)\n+        mask = self.evaluate(mask)\n+        self.assertAllEqual(mask, expected_mask)\n+        self.assertAllClose(result, expected_result, atol=1e-6)\n+\n     @test_combinations.generate(test_combinations.combine(mode=[\"graph\"]))\n     def test_sparse_categorical_crossentropy_loss_with_unknown_rank_tensor(\n         self,"
            },
            {
                "filename": "keras/engine/compile_utils.py",
                "patch": "@@ -261,7 +261,7 @@ def __call__(\n                 continue\n \n             y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n-            sw = apply_mask(y_p, sw, get_mask(y_p))\n+            sw = losses_utils.apply_mask(y_p, sw, losses_utils.get_mask(y_p))\n             loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n \n             total_loss_mean_value = loss_value\n@@ -596,8 +596,8 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n                 continue\n \n             y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n-            mask = get_mask(y_p)\n-            sw = apply_mask(y_p, sw, mask)\n+            mask = losses_utils.get_mask(y_p)\n+            sw = losses_utils.apply_mask(y_p, sw, mask)\n \n             for metric_obj in metric_objs:\n                 if metric_obj is None:\n@@ -847,25 +847,6 @@ def match_dtype_and_rank(y_t, y_p, sw):\n     return y_t, y_p, sw\n \n \n-def get_mask(y_p):\n-    \"\"\"Returns Keras mask from tensor.\"\"\"\n-    return getattr(y_p, \"_keras_mask\", None)\n-\n-\n-def apply_mask(y_p, sw, mask):\n-    \"\"\"Applies any mask on predictions to sample weights.\"\"\"\n-    if mask is not None:\n-        mask = tf.cast(mask, y_p.dtype)\n-        if sw is not None:\n-            mask, _, sw = losses_utils.squeeze_or_expand_dimensions(\n-                mask, sample_weight=sw\n-            )\n-            sw *= mask\n-        else:\n-            sw = mask\n-    return sw\n-\n-\n def get_custom_object_name(obj):\n     \"\"\"Returns the name to use for a custom loss or metric callable.\n "
            },
            {
                "filename": "keras/losses.py",
                "patch": "@@ -150,8 +150,13 @@ def __call__(self, y_true, y_pred, sample_weight=None):\n                     self.call, tf.__internal__.autograph.control_status_ctx()\n                 )\n             losses = call_fn(y_true, y_pred)\n+            mask = losses_utils.get_mask(losses)\n+            reduction = self._get_reduction()\n+            sample_weight = losses_utils.apply_valid_mask(\n+                losses, sample_weight, mask, reduction\n+            )\n             return losses_utils.compute_weighted_loss(\n-                losses, sample_weight, reduction=self._get_reduction()\n+                losses, sample_weight, reduction=reduction\n             )\n \n     @classmethod\n@@ -977,6 +982,7 @@ class SparseCategoricalCrossentropy(LossFunctionWrapper):\n     def __init__(\n         self,\n         from_logits=False,\n+        ignore_class=None,\n         reduction=losses_utils.ReductionV2.AUTO,\n         name=\"sparse_categorical_crossentropy\",\n     ):\n@@ -985,6 +991,11 @@ def __init__(\n         Args:\n           from_logits: Whether `y_pred` is expected to be a logits tensor. By\n             default, we assume that `y_pred` encodes a probability distribution.\n+          ignore_class: Optional integer. The ID of a class to be ignored during\n+            loss computation. This is useful, for example, in segmentation\n+            problems featuring a \"void\" class (commonly -1 or 255) in\n+            segmentation maps.\n+            By default (`ignore_class=None`), all classes are considered.\n           reduction: Type of `tf.keras.losses.Reduction` to apply to\n             loss. Default value is `AUTO`. `AUTO` indicates that the reduction\n             option will be determined by the usage context. For almost all cases\n@@ -1003,6 +1014,7 @@ def __init__(\n             name=name,\n             reduction=reduction,\n             from_logits=from_logits,\n+            ignore_class=ignore_class,\n         )\n \n \n@@ -2024,7 +2036,9 @@ def _ragged_tensor_categorical_crossentropy(\n     \"keras.losses.sparse_categorical_crossentropy\",\n )\n @tf.__internal__.dispatch.add_dispatch_support\n-def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):\n+def sparse_categorical_crossentropy(\n+    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None\n+):\n     \"\"\"Computes the sparse categorical crossentropy loss.\n \n     Standalone usage:\n@@ -2036,27 +2050,47 @@ def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):\n     >>> loss.numpy()\n     array([0.0513, 2.303], dtype=float32)\n \n+    >>> y_true = [[[ 0,  2],\n+    ...            [-1, -1]],\n+    ...           [[ 0,  2],\n+    ...            [-1, -1]]]\n+    >>> y_pred = [[[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n+                   [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]],\n+                  [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n+                   [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n+    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(\n+    ...   y_true, y_pred, ignore_class=-1)\n+    >>> assert loss.shape == (2,)\n+    >>> loss.numpy()\n+    array([2.3841855e-07, 3.4657377e-01], dtype=float32)\n+\n     Args:\n       y_true: Ground truth values.\n       y_pred: The predicted values.\n       from_logits: Whether `y_pred` is expected to be a logits tensor. By\n         default, we assume that `y_pred` encodes a probability distribution.\n       axis: Defaults to -1. The dimension along which the entropy is\n         computed.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        loss computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n \n     Returns:\n       Sparse categorical crossentropy loss value.\n     \"\"\"\n-    y_pred = tf.convert_to_tensor(y_pred)\n-\n     return backend.sparse_categorical_crossentropy(\n-        y_true, y_pred, from_logits=from_logits, axis=axis\n+        y_true,\n+        y_pred,\n+        from_logits=from_logits,\n+        ignore_class=ignore_class,\n+        axis=axis,\n     )\n \n \n @dispatch.dispatch_for_types(sparse_categorical_crossentropy, tf.RaggedTensor)\n def _ragged_tensor_sparse_categorical_crossentropy(\n-    y_true, y_pred, from_logits=False, axis=-1\n+    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None\n ):\n     \"\"\"Implements support for handling RaggedTensors.\n \n@@ -2071,7 +2105,10 @@ def _ragged_tensor_sparse_categorical_crossentropy(\n     the sum of the individual loss values divided by 3.\n     \"\"\"\n     fn = functools.partial(\n-        sparse_categorical_crossentropy, from_logits=from_logits, axis=axis\n+        sparse_categorical_crossentropy,\n+        from_logits=from_logits,\n+        ignore_class=ignore_class,\n+        axis=axis,\n     )\n     return _ragged_tensor_apply_loss(fn, y_true, y_pred, y_pred_extra_dim=True)\n "
            },
            {
                "filename": "keras/losses_test.py",
                "patch": "@@ -161,6 +161,36 @@ def test_sparse_categorical_crossentropy_loss(self):\n             atol=1e-5,\n         )\n \n+    @test_combinations.generate(\n+        test_combinations.combine(mode=[\"graph\", \"eager\"])\n+    )\n+    def test_sparse_categorical_crossentropy_loss_with_ignore_class(self):\n+        ignore_class = 255\n+        target = backend.variable(np.random.randint(0, 1, (5, 1)))\n+        logits = backend.variable(np.random.random((5, 1)))\n+        softmax_output = backend.softmax(logits)\n+\n+        _valid = tf.constant([[0], [1], [0], [1], [1]], target.dtype)\n+        target.assign(target * _valid + (1 - _valid) * ignore_class)\n+\n+        output_from_logit = losses.sparse_categorical_crossentropy(\n+            target, logits, ignore_class=ignore_class, from_logits=True\n+        )\n+        output_from_softmax = losses.sparse_categorical_crossentropy(\n+            target, softmax_output, ignore_class=ignore_class\n+        )\n+\n+        # expected_mask = [False, True, False, True, True]\n+        # for o in (output_from_logit, output_from_softmax):\n+        #     mask = backend.eval(losses_utils.get_mask(o))\n+        #     np.testing.assert_array_equal(mask, expected_mask)\n+\n+        np.testing.assert_allclose(\n+            backend.eval(output_from_logit),\n+            backend.eval(output_from_softmax),\n+            atol=1e-5,\n+        )\n+\n     @test_combinations.generate(test_combinations.combine(mode=[\"graph\"]))\n     def test_sparse_categorical_crossentropy_loss_with_unknown_rank_tensor(\n         self,\n@@ -1810,6 +1840,70 @@ def test_unweighted(self):\n         loss = cce_obj(y_true, logits)\n         self.assertAlmostEqual(self.evaluate(loss), 0.0573, 3)\n \n+    def test_unweighted_ignore_class(self):\n+        cce_obj = losses.SparseCategoricalCrossentropy(ignore_class=-1)\n+        y_true = tf.constant([0, 1, 2, -1])\n+        y_pred = tf.constant(\n+            [\n+                [0.9, 0.05, 0.05],\n+                [0.5, 0.89, 0.6],\n+                [0.05, 0.01, 0.94],\n+                [0.85, 0.14, 0.01],\n+            ],\n+            dtype=tf.float32,\n+        )\n+        loss = cce_obj(y_true, y_pred)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.3239, 3)\n+\n+        # Test with logits.\n+        logits = tf.constant(\n+            [[8.0, 1.0, 1.0], [0.0, 9.0, 1.0], [2.0, 3.0, 5.0], [7.8, 2.0, 1.0]]\n+        )\n+        cce_obj = losses.SparseCategoricalCrossentropy(\n+            ignore_class=-1, from_logits=True\n+        )\n+        loss = cce_obj(y_true, logits)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.0573, 3)\n+\n+    def test_unweighted_ignore_class_for_segmentation(self):\n+        cce_obj = losses.SparseCategoricalCrossentropy(ignore_class=-1)\n+        y_true = tf.constant(\n+            [[[0, 2], [-1, -1]], [[0, 2], [-1, -1]], [[0, 0], [0, 0]]]\n+        )\n+        y_pred = tf.constant(\n+            [\n+                [\n+                    [[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n+                    [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]],\n+                ],\n+                [\n+                    [[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n+                    [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]],\n+                ],\n+                [\n+                    [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0]],\n+                    [[0.1, 0.9, 0.0], [0.2, 0.8, 0.0]],\n+                ],\n+            ],\n+            dtype=tf.float32,\n+        )\n+\n+        # Expected loss values:\n+        # [[0.0, 0.0], [0.0, 0.0]],\n+        # [[0.0, 0.693148], [0.0, 0.0]],\n+        # [[0.0, 0.0], [2.302585, 1.609438]],\n+\n+        loss = cce_obj(y_true, y_pred)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.575646375, 3)\n+\n+        # # Test with logits.\n+        # logits = tf.constant(\n+        #     [[8.0, 1.0, 1.0], [0.0, 9.0, 1.0], [2.0, 3.0, 5.0]]\n+        # )\n+        # cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n+        # loss = cce_obj(y_true, logits)\n+        # self.assertAlmostEqual(self.evaluate(loss), 0.0573, 3)\n+\n     def test_scalar_weighted(self):\n         cce_obj = losses.SparseCategoricalCrossentropy()\n         y_true = tf.constant([[0], [1], [2]])\n@@ -1847,6 +1941,32 @@ def test_sample_weighted(self):\n         loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n         self.assertAlmostEqual(self.evaluate(loss), 0.31829, 3)\n \n+    def test_sample_weighted_ignore_class(self):\n+        cce_obj = losses.SparseCategoricalCrossentropy(ignore_class=-1)\n+        y_true = tf.constant([[0], [1], [2], [-1]])\n+        y_pred = tf.constant(\n+            [\n+                [0.9, 0.05, 0.05],\n+                [0.5, 0.89, 0.6],\n+                [0.05, 0.01, 0.94],\n+                [0.85, 0.14, 0.01],\n+            ],\n+            dtype=tf.float32,\n+        )\n+        sample_weight = tf.constant([[1.2], [3.4], [5.6], [10.4]], shape=(4, 1))\n+        loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n+        self.assertAlmostEqual(self.evaluate(loss), 1.0696, 3)\n+\n+        # Test with logits.\n+        logits = tf.constant(\n+            [[8.0, 1.0, 1.0], [0.0, 9.0, 1.0], [2.0, 3.0, 5.0], [7.8, 2.0, 1.0]]\n+        )\n+        cce_obj = losses.SparseCategoricalCrossentropy(\n+            ignore_class=-1, from_logits=True\n+        )\n+        loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.31829, 3)\n+\n     def test_no_reduction(self):\n         y_true = tf.constant([[0], [1], [2]])\n         logits = tf.constant("
            },
            {
                "filename": "keras/metrics/base_metric.py",
                "patch": "@@ -698,6 +698,10 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n             self._fn, tf.__internal__.autograph.control_status_ctx()\n         )\n         matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n+        mask = losses_utils.get_mask(matches)\n+        sample_weight = losses_utils.apply_valid_mask(\n+            matches, sample_weight, mask, self.reduction\n+        )\n         return super().update_state(matches, sample_weight=sample_weight)\n \n     def get_config(self):\n@@ -915,6 +919,10 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n             self._fn, tf.__internal__.autograph.control_status_ctx()\n         )\n         matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n+        mask = losses_utils.get_mask(matches)\n+        sample_weight = losses_utils.apply_valid_mask(\n+            matches, sample_weight, mask, self.reduction\n+        )\n         return super().update_state(matches, sample_weight=sample_weight)\n \n     def get_config(self):"
            },
            {
                "filename": "keras/metrics/metrics.py",
                "patch": "@@ -18,6 +18,7 @@\n \n import abc\n from typing import List\n+from typing import Optional\n from typing import Tuple\n from typing import Union\n \n@@ -2645,11 +2646,36 @@ class _IoUBase(base_metric.Metric):\n         `(num_classes, num_classes)` will be allocated.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      sparse_y_true: Whether labels are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      sparse_y_pred: Whether predictions are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      axis: (Optional) Defaults to -1. The dimension containing the logits.\n+\n     \"\"\"\n \n-    def __init__(self, num_classes, name=None, dtype=None):\n+    def __init__(\n+        self,\n+        num_classes: int,\n+        name: Optional[str] = None,\n+        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n+        ignore_class: Optional[int] = None,\n+        sparse_y_true: bool = True,\n+        sparse_y_pred: bool = True,\n+        axis: int = -1,\n+    ):\n         super().__init__(name=name, dtype=dtype)\n         self.num_classes = num_classes\n+        self.ignore_class = ignore_class\n+        self.sparse_y_true = sparse_y_true\n+        self.sparse_y_pred = sparse_y_pred\n+        self.axis = axis\n \n         # Variable to accumulate the predictions in the confusion matrix.\n         self.total_cm = self.add_weight(\n@@ -2672,6 +2698,11 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n           Update op.\n         \"\"\"\n \n+        if not self.sparse_y_true:\n+            y_true = tf.argmax(y_true, axis=self.axis)\n+        if not self.sparse_y_pred:\n+            y_pred = tf.argmax(y_pred, axis=self.axis)\n+\n         y_true = tf.cast(y_true, self._dtype)\n         y_pred = tf.cast(y_pred, self._dtype)\n \n@@ -2687,6 +2718,14 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n             if sample_weight.shape.ndims > 1:\n                 sample_weight = tf.reshape(sample_weight, [-1])\n \n+        if self.ignore_class is not None:\n+            ignore_class = tf.cast(self.ignore_class, y_true.dtype)\n+            valid_mask = tf.not_equal(y_true, ignore_class)\n+            y_true = y_true[valid_mask]\n+            y_pred = y_pred[valid_mask]\n+            if sample_weight is not None:\n+                sample_weight = sample_weight[valid_mask]\n+\n         # Accumulate the prediction to current confusion matrix.\n         current_cm = tf.math.confusion_matrix(\n             y_true,\n@@ -2738,6 +2777,17 @@ class IoU(_IoUBase):\n         single id value should be provided.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      sparse_y_true: Whether labels are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      sparse_y_pred: Whether predictions are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      axis: (Optional) Defaults to -1. The dimension containing the logits.\n \n     Standalone usage:\n \n@@ -2777,12 +2827,20 @@ def __init__(\n         self,\n         num_classes: int,\n         target_class_ids: Union[List[int], Tuple[int, ...]],\n-        name=None,\n-        dtype=None,\n+        name: Optional[str] = None,\n+        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n+        ignore_class: Optional[int] = None,\n+        sparse_y_true: bool = True,\n+        sparse_y_pred: bool = True,\n+        axis: int = -1,\n     ):\n         super().__init__(\n             name=name,\n             num_classes=num_classes,\n+            ignore_class=ignore_class,\n+            sparse_y_true=sparse_y_true,\n+            sparse_y_pred=sparse_y_pred,\n+            axis=axis,\n             dtype=dtype,\n         )\n         if max(target_class_ids) >= num_classes:\n@@ -2828,6 +2886,10 @@ def get_config(self):\n         config = {\n             \"num_classes\": self.num_classes,\n             \"target_class_ids\": self.target_class_ids,\n+            \"ignore_class\": self.ignore_class,\n+            \"sparse_y_true\": self.sparse_y_true,\n+            \"sparse_y_pred\": self.sparse_y_pred,\n+            \"axis\": self.axis,\n         }\n         base_config = super().get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n@@ -2983,6 +3045,17 @@ class MeanIoU(IoU):\n         [num_classes, num_classes] will be allocated.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      sparse_y_true: Whether labels are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      sparse_y_pred: Whether predictions are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      axis: (Optional) Defaults to -1. The dimension containing the logits.\n \n     Standalone usage:\n \n@@ -3013,20 +3086,37 @@ class MeanIoU(IoU):\n     \"\"\"\n \n     @dtensor_utils.inject_mesh\n-    def __init__(self, num_classes, name=None, dtype=None):\n+    def __init__(\n+        self,\n+        num_classes: int,\n+        name: Optional[str] = None,\n+        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n+        ignore_class: Optional[int] = None,\n+        sparse_y_true: bool = True,\n+        sparse_y_pred: bool = True,\n+        axis: int = -1,\n+    ):\n         target_class_ids = list(range(num_classes))\n         super().__init__(\n             name=name,\n             num_classes=num_classes,\n             target_class_ids=target_class_ids,\n+            axis=axis,\n             dtype=dtype,\n+            ignore_class=ignore_class,\n+            sparse_y_true=sparse_y_true,\n+            sparse_y_pred=sparse_y_pred,\n         )\n \n     def get_config(self):\n         return {\n             \"num_classes\": self.num_classes,\n             \"name\": self.name,\n             \"dtype\": self._dtype,\n+            \"ignore_class\": self.ignore_class,\n+            \"sparse_y_true\": self.sparse_y_true,\n+            \"sparse_y_pred\": self.sparse_y_pred,\n+            \"axis\": self.axis,\n         }\n \n \n@@ -3074,6 +3164,14 @@ class OneHotIoU(IoU):\n         single id value should be provided.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      sparse_y_pred: Whether predictions are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      axis: (Optional) Defaults to -1. The dimension containing the logits.\n \n     Standalone usage:\n \n@@ -3111,32 +3209,31 @@ def __init__(\n         target_class_ids: Union[List[int], Tuple[int, ...]],\n         name=None,\n         dtype=None,\n+        ignore_class: Optional[int] = None,\n+        sparse_y_pred: bool = False,\n+        axis: int = -1,\n     ):\n         super().__init__(\n             num_classes=num_classes,\n             target_class_ids=target_class_ids,\n             name=name,\n             dtype=dtype,\n+            ignore_class=ignore_class,\n+            sparse_y_true=False,\n+            sparse_y_pred=sparse_y_pred,\n+            axis=axis,\n         )\n \n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        \"\"\"Accumulates the confusion matrix statistics.\n-\n-        Args:\n-          y_true: The ground truth values.\n-          y_pred: The predicted values.\n-          sample_weight: Optional weighting of each example. Defaults to 1. Can\n-            be a `Tensor` whose rank is either 0, or the same rank as `y_true`,\n-            and must be broadcastable to `y_true`.\n-\n-        Returns:\n-          Update op.\n-        \"\"\"\n-        # Select max hot-encoding channels to convert into all-class format\n-        y_true = tf.argmax(y_true, axis=-1, output_type=tf.int32)\n-        y_pred = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n-\n-        return super().update_state(y_true, y_pred, sample_weight)\n+    def get_config(self):\n+        return {\n+            \"num_classes\": self.num_classes,\n+            \"target_class_ids\": self.target_class_ids,\n+            \"name\": self.name,\n+            \"dtype\": self._dtype,\n+            \"ignore_class\": self.ignore_class,\n+            \"sparse_y_pred\": self.sparse_y_pred,\n+            \"axis\": self.axis,\n+        }\n \n \n @keras_export(\"keras.metrics.OneHotMeanIoU\")\n@@ -3181,6 +3278,14 @@ class apply.\n         allocated to accumulate predictions from which the metric is calculated.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      sparse_y_pred: Whether predictions are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      axis: (Optional) Defaults to -1. The dimension containing the logits.\n \n     Standalone usage:\n \n@@ -3215,33 +3320,31 @@ class apply.\n     def __init__(\n         self,\n         num_classes: int,\n-        name=None,\n-        dtype=None,\n+        name: str = None,\n+        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n+        ignore_class: Optional[int] = None,\n+        sparse_y_pred: bool = False,\n+        axis: int = -1,\n     ):\n         super().__init__(\n             num_classes=num_classes,\n+            axis=axis,\n             name=name,\n             dtype=dtype,\n+            ignore_class=ignore_class,\n+            sparse_y_true=False,\n+            sparse_y_pred=sparse_y_pred,\n         )\n \n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        \"\"\"Accumulates the confusion matrix statistics.\n-\n-        Args:\n-          y_true: The ground truth values.\n-          y_pred: The predicted values.\n-          sample_weight: Optional weighting of each example. Defaults to 1. Can\n-            be a `Tensor` whose rank is either 0, or the same rank as `y_true`,\n-            and must be broadcastable to `y_true`.\n-\n-        Returns:\n-          Update op.\n-        \"\"\"\n-        # Select max hot-encoding channels to convert into all-class format\n-        y_true = tf.argmax(y_true, axis=-1, output_type=tf.int32)\n-        y_pred = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n-\n-        return super().update_state(y_true, y_pred, sample_weight)\n+    def get_config(self):\n+        return {\n+            \"num_classes\": self.num_classes,\n+            \"name\": self.name,\n+            \"dtype\": self._dtype,\n+            \"ignore_class\": self.ignore_class,\n+            \"sparse_y_pred\": self.sparse_y_pred,\n+            \"axis\": self.axis,\n+        }\n \n \n @keras_export(\"keras.metrics.BinaryCrossentropy\")\n@@ -3319,6 +3422,8 @@ class CategoricalCrossentropy(base_metric.MeanMetricWrapper):\n         smoothed, meaning the confidence on label values are relaxed. e.g.\n         `label_smoothing=0.2` means that we will use a value of `0.1` for label\n         `0` and `0.9` for label `1`\"\n+      axis: (Optional) Defaults to -1. The dimension along which entropy is\n+        computed.\n \n     Standalone usage:\n \n@@ -3359,13 +3464,15 @@ def __init__(\n         dtype=None,\n         from_logits=False,\n         label_smoothing=0,\n+        axis=-1,\n     ):\n         super().__init__(\n             categorical_crossentropy,\n             name,\n             dtype=dtype,\n             from_logits=from_logits,\n             label_smoothing=label_smoothing,\n+            axis=axis,\n         )\n \n \n@@ -3389,7 +3496,11 @@ class SparseCategoricalCrossentropy(base_metric.MeanMetricWrapper):\n       dtype: (Optional) data type of the metric result.\n       from_logits: (Optional) Whether output is expected to be a logits tensor.\n         By default, we consider that output encodes a probability distribution.\n-      axis: (Optional) Defaults to -1. The dimension along which the metric is\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      axis: (Optional) Defaults to -1. The dimension along which entropy is\n         computed.\n \n     Standalone usage:\n@@ -3430,16 +3541,18 @@ class SparseCategoricalCrossentropy(base_metric.MeanMetricWrapper):\n     @dtensor_utils.inject_mesh\n     def __init__(\n         self,\n-        name=\"sparse_categorical_crossentropy\",\n-        dtype=None,\n-        from_logits=False,\n-        axis=-1,\n+        name: str = \"sparse_categorical_crossentropy\",\n+        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n+        from_logits: bool = False,\n+        ignore_class: Optional[int] = None,\n+        axis: int = -1,\n     ):\n         super().__init__(\n             sparse_categorical_crossentropy,\n             name,\n             dtype=dtype,\n             from_logits=from_logits,\n+            ignore_class=ignore_class,\n             axis=axis,\n         )\n "
            },
            {
                "filename": "keras/metrics/metrics_test.py",
                "patch": "@@ -1282,6 +1282,44 @@ def test_unweighted(self):\n         expected_result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2\n         self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n \n+    def test_unweighted_ignore_class_255(self):\n+        y_pred = [0, 1, 1, 1]\n+        y_true = [0, 1, 2, 255]\n+\n+        m_obj = metrics.MeanIoU(num_classes=3, ignore_class=255)\n+        self.evaluate(tf.compat.v1.variables_initializer(m_obj.variables))\n+\n+        result = m_obj(y_true, y_pred)\n+\n+        # cm = [[1, 0, 0],\n+        #       [0, 1, 0],\n+        #       [0, 1, 0]]\n+        # sum_row = [1, 1, 1], sum_col = [1, 2, 0], true_positives = [1, 1, 0]\n+        # iou = true_positives / (sum_row + sum_col - true_positives))\n+        expected_result = (\n+            1 / (1 + 1 - 1) + 1 / (2 + 1 - 1) + 0 / (0 + 1 - 0)\n+        ) / 3\n+        self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n+    def test_unweighted_ignore_class_1(self):\n+        y_pred = [0, 1, 1, 1]\n+        y_true = [0, 1, 2, -1]\n+\n+        m_obj = metrics.MeanIoU(num_classes=3, ignore_class=-1)\n+        self.evaluate(tf.compat.v1.variables_initializer(m_obj.variables))\n+\n+        result = m_obj(y_true, y_pred)\n+\n+        # cm = [[1, 0, 0],\n+        #       [0, 1, 0],\n+        #       [0, 1, 0]]\n+        # sum_row = [1, 1, 1], sum_col = [1, 2, 0], true_positives = [1, 1, 0]\n+        # iou = true_positives / (sum_row + sum_col - true_positives))\n+        expected_result = (\n+            1 / (1 + 1 - 1) + 1 / (2 + 1 - 1) + 0 / (0 + 1 - 0)\n+        ) / 3\n+        self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n     def test_weighted(self):\n         y_pred = tf.constant([0, 1, 0, 1], dtype=tf.float32)\n         y_true = tf.constant([0, 0, 1, 1])\n@@ -1302,6 +1340,26 @@ def test_weighted(self):\n         ) / 2\n         self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n \n+    def test_weighted_ignore_class_1(self):\n+        y_pred = tf.constant([0, 1, 0, 1], dtype=tf.float32)\n+        y_true = tf.constant([0, 0, 1, -1])\n+        sample_weight = tf.constant([0.2, 0.3, 0.4, 0.1])\n+\n+        m_obj = metrics.MeanIoU(num_classes=2, ignore_class=-1)\n+        self.evaluate(tf.compat.v1.variables_initializer(m_obj.variables))\n+\n+        result = m_obj(y_true, y_pred, sample_weight=sample_weight)\n+\n+        # cm = [[0.2, 0.3],\n+        #       [0.4, 0.0]]\n+        # sum_row = [0.6, 0.3], sum_col = [0.5, 0.4], true_positives = [0.2,\n+        # 0.0]\n+        # iou = true_positives / (sum_row + sum_col - true_positives))\n+        expected_result = (\n+            0.2 / (0.6 + 0.5 - 0.2) + 0.0 / (0.3 + 0.4 - 0.0)\n+        ) / 2\n+        self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n     def test_multi_dim_input(self):\n         y_pred = tf.constant([[0, 1], [0, 1]], dtype=tf.float32)\n         y_true = tf.constant([[0, 0], [1, 1]])\n@@ -1736,6 +1794,16 @@ def test_unweighted(self):\n \n         self.assertAllClose(self.evaluate(result), 1.176, atol=1e-3)\n \n+    def test_unweighted_ignore_class(self):\n+        scce_obj = metrics.SparseCategoricalCrossentropy(ignore_class=-1)\n+        self.evaluate(tf.compat.v1.variables_initializer(scce_obj.variables))\n+\n+        y_true = np.asarray([-1, 2])\n+        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n+        result = scce_obj(y_true, y_pred)\n+\n+        self.assertAllClose(self.evaluate(result), 2.3026, atol=1e-3)\n+\n     def test_unweighted_from_logits(self):\n         scce_obj = metrics.SparseCategoricalCrossentropy(from_logits=True)\n         self.evaluate(tf.compat.v1.variables_initializer(scce_obj.variables))\n@@ -1790,6 +1858,17 @@ def test_weighted(self):\n \n         self.assertAllClose(self.evaluate(result), 1.338, atol=1e-3)\n \n+    def test_weighted_ignore_class(self):\n+        scce_obj = metrics.SparseCategoricalCrossentropy(ignore_class=-1)\n+        self.evaluate(tf.compat.v1.variables_initializer(scce_obj.variables))\n+\n+        y_true = np.asarray([1, 2, -1])\n+        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1], [0.1, 0.8, 0.1]])\n+        sample_weight = tf.constant([1.5, 2.0, 1.5])\n+        result = scce_obj(y_true, y_pred, sample_weight=sample_weight)\n+\n+        self.assertAllClose(self.evaluate(result), 1.338, atol=1e-3)\n+\n     def test_weighted_from_logits(self):\n         scce_obj = metrics.SparseCategoricalCrossentropy(from_logits=True)\n         self.evaluate(tf.compat.v1.variables_initializer(scce_obj.variables))"
            },
            {
                "filename": "keras/utils/losses_utils.py",
                "patch": "@@ -393,3 +393,41 @@ def cast_losses_to_common_dtype(losses):\n     if highest_float:\n         losses = [tf.cast(loss, highest_float) for loss in losses]\n     return losses\n+\n+\n+def get_mask(y_p):\n+    \"\"\"Returns Keras mask from tensor.\"\"\"\n+    return getattr(y_p, \"_keras_mask\", None)\n+\n+\n+def apply_mask(y_p, sw, mask):\n+    \"\"\"Applies any mask on predictions to sample weights.\"\"\"\n+    if mask is not None:\n+        mask = tf.cast(mask, y_p.dtype)\n+        if sw is not None:\n+            mask, _, sw = squeeze_or_expand_dimensions(mask, sample_weight=sw)\n+            sw *= mask\n+        else:\n+            sw = mask\n+    return sw\n+\n+\n+def apply_valid_mask(losses, sw, mask, reduction):\n+    \"\"\"Redistribute sample weights considering only valid entries.\"\"\"\n+    if mask is not None:\n+        mask = tf.cast(mask, losses.dtype)\n+\n+        if reduction in (ReductionV2.AUTO, ReductionV2.SUM_OVER_BATCH_SIZE):\n+            # Valid entries have weight `total/valid`, while invalid ones\n+            # have 0. When summed over batch, they will be reduced to:\n+            #\n+            # mean(loss * sample_weight * total / valid)\n+            #   = sum(loss * sample_weight * total / valid) / total\n+            #   = sum(loss * sample_weight) / total * total / valid\n+            #   = sum(loss * sample_weight) / valid\n+\n+            total = tf.cast(tf.size(mask), losses.dtype)\n+            valid = tf.reduce_sum(mask)\n+            mask *= total / valid\n+\n+    return apply_mask(losses, sw, mask)"
            }
        ],
        "diff": "diff --git a/keras/backend.py b/keras/backend.py\nindex bdf1854187f..4a250bc037d 100644\n--- a/keras/backend.py\n+++ b/keras/backend.py\n@@ -5440,6 +5440,41 @@ def softsign(x):\n     return tf.math.softsign(x)\n \n \n+def _get_logits(output, from_logits, op_type, fn_name):\n+    output_ = output\n+    from_logits_ = from_logits\n+\n+    has_keras_logits = hasattr(output, \"_keras_logits\")\n+    if has_keras_logits:\n+        output_ = output._keras_logits\n+        from_logits_ = True\n+\n+    from_expected_op_type = (\n+        not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable))\n+        and output.op.type == op_type\n+    ) and not has_keras_logits\n+\n+    if from_expected_op_type:\n+        # When softmax activation function is used for output operation, we\n+        # use logits from the softmax function directly to compute loss in order\n+        # to prevent collapsing zero when training.\n+        # See b/117284466\n+        assert len(output.op.inputs) == 1\n+        output_ = output.op.inputs[0]\n+        from_logits_ = True\n+\n+    if from_logits and (has_keras_logits or from_expected_op_type):\n+        warnings.warn(\n+            f'\"`{fn_name}` received `from_logits=True`, but '\n+            f\"the `output` argument was produced by a {op_type} \"\n+            \"activation and thus does not represent logits. \"\n+            \"Was this intended?\",\n+            stacklevel=2,\n+        )\n+\n+    return output_, from_logits_\n+\n+\n @keras_export(\"keras.backend.categorical_crossentropy\")\n @tf.__internal__.dispatch.add_dispatch_support\n @doc_controls.do_not_generate_docs\n@@ -5490,39 +5525,14 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n     output = tf.convert_to_tensor(output)\n     target.shape.assert_is_compatible_with(output.shape)\n \n-    # Use logits whenever they are available. `softmax` and `sigmoid`\n-    # activations cache logits on the `output` Tensor.\n-    if hasattr(output, \"_keras_logits\"):\n-        output = output._keras_logits\n-        if from_logits:\n-            warnings.warn(\n-                '\"`categorical_crossentropy` received `from_logits=True`, but '\n-                \"the `output` argument was produced by a sigmoid or softmax \"\n-                \"activation and thus does not represent logits. \"\n-                \"Was this intended?\",\n-                stacklevel=2,\n-            )\n-        from_logits = True\n-\n+    output, from_logits = _get_logits(\n+        output, from_logits, \"Softmax\", \"categorical_crossentropy\"\n+    )\n     if from_logits:\n         return tf.nn.softmax_cross_entropy_with_logits(\n             labels=target, logits=output, axis=axis\n         )\n \n-    if (\n-        not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable))\n-        and output.op.type == \"Softmax\"\n-    ) and not hasattr(output, \"_keras_history\"):\n-        # When softmax activation function is used for output operation, we\n-        # use logits from the softmax function directly to compute loss in order\n-        # to prevent collapsing zero when training.\n-        # See b/117284466\n-        assert len(output.op.inputs) == 1\n-        output = output.op.inputs[0]\n-        return tf.nn.softmax_cross_entropy_with_logits(\n-            labels=target, logits=output, axis=axis\n-        )\n-\n     # scale preds so that the class probas of each sample sum to 1\n     output = output / tf.reduce_sum(output, axis, True)\n     # Compute cross entropy from probabilities.\n@@ -5534,7 +5544,9 @@ def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n @keras_export(\"keras.backend.sparse_categorical_crossentropy\")\n @tf.__internal__.dispatch.add_dispatch_support\n @doc_controls.do_not_generate_docs\n-def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n+def sparse_categorical_crossentropy(\n+    target, output, from_logits=False, axis=-1, ignore_class=None\n+):\n     \"\"\"Categorical crossentropy with integer targets.\n \n     Args:\n@@ -5547,6 +5559,11 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n         axis: Int specifying the channels axis. `axis=-1` corresponds to data\n             format `channels_last`, and `axis=1` corresponds to data format\n             `channels_first`.\n+        ignore_class: Optional integer. The ID of a class to be ignored\n+            during loss computation. This is useful, for example, in\n+            segmentation problems featuring a \"void\" class (commonly -1\n+            or 255) in segmentation maps.\n+            By default (`ignore_class=None`), all classes are considered.\n \n     Returns:\n         Output tensor.\n@@ -5557,36 +5574,17 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n     target = tf.convert_to_tensor(target)\n     output = tf.convert_to_tensor(output)\n \n-    # Use logits whenever they are available. `softmax` and `sigmoid`\n-    # activations cache logits on the `output` Tensor.\n-    if hasattr(output, \"_keras_logits\"):\n-        output = output._keras_logits\n-        if from_logits:\n-            warnings.warn(\n-                '\"`sparse_categorical_crossentropy` received '\n-                \"`from_logits=True`, but the `output` argument \"\n-                \"was produced by a sigmoid or softmax activation \"\n-                'and thus does not represent logits. Was this intended?\"',\n-                stacklevel=2,\n-            )\n-        from_logits = True\n-    elif (\n-        not from_logits\n-        and not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable))\n-        and output.op.type == \"Softmax\"\n-    ) and not hasattr(output, \"_keras_history\"):\n-        # When softmax activation function is used for output operation, we\n-        # use logits from the softmax function directly to compute loss in order\n-        # to prevent collapsing zero when training.\n-        # See b/117284466\n-        assert len(output.op.inputs) == 1\n-        output = output.op.inputs[0]\n-        from_logits = True\n-    elif not from_logits:\n+    target = cast(target, \"int64\")\n+\n+    output, from_logits = _get_logits(\n+        output, from_logits, \"Softmax\", \"sparse_categorical_crossentropy\"\n+    )\n+    if not from_logits:\n         epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n         output = tf.clip_by_value(output, epsilon_, 1 - epsilon_)\n         output = tf.math.log(output)\n \n+    # Permute output so that the last axis contains the logits/probabilities.\n     if isinstance(output.shape, (tuple, list)):\n         output_rank = len(output.shape)\n     else:\n@@ -5606,8 +5604,6 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n             \"on an output tensor with unknown rank\".format(axis)\n         )\n \n-    target = cast(target, \"int64\")\n-\n     # Try to adjust the shape so that rank of labels = rank of logits - 1.\n     output_shape = tf.shape(output)\n     target_rank = target.shape.ndims\n@@ -5621,6 +5617,11 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n         target = flatten(target)\n         output = tf.reshape(output, [-1, output_shape[-1]])\n \n+    if ignore_class is not None:\n+        valid_mask = tf.not_equal(target, cast(ignore_class, target.dtype))\n+        target = target[valid_mask]\n+        output = output[valid_mask]\n+\n     if py_any(_is_symbolic_tensor(v) for v in [target, output]):\n         with get_graph().as_default():\n             res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n@@ -5631,13 +5632,21 @@ def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n             labels=target, logits=output\n         )\n \n-    if update_shape and output_rank >= 3:\n-        # If our output includes timesteps or spatial dimensions we need to\n-        # reshape\n-        return tf.reshape(res, output_shape[:-1])\n-    else:\n+    if ignore_class is not None:\n+        res_shape = cast(output_shape[:-1], \"int64\")\n+        valid_mask = tf.reshape(valid_mask, res_shape)\n+        res = tf.scatter_nd(tf.where(valid_mask), res, res_shape)\n+        res._keras_mask = valid_mask\n+\n         return res\n \n+    if update_shape and output_rank >= 3:\n+        # If our output includes timesteps or\n+        # spatial dimensions we need to reshape\n+        res = tf.reshape(res, output_shape[:-1])\n+\n+    return res\n+\n \n @keras_export(\"keras.backend.binary_crossentropy\")\n @tf.__internal__.dispatch.add_dispatch_support\n@@ -5658,38 +5667,14 @@ def binary_crossentropy(target, output, from_logits=False):\n     target = tf.convert_to_tensor(target)\n     output = tf.convert_to_tensor(output)\n \n-    # Use logits whenever they are available. `softmax` and `sigmoid`\n-    # activations cache logits on the `output` Tensor.\n-    if hasattr(output, \"_keras_logits\"):\n-        output = output._keras_logits\n-        if from_logits:\n-            warnings.warn(\n-                '\"`binary_crossentropy` received `from_logits=True`, '\n-                \"but the `output` argument was produced by a sigmoid \"\n-                \"or softmax activation and thus \"\n-                'does not represent logits. Was this intended?\"',\n-                stacklevel=2,\n-            )\n-        from_logits = True\n-\n+    output, from_logits = _get_logits(\n+        output, from_logits, \"Sigmoid\", \"binary_crossentropy\"\n+    )\n     if from_logits:\n         return tf.nn.sigmoid_cross_entropy_with_logits(\n             labels=target, logits=output\n         )\n \n-    if (\n-        not isinstance(output, (tf.__internal__.EagerTensor, tf.Variable))\n-        and output.op.type == \"Sigmoid\"\n-    ) and not hasattr(output, \"_keras_history\"):\n-        # When sigmoid activation function is used for output operation, we\n-        # use logits from the sigmoid function directly to compute loss in order\n-        # to prevent collapsing zero when training.\n-        assert len(output.op.inputs) == 1\n-        output = output.op.inputs[0]\n-        return tf.nn.sigmoid_cross_entropy_with_logits(\n-            labels=target, logits=output\n-        )\n-\n     epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n     output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\n \ndiff --git a/keras/backend_test.py b/keras/backend_test.py\nindex c9a6fb3e4d2..df848cfb88f 100644\n--- a/keras/backend_test.py\n+++ b/keras/backend_test.py\n@@ -28,6 +28,7 @@\n from keras.layers import activation\n from keras.layers.normalization import batch_normalization_v1\n from keras.testing_infra import test_combinations\n+from keras.utils import losses_utils\n from keras.utils import tf_inspect\n from keras.utils import tf_utils\n \n@@ -1969,6 +1970,88 @@ def test_sparse_categorical_crossentropy_loss(self):\n         )\n         self.assertArrayNear(self.evaluate(result)[0], [0.002, 0, 0.17], 1e-3)\n \n+    @test_combinations.generate(\n+        test_combinations.combine(mode=[\"graph\", \"eager\"])\n+    )\n+    def test_sparse_categorical_crossentropy_loss_with_ignore_class(self):\n+        tests = (([255, 1, 2, 2], 255), ([-1, 1, 2, 2], -1))\n+        p = backend.softmax(\n+            backend.constant(\n+                [\n+                    [1.8, 1.2, 0.5],\n+                    [0.2, 3.8, 0.8],\n+                    [1.1, 0.4, 3.4],\n+                    [1.3, 0.7, 3.8],\n+                ]\n+            )\n+        )\n+\n+        for t, ignore_class in tests:\n+            t = backend.constant(t)\n+            result = backend.sparse_categorical_crossentropy(\n+                t, p, ignore_class=ignore_class\n+            )\n+            self.assertArrayNear(\n+                self.evaluate(result),\n+                [0.0, 0.07428224, 0.13980183, 0.11967831],\n+                1e-3,\n+            )\n+\n+    @test_combinations.generate(\n+        test_combinations.combine(mode=[\"graph\", \"eager\"])\n+    )\n+    def test_sparse_cce_loss_with_ignore_class_for_segmentation(self):\n+        t = backend.constant(\n+            [[[0, 2], [-1, -1]], [[0, 2], [-1, -1]], [[0, 0], [0, 0]]]\n+        )\n+        p = backend.constant(\n+            [\n+                [\n+                    [[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n+                    [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]],\n+                ],\n+                [\n+                    [[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n+                    [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]],\n+                ],\n+                [\n+                    [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0]],\n+                    [[0.1, 0.9, 0.0], [0.2, 0.8, 0.0]],\n+                ],\n+            ]\n+        )\n+\n+        expected_result = [\n+            [[0.0, 0.0], [0.0, 0.0]],\n+            [[0.0, 0.693148], [0.0, 0.0]],\n+            [[0.0, 0.0], [2.302585, 1.609438]],\n+        ]\n+\n+        # total_entries = 12\n+        # valid_entries = 8\n+        expected_mask = backend.constant(\n+            [\n+                [[True, True], [False, False]],\n+                [[True, True], [False, False]],\n+                [[True, True], [True, True]],\n+            ]\n+        )\n+\n+        result = backend.sparse_categorical_crossentropy(t, p, ignore_class=-1)\n+        mask = losses_utils.get_mask(result)\n+\n+        self.assertIsNotNone(\n+            mask,\n+            \"expected sparse_categorical_crossentropy to set the \"\n+            \"`_keras_mask` attribute when `ignore_class is not None`, \"\n+            \"which indicates which loss values are valid.\",\n+        )\n+\n+        result = self.evaluate(result)\n+        mask = self.evaluate(mask)\n+        self.assertAllEqual(mask, expected_mask)\n+        self.assertAllClose(result, expected_result, atol=1e-6)\n+\n     @test_combinations.generate(test_combinations.combine(mode=[\"graph\"]))\n     def test_sparse_categorical_crossentropy_loss_with_unknown_rank_tensor(\n         self,\ndiff --git a/keras/engine/compile_utils.py b/keras/engine/compile_utils.py\nindex 6da3338117d..5e998e552ef 100644\n--- a/keras/engine/compile_utils.py\n+++ b/keras/engine/compile_utils.py\n@@ -261,7 +261,7 @@ def __call__(\n                 continue\n \n             y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n-            sw = apply_mask(y_p, sw, get_mask(y_p))\n+            sw = losses_utils.apply_mask(y_p, sw, losses_utils.get_mask(y_p))\n             loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n \n             total_loss_mean_value = loss_value\n@@ -596,8 +596,8 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n                 continue\n \n             y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n-            mask = get_mask(y_p)\n-            sw = apply_mask(y_p, sw, mask)\n+            mask = losses_utils.get_mask(y_p)\n+            sw = losses_utils.apply_mask(y_p, sw, mask)\n \n             for metric_obj in metric_objs:\n                 if metric_obj is None:\n@@ -847,25 +847,6 @@ def match_dtype_and_rank(y_t, y_p, sw):\n     return y_t, y_p, sw\n \n \n-def get_mask(y_p):\n-    \"\"\"Returns Keras mask from tensor.\"\"\"\n-    return getattr(y_p, \"_keras_mask\", None)\n-\n-\n-def apply_mask(y_p, sw, mask):\n-    \"\"\"Applies any mask on predictions to sample weights.\"\"\"\n-    if mask is not None:\n-        mask = tf.cast(mask, y_p.dtype)\n-        if sw is not None:\n-            mask, _, sw = losses_utils.squeeze_or_expand_dimensions(\n-                mask, sample_weight=sw\n-            )\n-            sw *= mask\n-        else:\n-            sw = mask\n-    return sw\n-\n-\n def get_custom_object_name(obj):\n     \"\"\"Returns the name to use for a custom loss or metric callable.\n \ndiff --git a/keras/losses.py b/keras/losses.py\nindex a754460226d..58f2309b5c5 100644\n--- a/keras/losses.py\n+++ b/keras/losses.py\n@@ -150,8 +150,13 @@ def __call__(self, y_true, y_pred, sample_weight=None):\n                     self.call, tf.__internal__.autograph.control_status_ctx()\n                 )\n             losses = call_fn(y_true, y_pred)\n+            mask = losses_utils.get_mask(losses)\n+            reduction = self._get_reduction()\n+            sample_weight = losses_utils.apply_valid_mask(\n+                losses, sample_weight, mask, reduction\n+            )\n             return losses_utils.compute_weighted_loss(\n-                losses, sample_weight, reduction=self._get_reduction()\n+                losses, sample_weight, reduction=reduction\n             )\n \n     @classmethod\n@@ -977,6 +982,7 @@ class SparseCategoricalCrossentropy(LossFunctionWrapper):\n     def __init__(\n         self,\n         from_logits=False,\n+        ignore_class=None,\n         reduction=losses_utils.ReductionV2.AUTO,\n         name=\"sparse_categorical_crossentropy\",\n     ):\n@@ -985,6 +991,11 @@ def __init__(\n         Args:\n           from_logits: Whether `y_pred` is expected to be a logits tensor. By\n             default, we assume that `y_pred` encodes a probability distribution.\n+          ignore_class: Optional integer. The ID of a class to be ignored during\n+            loss computation. This is useful, for example, in segmentation\n+            problems featuring a \"void\" class (commonly -1 or 255) in\n+            segmentation maps.\n+            By default (`ignore_class=None`), all classes are considered.\n           reduction: Type of `tf.keras.losses.Reduction` to apply to\n             loss. Default value is `AUTO`. `AUTO` indicates that the reduction\n             option will be determined by the usage context. For almost all cases\n@@ -1003,6 +1014,7 @@ def __init__(\n             name=name,\n             reduction=reduction,\n             from_logits=from_logits,\n+            ignore_class=ignore_class,\n         )\n \n \n@@ -2024,7 +2036,9 @@ def _ragged_tensor_categorical_crossentropy(\n     \"keras.losses.sparse_categorical_crossentropy\",\n )\n @tf.__internal__.dispatch.add_dispatch_support\n-def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):\n+def sparse_categorical_crossentropy(\n+    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None\n+):\n     \"\"\"Computes the sparse categorical crossentropy loss.\n \n     Standalone usage:\n@@ -2036,6 +2050,20 @@ def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):\n     >>> loss.numpy()\n     array([0.0513, 2.303], dtype=float32)\n \n+    >>> y_true = [[[ 0,  2],\n+    ...            [-1, -1]],\n+    ...           [[ 0,  2],\n+    ...            [-1, -1]]]\n+    >>> y_pred = [[[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n+                   [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]],\n+                  [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n+                   [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n+    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(\n+    ...   y_true, y_pred, ignore_class=-1)\n+    >>> assert loss.shape == (2,)\n+    >>> loss.numpy()\n+    array([2.3841855e-07, 3.4657377e-01], dtype=float32)\n+\n     Args:\n       y_true: Ground truth values.\n       y_pred: The predicted values.\n@@ -2043,20 +2071,26 @@ def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):\n         default, we assume that `y_pred` encodes a probability distribution.\n       axis: Defaults to -1. The dimension along which the entropy is\n         computed.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        loss computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n \n     Returns:\n       Sparse categorical crossentropy loss value.\n     \"\"\"\n-    y_pred = tf.convert_to_tensor(y_pred)\n-\n     return backend.sparse_categorical_crossentropy(\n-        y_true, y_pred, from_logits=from_logits, axis=axis\n+        y_true,\n+        y_pred,\n+        from_logits=from_logits,\n+        ignore_class=ignore_class,\n+        axis=axis,\n     )\n \n \n @dispatch.dispatch_for_types(sparse_categorical_crossentropy, tf.RaggedTensor)\n def _ragged_tensor_sparse_categorical_crossentropy(\n-    y_true, y_pred, from_logits=False, axis=-1\n+    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None\n ):\n     \"\"\"Implements support for handling RaggedTensors.\n \n@@ -2071,7 +2105,10 @@ def _ragged_tensor_sparse_categorical_crossentropy(\n     the sum of the individual loss values divided by 3.\n     \"\"\"\n     fn = functools.partial(\n-        sparse_categorical_crossentropy, from_logits=from_logits, axis=axis\n+        sparse_categorical_crossentropy,\n+        from_logits=from_logits,\n+        ignore_class=ignore_class,\n+        axis=axis,\n     )\n     return _ragged_tensor_apply_loss(fn, y_true, y_pred, y_pred_extra_dim=True)\n \ndiff --git a/keras/losses_test.py b/keras/losses_test.py\nindex c8980c89aa5..26ac4da14f7 100644\n--- a/keras/losses_test.py\n+++ b/keras/losses_test.py\n@@ -161,6 +161,36 @@ def test_sparse_categorical_crossentropy_loss(self):\n             atol=1e-5,\n         )\n \n+    @test_combinations.generate(\n+        test_combinations.combine(mode=[\"graph\", \"eager\"])\n+    )\n+    def test_sparse_categorical_crossentropy_loss_with_ignore_class(self):\n+        ignore_class = 255\n+        target = backend.variable(np.random.randint(0, 1, (5, 1)))\n+        logits = backend.variable(np.random.random((5, 1)))\n+        softmax_output = backend.softmax(logits)\n+\n+        _valid = tf.constant([[0], [1], [0], [1], [1]], target.dtype)\n+        target.assign(target * _valid + (1 - _valid) * ignore_class)\n+\n+        output_from_logit = losses.sparse_categorical_crossentropy(\n+            target, logits, ignore_class=ignore_class, from_logits=True\n+        )\n+        output_from_softmax = losses.sparse_categorical_crossentropy(\n+            target, softmax_output, ignore_class=ignore_class\n+        )\n+\n+        # expected_mask = [False, True, False, True, True]\n+        # for o in (output_from_logit, output_from_softmax):\n+        #     mask = backend.eval(losses_utils.get_mask(o))\n+        #     np.testing.assert_array_equal(mask, expected_mask)\n+\n+        np.testing.assert_allclose(\n+            backend.eval(output_from_logit),\n+            backend.eval(output_from_softmax),\n+            atol=1e-5,\n+        )\n+\n     @test_combinations.generate(test_combinations.combine(mode=[\"graph\"]))\n     def test_sparse_categorical_crossentropy_loss_with_unknown_rank_tensor(\n         self,\n@@ -1810,6 +1840,70 @@ def test_unweighted(self):\n         loss = cce_obj(y_true, logits)\n         self.assertAlmostEqual(self.evaluate(loss), 0.0573, 3)\n \n+    def test_unweighted_ignore_class(self):\n+        cce_obj = losses.SparseCategoricalCrossentropy(ignore_class=-1)\n+        y_true = tf.constant([0, 1, 2, -1])\n+        y_pred = tf.constant(\n+            [\n+                [0.9, 0.05, 0.05],\n+                [0.5, 0.89, 0.6],\n+                [0.05, 0.01, 0.94],\n+                [0.85, 0.14, 0.01],\n+            ],\n+            dtype=tf.float32,\n+        )\n+        loss = cce_obj(y_true, y_pred)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.3239, 3)\n+\n+        # Test with logits.\n+        logits = tf.constant(\n+            [[8.0, 1.0, 1.0], [0.0, 9.0, 1.0], [2.0, 3.0, 5.0], [7.8, 2.0, 1.0]]\n+        )\n+        cce_obj = losses.SparseCategoricalCrossentropy(\n+            ignore_class=-1, from_logits=True\n+        )\n+        loss = cce_obj(y_true, logits)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.0573, 3)\n+\n+    def test_unweighted_ignore_class_for_segmentation(self):\n+        cce_obj = losses.SparseCategoricalCrossentropy(ignore_class=-1)\n+        y_true = tf.constant(\n+            [[[0, 2], [-1, -1]], [[0, 2], [-1, -1]], [[0, 0], [0, 0]]]\n+        )\n+        y_pred = tf.constant(\n+            [\n+                [\n+                    [[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n+                    [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]],\n+                ],\n+                [\n+                    [[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n+                    [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]],\n+                ],\n+                [\n+                    [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0]],\n+                    [[0.1, 0.9, 0.0], [0.2, 0.8, 0.0]],\n+                ],\n+            ],\n+            dtype=tf.float32,\n+        )\n+\n+        # Expected loss values:\n+        # [[0.0, 0.0], [0.0, 0.0]],\n+        # [[0.0, 0.693148], [0.0, 0.0]],\n+        # [[0.0, 0.0], [2.302585, 1.609438]],\n+\n+        loss = cce_obj(y_true, y_pred)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.575646375, 3)\n+\n+        # # Test with logits.\n+        # logits = tf.constant(\n+        #     [[8.0, 1.0, 1.0], [0.0, 9.0, 1.0], [2.0, 3.0, 5.0]]\n+        # )\n+        # cce_obj = losses.SparseCategoricalCrossentropy(from_logits=True)\n+        # loss = cce_obj(y_true, logits)\n+        # self.assertAlmostEqual(self.evaluate(loss), 0.0573, 3)\n+\n     def test_scalar_weighted(self):\n         cce_obj = losses.SparseCategoricalCrossentropy()\n         y_true = tf.constant([[0], [1], [2]])\n@@ -1847,6 +1941,32 @@ def test_sample_weighted(self):\n         loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n         self.assertAlmostEqual(self.evaluate(loss), 0.31829, 3)\n \n+    def test_sample_weighted_ignore_class(self):\n+        cce_obj = losses.SparseCategoricalCrossentropy(ignore_class=-1)\n+        y_true = tf.constant([[0], [1], [2], [-1]])\n+        y_pred = tf.constant(\n+            [\n+                [0.9, 0.05, 0.05],\n+                [0.5, 0.89, 0.6],\n+                [0.05, 0.01, 0.94],\n+                [0.85, 0.14, 0.01],\n+            ],\n+            dtype=tf.float32,\n+        )\n+        sample_weight = tf.constant([[1.2], [3.4], [5.6], [10.4]], shape=(4, 1))\n+        loss = cce_obj(y_true, y_pred, sample_weight=sample_weight)\n+        self.assertAlmostEqual(self.evaluate(loss), 1.0696, 3)\n+\n+        # Test with logits.\n+        logits = tf.constant(\n+            [[8.0, 1.0, 1.0], [0.0, 9.0, 1.0], [2.0, 3.0, 5.0], [7.8, 2.0, 1.0]]\n+        )\n+        cce_obj = losses.SparseCategoricalCrossentropy(\n+            ignore_class=-1, from_logits=True\n+        )\n+        loss = cce_obj(y_true, logits, sample_weight=sample_weight)\n+        self.assertAlmostEqual(self.evaluate(loss), 0.31829, 3)\n+\n     def test_no_reduction(self):\n         y_true = tf.constant([[0], [1], [2]])\n         logits = tf.constant(\ndiff --git a/keras/metrics/base_metric.py b/keras/metrics/base_metric.py\nindex afab9681e01..b2c8a4e1c04 100644\n--- a/keras/metrics/base_metric.py\n+++ b/keras/metrics/base_metric.py\n@@ -698,6 +698,10 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n             self._fn, tf.__internal__.autograph.control_status_ctx()\n         )\n         matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n+        mask = losses_utils.get_mask(matches)\n+        sample_weight = losses_utils.apply_valid_mask(\n+            matches, sample_weight, mask, self.reduction\n+        )\n         return super().update_state(matches, sample_weight=sample_weight)\n \n     def get_config(self):\n@@ -915,6 +919,10 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n             self._fn, tf.__internal__.autograph.control_status_ctx()\n         )\n         matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n+        mask = losses_utils.get_mask(matches)\n+        sample_weight = losses_utils.apply_valid_mask(\n+            matches, sample_weight, mask, self.reduction\n+        )\n         return super().update_state(matches, sample_weight=sample_weight)\n \n     def get_config(self):\ndiff --git a/keras/metrics/metrics.py b/keras/metrics/metrics.py\nindex d1d6a50e0c9..41c69d8564f 100644\n--- a/keras/metrics/metrics.py\n+++ b/keras/metrics/metrics.py\n@@ -18,6 +18,7 @@\n \n import abc\n from typing import List\n+from typing import Optional\n from typing import Tuple\n from typing import Union\n \n@@ -2645,11 +2646,36 @@ class _IoUBase(base_metric.Metric):\n         `(num_classes, num_classes)` will be allocated.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      sparse_y_true: Whether labels are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      sparse_y_pred: Whether predictions are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      axis: (Optional) Defaults to -1. The dimension containing the logits.\n+\n     \"\"\"\n \n-    def __init__(self, num_classes, name=None, dtype=None):\n+    def __init__(\n+        self,\n+        num_classes: int,\n+        name: Optional[str] = None,\n+        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n+        ignore_class: Optional[int] = None,\n+        sparse_y_true: bool = True,\n+        sparse_y_pred: bool = True,\n+        axis: int = -1,\n+    ):\n         super().__init__(name=name, dtype=dtype)\n         self.num_classes = num_classes\n+        self.ignore_class = ignore_class\n+        self.sparse_y_true = sparse_y_true\n+        self.sparse_y_pred = sparse_y_pred\n+        self.axis = axis\n \n         # Variable to accumulate the predictions in the confusion matrix.\n         self.total_cm = self.add_weight(\n@@ -2672,6 +2698,11 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n           Update op.\n         \"\"\"\n \n+        if not self.sparse_y_true:\n+            y_true = tf.argmax(y_true, axis=self.axis)\n+        if not self.sparse_y_pred:\n+            y_pred = tf.argmax(y_pred, axis=self.axis)\n+\n         y_true = tf.cast(y_true, self._dtype)\n         y_pred = tf.cast(y_pred, self._dtype)\n \n@@ -2687,6 +2718,14 @@ def update_state(self, y_true, y_pred, sample_weight=None):\n             if sample_weight.shape.ndims > 1:\n                 sample_weight = tf.reshape(sample_weight, [-1])\n \n+        if self.ignore_class is not None:\n+            ignore_class = tf.cast(self.ignore_class, y_true.dtype)\n+            valid_mask = tf.not_equal(y_true, ignore_class)\n+            y_true = y_true[valid_mask]\n+            y_pred = y_pred[valid_mask]\n+            if sample_weight is not None:\n+                sample_weight = sample_weight[valid_mask]\n+\n         # Accumulate the prediction to current confusion matrix.\n         current_cm = tf.math.confusion_matrix(\n             y_true,\n@@ -2738,6 +2777,17 @@ class IoU(_IoUBase):\n         single id value should be provided.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      sparse_y_true: Whether labels are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      sparse_y_pred: Whether predictions are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      axis: (Optional) Defaults to -1. The dimension containing the logits.\n \n     Standalone usage:\n \n@@ -2777,12 +2827,20 @@ def __init__(\n         self,\n         num_classes: int,\n         target_class_ids: Union[List[int], Tuple[int, ...]],\n-        name=None,\n-        dtype=None,\n+        name: Optional[str] = None,\n+        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n+        ignore_class: Optional[int] = None,\n+        sparse_y_true: bool = True,\n+        sparse_y_pred: bool = True,\n+        axis: int = -1,\n     ):\n         super().__init__(\n             name=name,\n             num_classes=num_classes,\n+            ignore_class=ignore_class,\n+            sparse_y_true=sparse_y_true,\n+            sparse_y_pred=sparse_y_pred,\n+            axis=axis,\n             dtype=dtype,\n         )\n         if max(target_class_ids) >= num_classes:\n@@ -2828,6 +2886,10 @@ def get_config(self):\n         config = {\n             \"num_classes\": self.num_classes,\n             \"target_class_ids\": self.target_class_ids,\n+            \"ignore_class\": self.ignore_class,\n+            \"sparse_y_true\": self.sparse_y_true,\n+            \"sparse_y_pred\": self.sparse_y_pred,\n+            \"axis\": self.axis,\n         }\n         base_config = super().get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n@@ -2983,6 +3045,17 @@ class MeanIoU(IoU):\n         [num_classes, num_classes] will be allocated.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      sparse_y_true: Whether labels are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      sparse_y_pred: Whether predictions are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      axis: (Optional) Defaults to -1. The dimension containing the logits.\n \n     Standalone usage:\n \n@@ -3013,13 +3086,26 @@ class MeanIoU(IoU):\n     \"\"\"\n \n     @dtensor_utils.inject_mesh\n-    def __init__(self, num_classes, name=None, dtype=None):\n+    def __init__(\n+        self,\n+        num_classes: int,\n+        name: Optional[str] = None,\n+        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n+        ignore_class: Optional[int] = None,\n+        sparse_y_true: bool = True,\n+        sparse_y_pred: bool = True,\n+        axis: int = -1,\n+    ):\n         target_class_ids = list(range(num_classes))\n         super().__init__(\n             name=name,\n             num_classes=num_classes,\n             target_class_ids=target_class_ids,\n+            axis=axis,\n             dtype=dtype,\n+            ignore_class=ignore_class,\n+            sparse_y_true=sparse_y_true,\n+            sparse_y_pred=sparse_y_pred,\n         )\n \n     def get_config(self):\n@@ -3027,6 +3113,10 @@ def get_config(self):\n             \"num_classes\": self.num_classes,\n             \"name\": self.name,\n             \"dtype\": self._dtype,\n+            \"ignore_class\": self.ignore_class,\n+            \"sparse_y_true\": self.sparse_y_true,\n+            \"sparse_y_pred\": self.sparse_y_pred,\n+            \"axis\": self.axis,\n         }\n \n \n@@ -3074,6 +3164,14 @@ class OneHotIoU(IoU):\n         single id value should be provided.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      sparse_y_pred: Whether predictions are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      axis: (Optional) Defaults to -1. The dimension containing the logits.\n \n     Standalone usage:\n \n@@ -3111,32 +3209,31 @@ def __init__(\n         target_class_ids: Union[List[int], Tuple[int, ...]],\n         name=None,\n         dtype=None,\n+        ignore_class: Optional[int] = None,\n+        sparse_y_pred: bool = False,\n+        axis: int = -1,\n     ):\n         super().__init__(\n             num_classes=num_classes,\n             target_class_ids=target_class_ids,\n             name=name,\n             dtype=dtype,\n+            ignore_class=ignore_class,\n+            sparse_y_true=False,\n+            sparse_y_pred=sparse_y_pred,\n+            axis=axis,\n         )\n \n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        \"\"\"Accumulates the confusion matrix statistics.\n-\n-        Args:\n-          y_true: The ground truth values.\n-          y_pred: The predicted values.\n-          sample_weight: Optional weighting of each example. Defaults to 1. Can\n-            be a `Tensor` whose rank is either 0, or the same rank as `y_true`,\n-            and must be broadcastable to `y_true`.\n-\n-        Returns:\n-          Update op.\n-        \"\"\"\n-        # Select max hot-encoding channels to convert into all-class format\n-        y_true = tf.argmax(y_true, axis=-1, output_type=tf.int32)\n-        y_pred = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n-\n-        return super().update_state(y_true, y_pred, sample_weight)\n+    def get_config(self):\n+        return {\n+            \"num_classes\": self.num_classes,\n+            \"target_class_ids\": self.target_class_ids,\n+            \"name\": self.name,\n+            \"dtype\": self._dtype,\n+            \"ignore_class\": self.ignore_class,\n+            \"sparse_y_pred\": self.sparse_y_pred,\n+            \"axis\": self.axis,\n+        }\n \n \n @keras_export(\"keras.metrics.OneHotMeanIoU\")\n@@ -3181,6 +3278,14 @@ class apply.\n         allocated to accumulate predictions from which the metric is calculated.\n       name: (Optional) string name of the metric instance.\n       dtype: (Optional) data type of the metric result.\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      sparse_y_pred: Whether predictions are encoded using natural numbers or\n+        probability distribution vectors. If `False`, the `tf.argmax` function\n+        will be used to determine each sample's most likely associated label.\n+      axis: (Optional) Defaults to -1. The dimension containing the logits.\n \n     Standalone usage:\n \n@@ -3215,33 +3320,31 @@ class apply.\n     def __init__(\n         self,\n         num_classes: int,\n-        name=None,\n-        dtype=None,\n+        name: str = None,\n+        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n+        ignore_class: Optional[int] = None,\n+        sparse_y_pred: bool = False,\n+        axis: int = -1,\n     ):\n         super().__init__(\n             num_classes=num_classes,\n+            axis=axis,\n             name=name,\n             dtype=dtype,\n+            ignore_class=ignore_class,\n+            sparse_y_true=False,\n+            sparse_y_pred=sparse_y_pred,\n         )\n \n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        \"\"\"Accumulates the confusion matrix statistics.\n-\n-        Args:\n-          y_true: The ground truth values.\n-          y_pred: The predicted values.\n-          sample_weight: Optional weighting of each example. Defaults to 1. Can\n-            be a `Tensor` whose rank is either 0, or the same rank as `y_true`,\n-            and must be broadcastable to `y_true`.\n-\n-        Returns:\n-          Update op.\n-        \"\"\"\n-        # Select max hot-encoding channels to convert into all-class format\n-        y_true = tf.argmax(y_true, axis=-1, output_type=tf.int32)\n-        y_pred = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n-\n-        return super().update_state(y_true, y_pred, sample_weight)\n+    def get_config(self):\n+        return {\n+            \"num_classes\": self.num_classes,\n+            \"name\": self.name,\n+            \"dtype\": self._dtype,\n+            \"ignore_class\": self.ignore_class,\n+            \"sparse_y_pred\": self.sparse_y_pred,\n+            \"axis\": self.axis,\n+        }\n \n \n @keras_export(\"keras.metrics.BinaryCrossentropy\")\n@@ -3319,6 +3422,8 @@ class CategoricalCrossentropy(base_metric.MeanMetricWrapper):\n         smoothed, meaning the confidence on label values are relaxed. e.g.\n         `label_smoothing=0.2` means that we will use a value of `0.1` for label\n         `0` and `0.9` for label `1`\"\n+      axis: (Optional) Defaults to -1. The dimension along which entropy is\n+        computed.\n \n     Standalone usage:\n \n@@ -3359,6 +3464,7 @@ def __init__(\n         dtype=None,\n         from_logits=False,\n         label_smoothing=0,\n+        axis=-1,\n     ):\n         super().__init__(\n             categorical_crossentropy,\n@@ -3366,6 +3472,7 @@ def __init__(\n             dtype=dtype,\n             from_logits=from_logits,\n             label_smoothing=label_smoothing,\n+            axis=axis,\n         )\n \n \n@@ -3389,7 +3496,11 @@ class SparseCategoricalCrossentropy(base_metric.MeanMetricWrapper):\n       dtype: (Optional) data type of the metric result.\n       from_logits: (Optional) Whether output is expected to be a logits tensor.\n         By default, we consider that output encodes a probability distribution.\n-      axis: (Optional) Defaults to -1. The dimension along which the metric is\n+      ignore_class: Optional integer. The ID of a class to be ignored during\n+        metric computation. This is useful, for example, in segmentation\n+        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n+        maps. By default (`ignore_class=None`), all classes are considered.\n+      axis: (Optional) Defaults to -1. The dimension along which entropy is\n         computed.\n \n     Standalone usage:\n@@ -3430,16 +3541,18 @@ class SparseCategoricalCrossentropy(base_metric.MeanMetricWrapper):\n     @dtensor_utils.inject_mesh\n     def __init__(\n         self,\n-        name=\"sparse_categorical_crossentropy\",\n-        dtype=None,\n-        from_logits=False,\n-        axis=-1,\n+        name: str = \"sparse_categorical_crossentropy\",\n+        dtype: Optional[Union[str, tf.dtypes.DType]] = None,\n+        from_logits: bool = False,\n+        ignore_class: Optional[int] = None,\n+        axis: int = -1,\n     ):\n         super().__init__(\n             sparse_categorical_crossentropy,\n             name,\n             dtype=dtype,\n             from_logits=from_logits,\n+            ignore_class=ignore_class,\n             axis=axis,\n         )\n \ndiff --git a/keras/metrics/metrics_test.py b/keras/metrics/metrics_test.py\nindex 01ae71b6d35..cd88e7a21e5 100644\n--- a/keras/metrics/metrics_test.py\n+++ b/keras/metrics/metrics_test.py\n@@ -1282,6 +1282,44 @@ def test_unweighted(self):\n         expected_result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2\n         self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n \n+    def test_unweighted_ignore_class_255(self):\n+        y_pred = [0, 1, 1, 1]\n+        y_true = [0, 1, 2, 255]\n+\n+        m_obj = metrics.MeanIoU(num_classes=3, ignore_class=255)\n+        self.evaluate(tf.compat.v1.variables_initializer(m_obj.variables))\n+\n+        result = m_obj(y_true, y_pred)\n+\n+        # cm = [[1, 0, 0],\n+        #       [0, 1, 0],\n+        #       [0, 1, 0]]\n+        # sum_row = [1, 1, 1], sum_col = [1, 2, 0], true_positives = [1, 1, 0]\n+        # iou = true_positives / (sum_row + sum_col - true_positives))\n+        expected_result = (\n+            1 / (1 + 1 - 1) + 1 / (2 + 1 - 1) + 0 / (0 + 1 - 0)\n+        ) / 3\n+        self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n+    def test_unweighted_ignore_class_1(self):\n+        y_pred = [0, 1, 1, 1]\n+        y_true = [0, 1, 2, -1]\n+\n+        m_obj = metrics.MeanIoU(num_classes=3, ignore_class=-1)\n+        self.evaluate(tf.compat.v1.variables_initializer(m_obj.variables))\n+\n+        result = m_obj(y_true, y_pred)\n+\n+        # cm = [[1, 0, 0],\n+        #       [0, 1, 0],\n+        #       [0, 1, 0]]\n+        # sum_row = [1, 1, 1], sum_col = [1, 2, 0], true_positives = [1, 1, 0]\n+        # iou = true_positives / (sum_row + sum_col - true_positives))\n+        expected_result = (\n+            1 / (1 + 1 - 1) + 1 / (2 + 1 - 1) + 0 / (0 + 1 - 0)\n+        ) / 3\n+        self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n     def test_weighted(self):\n         y_pred = tf.constant([0, 1, 0, 1], dtype=tf.float32)\n         y_true = tf.constant([0, 0, 1, 1])\n@@ -1302,6 +1340,26 @@ def test_weighted(self):\n         ) / 2\n         self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n \n+    def test_weighted_ignore_class_1(self):\n+        y_pred = tf.constant([0, 1, 0, 1], dtype=tf.float32)\n+        y_true = tf.constant([0, 0, 1, -1])\n+        sample_weight = tf.constant([0.2, 0.3, 0.4, 0.1])\n+\n+        m_obj = metrics.MeanIoU(num_classes=2, ignore_class=-1)\n+        self.evaluate(tf.compat.v1.variables_initializer(m_obj.variables))\n+\n+        result = m_obj(y_true, y_pred, sample_weight=sample_weight)\n+\n+        # cm = [[0.2, 0.3],\n+        #       [0.4, 0.0]]\n+        # sum_row = [0.6, 0.3], sum_col = [0.5, 0.4], true_positives = [0.2,\n+        # 0.0]\n+        # iou = true_positives / (sum_row + sum_col - true_positives))\n+        expected_result = (\n+            0.2 / (0.6 + 0.5 - 0.2) + 0.0 / (0.3 + 0.4 - 0.0)\n+        ) / 2\n+        self.assertAllClose(self.evaluate(result), expected_result, atol=1e-3)\n+\n     def test_multi_dim_input(self):\n         y_pred = tf.constant([[0, 1], [0, 1]], dtype=tf.float32)\n         y_true = tf.constant([[0, 0], [1, 1]])\n@@ -1736,6 +1794,16 @@ def test_unweighted(self):\n \n         self.assertAllClose(self.evaluate(result), 1.176, atol=1e-3)\n \n+    def test_unweighted_ignore_class(self):\n+        scce_obj = metrics.SparseCategoricalCrossentropy(ignore_class=-1)\n+        self.evaluate(tf.compat.v1.variables_initializer(scce_obj.variables))\n+\n+        y_true = np.asarray([-1, 2])\n+        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n+        result = scce_obj(y_true, y_pred)\n+\n+        self.assertAllClose(self.evaluate(result), 2.3026, atol=1e-3)\n+\n     def test_unweighted_from_logits(self):\n         scce_obj = metrics.SparseCategoricalCrossentropy(from_logits=True)\n         self.evaluate(tf.compat.v1.variables_initializer(scce_obj.variables))\n@@ -1790,6 +1858,17 @@ def test_weighted(self):\n \n         self.assertAllClose(self.evaluate(result), 1.338, atol=1e-3)\n \n+    def test_weighted_ignore_class(self):\n+        scce_obj = metrics.SparseCategoricalCrossentropy(ignore_class=-1)\n+        self.evaluate(tf.compat.v1.variables_initializer(scce_obj.variables))\n+\n+        y_true = np.asarray([1, 2, -1])\n+        y_pred = np.asarray([[0.05, 0.95, 0], [0.1, 0.8, 0.1], [0.1, 0.8, 0.1]])\n+        sample_weight = tf.constant([1.5, 2.0, 1.5])\n+        result = scce_obj(y_true, y_pred, sample_weight=sample_weight)\n+\n+        self.assertAllClose(self.evaluate(result), 1.338, atol=1e-3)\n+\n     def test_weighted_from_logits(self):\n         scce_obj = metrics.SparseCategoricalCrossentropy(from_logits=True)\n         self.evaluate(tf.compat.v1.variables_initializer(scce_obj.variables))\ndiff --git a/keras/utils/losses_utils.py b/keras/utils/losses_utils.py\nindex 4ee816d2d04..975daea8063 100644\n--- a/keras/utils/losses_utils.py\n+++ b/keras/utils/losses_utils.py\n@@ -393,3 +393,41 @@ def cast_losses_to_common_dtype(losses):\n     if highest_float:\n         losses = [tf.cast(loss, highest_float) for loss in losses]\n     return losses\n+\n+\n+def get_mask(y_p):\n+    \"\"\"Returns Keras mask from tensor.\"\"\"\n+    return getattr(y_p, \"_keras_mask\", None)\n+\n+\n+def apply_mask(y_p, sw, mask):\n+    \"\"\"Applies any mask on predictions to sample weights.\"\"\"\n+    if mask is not None:\n+        mask = tf.cast(mask, y_p.dtype)\n+        if sw is not None:\n+            mask, _, sw = squeeze_or_expand_dimensions(mask, sample_weight=sw)\n+            sw *= mask\n+        else:\n+            sw = mask\n+    return sw\n+\n+\n+def apply_valid_mask(losses, sw, mask, reduction):\n+    \"\"\"Redistribute sample weights considering only valid entries.\"\"\"\n+    if mask is not None:\n+        mask = tf.cast(mask, losses.dtype)\n+\n+        if reduction in (ReductionV2.AUTO, ReductionV2.SUM_OVER_BATCH_SIZE):\n+            # Valid entries have weight `total/valid`, while invalid ones\n+            # have 0. When summed over batch, they will be reduced to:\n+            #\n+            # mean(loss * sample_weight * total / valid)\n+            #   = sum(loss * sample_weight * total / valid) / total\n+            #   = sum(loss * sample_weight) / total * total / valid\n+            #   = sum(loss * sample_weight) / valid\n+\n+            total = tf.cast(tf.size(mask), losses.dtype)\n+            valid = tf.reduce_sum(mask)\n+            mask *= total / valid\n+\n+    return apply_mask(losses, sw, mask)\n",
        "reviews": [
            {
                "reviewer": "fchollet",
                "state": "COMMENTED",
                "body": "Thanks for the PR. Wouldn't `ignore_class` be a more explicit / precise name for this argument?"
            },
            {
                "reviewer": "fchollet",
                "state": "COMMENTED",
                "body": "Thanks for the update!"
            },
            {
                "reviewer": "lucasdavid",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "fchollet",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "lucasdavid",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "fchollet",
                "state": "COMMENTED",
                "body": "Thanks for the updates. The changes all look good to me!"
            },
            {
                "reviewer": "lucasdavid",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "lucasdavid",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "fchollet",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "fchollet",
                "state": "COMMENTED",
                "body": "Thanks for the answers!"
            },
            {
                "reviewer": "fchollet",
                "state": "APPROVED",
                "body": "Excellent work, thank you for the contribution. LGTM"
            }
        ],
        "comments": [
            {
                "commenter": "lucasdavid",
                "body": "> Wouldn't `ignore_class` be a more explicit / precise name for this argument?\r\n\r\nI named it after torch's, hopping that people would make the association transparently. Furthermore, I think caffe called it `ignore_label`.\r\nAll are good choices, in my opinion. Let me know which one should I keep.\r\n\r\n> The new argument should be at the end of the signature.\r\n\r\nShould I use the same parameter order in the modules (losses, metrics)?\r\n\r\n> This description is not understandable for someone who does not already know what the argument does.\r\n\r\nI fixed it. Let me know if it still needs improvement."
            },
            {
                "commenter": "fchollet",
                "body": "> I named it after torch's, hopping that people would make the association transparently. Furthermore, I think caffe called it ignore_label.\r\n\r\n`ignore_index` is confusing, because an \"index\" is typically an integer you use for indexing an array, something like `x[4]`, etc. If you ask someone, \"I want to ignore index 2 in my crossentropy loss\", is that readily understandable? I'm not so sure. It seems far too imprecise, you don't know what \"index\" refers to in the context of a crossentropy loss.\r\n\r\n`ignore_label` is slightly incorrect because a \"label\" is a class annotation for a specific sample (an instance of a class). We're looking to ignore an entire class here. People often get class and label confused. It starts mattering in multi-label tasks.\r\n\r\n`ignore_class` is precise (it tells you *what* you want to ignore: a class from your class set) and accurate (you're talking a class in general, not a label attached to a sample).\r\n\r\n"
            },
            {
                "commenter": "lucasdavid",
                "body": "Some pixels in the segmentation map were ignored, which means cross-entropy values weren't computed for them (I only pass valid pixels for `tf.nn.sparse_softmax_cross_entropy_with_logits`, and then `tf.scatter_nd` them into a new tensor with the original shape). Thus the non-ignored pixels have correct cross-entropy values and the ignored ones have zeros.\r\nNow we have to average them considering **only** the valid pixels. Leaving reduction for `losses_utils.compute_weighted_loss` (which uses `tf.reduce_mean` or `tf.reduce_sum`) would be incorrect, because it would also consider these zeros into the mix and artificially reduce the cost value.\r\n\r\nHere is an example with a batch of *one* sample, that is a segmentation map of size *(2, 2)* containing up to *three* classes:\r\n```py\r\ny_true = [\r\n  [[ 0,  2],\r\n   [-1, -1]]]\r\ny_pred = [\r\n  [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\r\n   [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\r\n```\r\nIf we were to ignore `-1`, then `backend.sparse_categorical_crossentropy` proceeds as:\r\n```py\r\nvalid_mask = [[               # L5621\r\n  [True, True],\r\n  [False, False],\r\n]]\r\ntarget = [0, 2]               # L5622 (select valid pixel labels)\r\noutput = tf.math.log(y_pred)  # L5585, not from_logits\r\noutput = [\r\n  [ 0.  ,    -inf,    -inf],\r\n  [ -inf, -0.6931, -0.6931]]  # L5623 (select probabilities associated with valid pixels)\r\nres = [0., 0.6931]  # L5631 (tf.nn.softmax_crossentropy...)\r\nres = [\r\n  [[ 0., 0.6931],\r\n   [ 0., 0.    ]]]  # L5639 (reconstruct samples with tf.scatter_nd)\r\nres = [0.3466]      # L5647 (average amongst valid pixels -- the two in the top row)\r\n```\r\n\r\n`res` will contain the exact number of samples (so `sample_weight` still works), while all invalid pixels were ignored when computing the cost function value for each sample. Does it make sense?\r\n\r\n---\r\n\r\nFor reference, pytorch works similarly (implementation at [aten/src/ATen/native/LossNLL.cpp](https://github.com/pytorch/pytorch/blob/5af48581b5098eefaaa8b7ec55a5fabc5027c8e5/aten/src/ATen/native/LossNLL.cpp#L554-L567)):\r\n> ignore_index ([int](https://docs.python.org/3/library/functions.html#int), optional) \u2013 Specifies a target value that is ignored and does not contribute to the input gradient. When size_average is True, the loss is averaged over non-ignored targets. Note that ignore_index is only applicable when the target contains class indices.\r\n\r\nThis \"issue\" isn't as apparent because the low level loss function is also responsible for doing the reduction:\r\n```py\r\n>>> y_true = torch.tensor([\r\n...  [[ 0,  2],\r\n...   [-1, -1]]])\r\n>>> y_pred = torch.from_numpy(np.asarray([\r\n... [[1.0, 0.0, 0.0], [0.0, 0.5, .5]],\r\n... [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]).transpose((2, 0, 1))[np.newaxis, ...])\r\n>>>\r\n>>> loss=torch.nn.CrossEntropyLoss(ignore_index=-1)\r\n>>> loss(torch.log(y_pred), y_true)\r\ntensor(0.3466, dtype=torch.float64)\r\n>>> loss=torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='none')\r\n>>> loss(torch.log(y_pred), y_true)\r\ntensor([[[-0.0000, 0.6931],\r\n         [ 0.0000, 0.0000]]], dtype=torch.float64)\r\n```"
            },
            {
                "commenter": "fchollet",
                "body": "Thanks for the clear explanation.\r\n\r\nLoss reduction is something that needs to be factored separately, in a way that is orthogonal to samplewise loss value computation. Loss reduction needs to be controllable by the user when writing custom distributed training loops.\r\n\r\nThe way we configure loss reduction is via the `reduction` argument in the `Loss` class. So that calling `SparseCategoricalCrossentropy(reduction=\"auto\")` will reduce your loss, but calling `sparse_categorical_crossentropy` will not.\r\n\r\nIMO `sparse_categorical_crossentropy(..., ignore_class=-1)` should return non-reduced values with 0s for ignored values. \r\n\r\nThen  `SparseCategoricalCrossentropy()` when called with `ignore_class` will also compute a mask for the ignored values, and will merge this mask with `sample_weight` when performing reduction.\r\n\r\nWe can achieve this with the following change, that generalizes to every situation:\r\n\r\nSee `losses.py`, the following paragraph:\r\n\r\n```python\r\n            losses = call_fn(y_true, y_pred)\r\n            return losses_utils.compute_weighted_loss(\r\n                losses, sample_weight, reduction=self._get_reduction()\r\n            )\r\n```\r\n\r\nIn Keras in general it is possible to annotate a tensor with a mask by setting the `._keras_mask` attribute. Here we never expected that a loss function would set this mask, so we don't take into account, but in the general case we should do something like:\r\n\r\n```python\r\n            losses = call_fn(y_true, y_pred)\r\n            mask = getattr(losses, '_keras_mask', None)\r\n            if mask:\r\n                sample_weight = merge(sample_weight, mask)\r\n            return losses_utils.compute_weighted_loss(\r\n                losses, sample_weight, reduction=self._get_reduction()\r\n            )\r\n```\r\n\r\nIf we do this, then `sparse_categorical_crossentropy(..., ignore_class=-1)` can simply return 0s for masked entries, and also set `_keras_mask` as an attribute on the return tensor.\r\n\r\nFor end users, everything will work as expected. Standalone usage of the function should go to `SparseCategoricalCrossentropy()` which will do reduction for you.\r\n\r\n"
            },
            {
                "commenter": "lucasdavid",
                "body": "\r\n> Loss reduction needs to be controllable by the user when writing custom distributed training loops.\r\n\r\nI understand that the batch (first axis) should not be reduced in distributed environments. However, considering that we don't split a single sample in multiple replicas and that the default reduction is called `SUM_OVER_BATCH_SIZE`, I don't quite see the problem in reducing the remaining (within sample) axes.\r\n\r\n---\r\n\r\nI implemented it as you asked. I reused existing `get_mask` and `apply_mask` functions from the `compile_utils` module (moved them to `losses_utils` to avoid a cyclical import). Let me know if more test cases are required.\r\n\r\nI admit that `sparse_categorical_crossentropy` is more consistent now, but code had to be added to at least three different classes in order to achieve the same result (`losses.Loss`, `metrics.MeanMetricWrapper` and `metrics.SumOverBatchSizeMetricWrapper`). More importantly, now `sparse_categorical_crossentropy(ignore_index=...)` returns 0s that should be ignored, so it's one more thing for people with custom training operations to worry about.\r\n\r\nWe probably need to write an example in the docstring of how to handle these in custom training loops, right?\r\n\r\n\r\n"
            },
            {
                "commenter": "lucasdavid",
                "body": "@fchollet is the PR being rolled back? Did I break something?"
            },
            {
                "commenter": "visionscaper",
                "body": "@lucasdavid @fchollet Keras and TF are not in sync with respect to this new feature:\r\n\r\n * The TF v2.10.0 documentation for [`SparseCategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) mentions the `ignore_class` parameter\r\n * `tf.keras.losses.SparseCategoricalCrossentropy` code (v2.10.0) does not support the `ignore_class` parameter\r\n * `keras.losses.SparseCategoricalCrossentropy` code (v2.10.0) *does* support the `ignore_class` parameter\r\n\r\nSo, although the documentation mentions the parameter, Tensorflow doesn't support it yet, while Keras does."
            },
            {
                "commenter": "lucasdavid",
                "body": "@visionscaper I thought these two synchronized automatically... Maybe this has something to do with PR #16851?\r\nI think it might be best to create a new issue to increase visibility over this problem.\r\n\r\nA suspicious thing happened during this PR:\r\n1. capybara tests were passing (http://cl/460977716);\r\n2. @fchollet [asked me to remove](https://github.com/keras-team/keras/pull/16712#discussion_r919417610) some unnecessary code/comments and to [change some names](https://github.com/keras-team/keras/pull/16712#discussion_r919418171);\r\n3. I performed the changes and pushed-force;\r\n4. Capybara tests failed (http://cl/460977716), but the PR was merged anyways\r\n\r\nI don't have the necessary access permissions to see what failed in capybara's logs, but all tests cases pass in my machine and in the [GPU](https://source.cloud.google.com/results/invocations/b7206808-89c2-4b81-8cf2-7bb30ca97e45) and [CPU](https://source.cloud.google.com/results/invocations/3945a917-3258-4b3f-8489-3eab0eb7a304) CIs."
            },
            {
                "commenter": "lucasdavid",
                "body": "@visionscaper, I believe it's now working in tf-nightly:\r\n```py\r\nimport numpy as np\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nprint(tf.keras.losses.sparse_categorical_crossentropy(\r\n  np.random.randint(-1, 10, size=[40, 1]),\r\n  np.random.randn(40, 10),\r\n  ignore_class=-1\r\n))\r\nprint(tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1)(\r\n  np.random.randint(-1, 10, size=[40, 1]),\r\n  np.random.randn(40, 10)\r\n))\r\n```\r\n```shell\r\n2.11.0-dev20221011\r\n\r\n<tf.Tensor: shape=(40,), dtype=float64, numpy=\r\narray([17.46086028,  1.64064914, 16.93660172,  2.25964914,  3.02902916,\r\n        2.38092942, 16.97059782, 16.5225091 ,  0.        , 17.21726741,\r\n        1.47735013, 16.65561627, 16.58555793,  0.        ,  1.94407448,\r\n       17.10451514,  2.04504283, 16.77500514,  2.10482156, 16.75909515,\r\n        1.45206898,  1.36361875, 16.52289682, 16.88043939, 17.54349066,\r\n       17.05594301,  2.36618914,  1.87394029, 17.44958865,  1.42225717,\r\n       17.27105659,  0.        , 17.47401625, 17.47470669, 17.42965694,\r\n       17.33150152,  1.03149344,  1.56646177, 16.54211899, 17.32527626])>\r\n\r\n<tf.Tensor: shape=(), dtype=float64, numpy=10.997069327410369>\r\n```"
            },
            {
                "commenter": "visionscaper",
                "body": "Thanks for letting me know @lucasdavid!\r\n"
            },
            {
                "commenter": "svobora",
                "body": "Well the ignore labels work but it is extremely slow."
            },
            {
                "commenter": "lucasdavid",
                "body": "I used a very similar version of this one to train over Pascal VOC 2012 and I didn't see any performance issues.\r\nCan you give us more information about your problem domain, data and model? Or perhaps a code snippet that illustrates the performance degradation."
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 15702,
        "body": "Please see keras-team/keras#15240 and keras-team/keras#15419. \r\n\r\nProgress so far:\r\n\r\nX variant:\r\n\r\n<table>\r\n    <tr>\r\n        <th>Model</th>\r\n        <th>Paper (in %)</th>\r\n        <th>Ours (in %)</th>\r\n        <th>Diff (in %)</th>\r\n        <th>Comments</th>\r\n    </tr>\r\n    <tr>\r\n        <td>X002</td>\r\n        <td>68.9</td>\r\n        <td>67.15</td>\r\n        <td>1.75</td>\r\n        <td>adamw, area_factor=0.25</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X004</td>\r\n        <td>72.6</td>\r\n        <td>71.22</td>\r\n        <td>1.38</td>\r\n        <td>adamw, area_factor=0.08</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X006</td>\r\n        <td>74.1</td>\r\n        <td>72.37</td>\r\n        <td>1.73</td>\r\n        <td>adamw, area_factor=0.08</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X008</td>\r\n        <td>75.2</td>\r\n        <td>73.45</td>\r\n        <td>1.75</td>\r\n        <td>adamw, area_factor=0.08</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X016</td>\r\n        <td>77</td>\r\n        <td>75.55</td>\r\n        <td>1.45</td>\r\n        <td>adamw, area_factor=0.08, mixup=0.2</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X032</td>\r\n        <td>78.3</td>\r\n        <td>77.09</td>\r\n        <td>1.21</td>\r\n        <td>adamw, area_factor=0.08, mixup=0.2</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X040</td>\r\n        <td>78.6</td>\r\n        <td>77.87</td>\r\n        <td>0.73</td>\r\n        <td>adamw, area_factor=0.08, mixup=0.2</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X064</td>\r\n        <td>79.2</td>\r\n        <td>78.22</td>\r\n        <td>0.98</td>\r\n        <td>adamw, area_factor=0.08, mixup=0.3</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X080</td>\r\n        <td>79.3</td>\r\n        <td>78.41</td>\r\n        <td>0.89</td>\r\n        <td>adamw, area_factor=0.08, mixup=0.3</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X120</td>\r\n        <td>79.7</td>\r\n        <td>79.09</td>\r\n        <td>0.61</td>\r\n        <td>adamw, area_factor=0.08, mixup=0.4</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X160</td>\r\n        <td>80</td>\r\n        <td>79.53</td>\r\n        <td>0.47</td>\r\n        <td>adamw, area_factor=0.08, mixup=0.4</td>\r\n    </tr>\r\n    <tr>\r\n        <td>X320</td>\r\n        <td>80.5</td>\r\n        <td>80.35</td>\r\n        <td> 0.15</td>\r\n        <td>adamw, area_factor=0.08, mixup=0.4</td>\r\n    </tr>\r\n</table>\r\n\r\nY variant:\r\n\r\n<table>\r\n<thead>\r\n  <tr>\r\n    <th></th>\r\n    <th>Paper (in %)</th>\r\n    <th>Ours (in %)</th>\r\n    <th>Diff (in %)</th>\r\n    <th>Comments</th>\r\n  </tr>\r\n</thead>\r\n<tbody>\r\n  <tr>\r\n    <td>Y002</td>\r\n    <td>70.3</td>\r\n    <td>68.51</td>\r\n    <td>1.79</td>\r\n    <td>adamw, WD=1e-5, area_factor=0.16 mixup=0.2</td>\r\n  </tr>\r\n <tr>\r\n    <td>Y004</td>\r\n    <td>74.1</td>\r\n    <td>72.11</td>\r\n    <td>1.99</td>\r\n    <td>adamw, area_factor=0.16, mixup=0.2,WD=1e-5</td>\r\n  </tr> \r\n <tr>\r\n    <td>Y006</td>\r\n    <td>75.5</td>\r\n    <td>73.52</td>\r\n    <td>1.98</td>\r\n    <td>adamw, area_factor=0.16, mixup=0.2</td>\r\n  </tr> \r\n <tr>\r\n    <td>Y008</td>\r\n    <td>76.3</td>\r\n    <td>74.48</td>\r\n    <td>1.82</td>\r\n    <td>adamw, area_factor=0.16, mixup=0.2</td>\r\n  </tr> \r\n <tr>\r\n    <td>Y016</td>\r\n    <td>77.9</td>\r\n    <td>76.95</td>\r\n    <td>0.95</td>\r\n    <td>adamw, area_factor=0.08, mixup=0.2</td>\r\n  </tr> \r\n <tr>\r\n    <td>Y032</td>\r\n    <td>78.9</td>\r\n    <td>78.05</td>\r\n    <td>0.85</td>\r\n    <td>adamw, area_factor=0.08, mixup=0.2</td>\r\n  </tr> \r\n  <tr>\r\n    <td>Y040</td>\r\n    <td>79.4</td>\r\n    <td>78.2</td>\r\n    <td>1.2</td>\r\n    <td>adamw, area_factor=0.08, mixup=0.2</td>\r\n  </tr>\r\n  <tr>\r\n    <td>Y064</td>\r\n    <td>79.9</td>\r\n    <td>78.95</td>\r\n    <td>0.95</td>\r\n    <td>adamw, area_factor=0.08, mixup=0.3</td>\r\n  </tr> \r\n <tr>\r\n    <td>Y080</td>\r\n    <td>79.9</td>\r\n    <td>79.11</td>\r\n    <td>0.69</td>\r\n    <td>adamw, area_factor=0.08, mixup=0.3</td>\r\n  </tr>\r\n  <tr>\r\n    <td>Y120</td>\r\n    <td>80.3</td>\r\n    <td>79.45</td>\r\n    <td>0.85</td>\r\n    <td>adamw, area_factor=0.08, mixup=0.4</td>\r\n  </tr>\r\n  <tr>\r\n    <td>Y160</td>\r\n    <td>80.4</td>\r\n    <td>79.71</td>\r\n    <td>0.69</td>\r\n    <td>adamw, area_factor=0.08, mixup=0.4</td>\r\n  </tr>\r\n  <tr>\r\n    <td>Y320</td>\r\n    <td>80.9</td>\r\n    <td>80.12</td>\r\n    <td>0.78</td>\r\n    <td>adamw, area_factor=0.08, mixup=0.4</td>\r\n  </tr>\r\n</tbody>\r\n</table>\r\n\r\n/cc @fchollet @sayakpaul @qlzh727 \r\n/auto Closes keras-team/keras#15240.",
        "changed_files": [
            {
                "filename": "keras/api/BUILD",
                "patch": "@@ -31,6 +31,7 @@ keras_packages = [\n     \"keras.applications.mobilenet_v2\",\n     \"keras.applications.mobilenet_v3\",\n     \"keras.applications.nasnet\",\n+    \"keras.applications.regnet\",\n     \"keras.applications.resnet\",\n     \"keras.applications.resnet_v2\",\n     \"keras.applications.vgg16\","
            },
            {
                "filename": "keras/api/api_init_files.bzl",
                "patch": "@@ -21,6 +21,7 @@ KERAS_API_INIT_FILES = [\n     \"keras/applications/mobilenet_v2/__init__.py\",\n     \"keras/applications/mobilenet_v3/__init__.py\",\n     \"keras/applications/nasnet/__init__.py\",\n+    \"keras/applications/regnet/__init__.py\",\n     \"keras/applications/resnet/__init__.py\",\n     \"keras/applications/resnet50/__init__.py\",\n     \"keras/applications/resnet_v2/__init__.py\",\n@@ -85,6 +86,7 @@ KERAS_API_INIT_FILES_V1 = [\n     \"keras/applications/mobilenet_v2/__init__.py\",\n     \"keras/applications/mobilenet_v3/__init__.py\",\n     \"keras/applications/nasnet/__init__.py\",\n+    \"keras/applications/regnet/__init__.py\",\n     \"keras/applications/resnet/__init__.py\",\n     \"keras/applications/resnet_v2/__init__.py\",\n     \"keras/applications/resnet50/__init__.py\","
            },
            {
                "filename": "keras/applications/BUILD",
                "patch": "@@ -25,6 +25,7 @@ py_library(\n         \"mobilenet_v2.py\",\n         \"mobilenet_v3.py\",\n         \"nasnet.py\",\n+        \"regnet.py\",\n         \"resnet.py\",\n         \"resnet_v2.py\",\n         \"vgg16.py\",\n@@ -312,6 +313,23 @@ tf_py_test(\n     ],\n )\n \n+tf_py_test(\n+    name = \"applications_load_weight_test_regnet\",\n+    srcs = [\"applications_load_weight_test.py\"],\n+    args = [\"--module=regnet\"],\n+    main = \"applications_load_weight_test.py\",\n+    tags = [\n+        \"no_oss\",\n+        \"no_pip\",\n+    ],\n+    deps = [\n+        \":applications\",\n+        \"//:expect_absl_installed\",\n+        \"//:expect_tensorflow_installed\",\n+        \"//keras/preprocessing\",\n+    ],\n+)\n+\n tf_py_test(\n     name = \"applications_load_weight_test_nasnet_mobile\",\n     srcs = [\"applications_load_weight_test.py\"],"
            },
            {
                "filename": "keras/applications/applications_load_weight_test.py",
                "patch": "@@ -29,6 +29,7 @@\n from keras.applications import mobilenet_v2\n from keras.applications import mobilenet_v3\n from keras.applications import nasnet\n+from keras.applications import regnet\n from keras.applications import resnet\n from keras.applications import resnet_v2\n from keras.applications import vgg16\n@@ -69,7 +70,16 @@\n         efficientnet_v2.EfficientNetV2B2, efficientnet_v2.EfficientNetV2B3,\n         efficientnet_v2.EfficientNetV2S, efficientnet_v2.EfficientNetV2M,\n         efficientnet_v2.EfficientNetV2L\n-    ])\n+    ]),\n+    'regnet': (regnet,\n+        [regnet.RegNetX002, regnet.RegNetX004, regnet.RegNetX006,\n+         regnet.RegNetX008, regnet.RegNetX016, regnet.RegNetX032,\n+         regnet.RegNetX040, regnet.RegNetX064, regnet.RegNetX080,\n+         regnet.RegNetX120, regnet.RegNetX160, regnet.RegNetX320,\n+         regnet.RegNetY002, regnet.RegNetY004, regnet.RegNetY006,\n+         regnet.RegNetY008, regnet.RegNetY016, regnet.RegNetY032,\n+         regnet.RegNetY040, regnet.RegNetY064, regnet.RegNetY080,\n+         regnet.RegNetY120, regnet.RegNetY160, regnet.RegNetY320])\n }\n \n TEST_IMAGE_PATH = ('https://storage.googleapis.com/tensorflow/'"
            },
            {
                "filename": "keras/applications/applications_test.py",
                "patch": "@@ -28,6 +28,7 @@\n from keras.applications import mobilenet_v2\n from keras.applications import mobilenet_v3\n from keras.applications import nasnet\n+from keras.applications import regnet\n from keras.applications import resnet\n from keras.applications import resnet_v2\n from keras.applications import vgg16\n@@ -69,6 +70,30 @@\n     (efficientnet_v2.EfficientNetV2S, 1280),\n     (efficientnet_v2.EfficientNetV2M, 1280),\n     (efficientnet_v2.EfficientNetV2L, 1280),\n+    (regnet.RegNetX002, 368),\n+    (regnet.RegNetX004, 384),\n+    (regnet.RegNetX006, 528),\n+    (regnet.RegNetX008, 672),\n+    (regnet.RegNetX016, 912),\n+    (regnet.RegNetX032, 1008),\n+    (regnet.RegNetX040, 1360),\n+    (regnet.RegNetX064, 1624),\n+    (regnet.RegNetX080, 1920),\n+    (regnet.RegNetX120, 2240),\n+    (regnet.RegNetX160, 2048),\n+    (regnet.RegNetX320, 2520),\n+    (regnet.RegNetY002, 368),\n+    (regnet.RegNetY004, 440),\n+    (regnet.RegNetY006, 608),\n+    (regnet.RegNetY008, 768),\n+    (regnet.RegNetY016, 888),\n+    (regnet.RegNetY032, 1512),\n+    (regnet.RegNetY040, 1088),\n+    (regnet.RegNetY064, 1296),\n+    (regnet.RegNetY080, 2016),\n+    (regnet.RegNetY120, 2240),\n+    (regnet.RegNetY160, 3024),\n+    (regnet.RegNetY320, 3712)\n ]\n \n NASNET_LIST = ["
            },
            {
                "filename": "keras/applications/regnet.py",
                "patch": "@@ -0,0 +1,1631 @@\n+# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+# pylint: disable=invalid-name\n+# pylint: disable=missing-docstring\n+\"\"\"RegNet models for Keras.\n+\n+References:\n+\n+- [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+  (CVPR 2020)\n+- [Fast and Accurate Model Scaling](https://arxiv.org/abs/2103.06877)\n+  (CVPR 2021)\n+\"\"\"\n+\n+import tensorflow as tf\n+\n+from keras import backend\n+from keras import layers\n+from keras.applications import imagenet_utils\n+from keras.engine import training\n+from keras.utils import layer_utils\n+from keras.utils import data_utils\n+from tensorflow.python.util.tf_export import keras_export\n+\n+BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/keras-applications/\"\n+\n+WEIGHTS_HASHES = {\n+    \"x002\":\n+        (\"49fb46e56cde07fdaf57bffd851461a86548f6a3a4baef234dd37290b826c0b8\",\n+         \"5445b66cd50445eb7ecab094c1e78d4d3d29375439d1a7798861c4af15ffff21\"),\n+    \"x004\":\n+        (\"3523c7f5ac0dbbcc2fd6d83b3570e7540f7449d3301cc22c29547302114e4088\",\n+         \"de139bf07a66c9256f2277bf5c1b6dd2d5a3a891a5f8a925a10c8a0a113fd6f3\"),\n+    \"x006\":\n+        (\"340216ef334a7bae30daac9f414e693c136fac9ab868704bbfcc9ce6a5ec74bb\",\n+         \"a43ec97ad62f86b2a96a783bfdc63a5a54de02eef54f26379ea05e1bf90a9505\"),\n+    \"x008\":\n+        (\"8f145d6a5fae6da62677bb8d26eb92d0b9dfe143ec1ebf68b24a57ae50a2763d\",\n+         \"3c7e4b0917359304dc18e644475c5c1f5e88d795542b676439c4a3acd63b7207\"),\n+    \"x016\":\n+        (\"31c386f4c7bfef4c021a583099aa79c1b3928057ba1b7d182f174674c5ef3510\",\n+         \"1b8e3d545d190271204a7b2165936a227d26b79bb7922bac5ee4d303091bf17a\"),\n+    \"x032\":\n+        (\"6c025df1409e5ea846375bc9dfa240956cca87ef57384d93fef7d6fa90ca8c7f\",\n+         \"9cd4522806c0fcca01b37874188b2bd394d7c419956d77472a4e072b01d99041\"),\n+    \"x040\":\n+        (\"ba128046c588a26dbd3b3a011b26cb7fa3cf8f269c184c132372cb20b6eb54c1\",\n+         \"b4ed0ca0b9a98e789e05000e830403a7ade4d8afa01c73491c44610195198afe\"),\n+    \"x064\":\n+        (\"0f4489c3cd3ad979bd6b0324213998bcb36dc861d178f977997ebfe53c3ba564\",\n+         \"3e706fa416a18dfda14c713423eba8041ae2509db3e0a611d5f599b5268a46c4\"),\n+    \"x080\":\n+        (\"76320e43272719df648db37271a247c22eb6e810fe469c37a5db7e2cb696d162\",\n+         \"7b1ce8e29ceefec10a6569640ee329dba7fbc98b5d0f6346aabade058b66cf29\"),\n+    \"x120\":\n+        (\"5cafc461b78897d5e4f24e68cb406d18e75f31105ef620e7682b611bb355eb3a\",\n+         \"36174ddd0299db04a42631d028abcb1cc7afec2b705e42bd28fcd325e5d596bf\"),\n+    \"x160\":\n+        (\"8093f57a5824b181fb734ea21ae34b1f7ee42c5298e63cf6d587c290973195d2\",\n+         \"9d1485050bdf19531ffa1ed7827c75850e0f2972118a996b91aa9264b088fd43\"),\n+    \"x320\":\n+        (\"91fb3e6f4e9e44b3687e80977f7f4412ee9937c0c704232664fc83e4322ea01e\",\n+         \"9db7eacc37b85c98184070e1a172e6104c00846f44bcd4e727da9e50d9692398\"),\n+    \"y002\":\n+        (\"1e8091c674532b1a61c04f6393a9c570113e0197f22bd1b98cc4c4fe800c6465\",\n+         \"f63221f63d625b8e201221499682587bfe29d33f50a4c4f4d53be00f66c0f12c\"),\n+    \"y004\":\n+        (\"752fdbad21c78911bf1dcb8c513e5a0e14697b068e5d9e73525dbaa416d18d8e\",\n+         \"45e6ba8309a17a77e67afc05228454b2e0ee6be0dae65edc0f31f1da10cc066b\"),\n+    \"y006\":\n+        (\"98942e07b273da500ff9699a1f88aca78dfad4375faabb0bab784bb0dace80a9\",\n+         \"b70261cba4e60013c99d130cc098d2fce629ff978a445663b6fa4f8fc099a2be\"),\n+    \"y008\":\n+        (\"1b099377cc9a4fb183159a6f9b24bc998e5659d25a449f40c90cbffcbcfdcae4\",\n+         \"b11f5432a216ee640fe9be6e32939defa8d08b8d136349bf3690715a98752ca1\"),\n+    \"y016\":\n+        (\"b7ce1f5e223f0941c960602de922bcf846288ce7a4c33b2a4f2e4ac4b480045b\",\n+         \"d7404f50205e82d793e219afb9eb2bfeb781b6b2d316a6128c6d7d7dacab7f57\"),\n+    \"y032\":\n+        (\"6a6a545cf3549973554c9b94f0cd40e25f229fffb1e7f7ac779a59dcbee612bd\",\n+         \"eb3ac1c45ec60f4f031c3f5180573422b1cf7bebc26c004637517372f68f8937\"),\n+    \"y040\":\n+        (\"98d00118b335162bbffe8f1329e54e5c8e75ee09b2a5414f97b0ddfc56e796f6\",\n+         \"b5be2a5e5f072ecdd9c0b8a437cd896df0efa1f6a1f77e41caa8719b7dfcb05d\"),\n+    \"y064\":\n+        (\"65c948c7a18aaecaad2d1bd4fd978987425604ba6669ef55a1faa0069a2804b7\",\n+         \"885c4b7ed7ea339daca7dafa1a62cb7d41b1068897ef90a5a3d71b4a2e2db31a\"),\n+    \"y080\":\n+        (\"7a2c62da2982e369a4984d3c7c3b32d6f8d3748a71cb37a31156c436c37f3e95\",\n+         \"3d119577e1e3bf8d153b895e8ea9e4ec150ff2d92abdca711b6e949c3fd7115d\"),\n+    \"y120\":\n+        (\"a96ab0d27d3ae35a422ee7df0d789069b3e3217a99334e0ce861a96595bc5986\",\n+         \"4a6fa387108380b730b71feea2ad80b5224b5ea9dc21dc156c93fe3c6186485c\"),\n+    \"y160\":\n+        (\"45067240ffbc7ca2591313fee2f80dbdda6d66ec1a7451446f9a6d00d8f7ac6e\",\n+         \"ead1e6b568be8f34447ec8941299a9df4368736ba9a8205de5427fa20a1fb316\"),\n+    \"y320\": (\"b05e173e4ae635cfa22d06392ee3741284d17dadfee68f2aa6fd8cb2b7561112\",\n+             \"cad78f74a586e24c61d38be17f3ae53bb9674380174d2585da1a526b8c20e1fd\")\n+}\n+\n+# The widths and depths are deduced from a quantized linear function. For\n+# more information, please refer to \"Designing Network Design Spaces\" by\n+# Radosavovic et al.\n+\n+# BatchNorm momentum and epsilon values taken from original implementation.\n+\n+MODEL_CONFIGS = {\n+    \"x002\": {\n+        \"depths\": [1, 1, 4, 7],\n+        \"widths\": [24, 56, 152, 368],\n+        \"group_width\": 8,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x004\": {\n+        \"depths\": [1, 2, 7, 12],\n+        \"widths\": [32, 64, 160, 384],\n+        \"group_width\": 16,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x006\": {\n+        \"depths\": [1, 3, 5, 7],\n+        \"widths\": [48, 96, 240, 528],\n+        \"group_width\": 24,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x008\": {\n+        \"depths\": [1, 3, 7, 5],\n+        \"widths\": [64, 128, 288, 672],\n+        \"group_width\": 16,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x016\": {\n+        \"depths\": [2, 4, 10, 2],\n+        \"widths\": [72, 168, 408, 912],\n+        \"group_width\": 24,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x032\": {\n+        \"depths\": [2, 6, 15, 2],\n+        \"widths\": [96, 192, 432, 1008],\n+        \"group_width\": 48,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x040\": {\n+        \"depths\": [2, 5, 14, 2],\n+        \"widths\": [80, 240, 560, 1360],\n+        \"group_width\": 40,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x064\": {\n+        \"depths\": [2, 4, 10, 1],\n+        \"widths\": [168, 392, 784, 1624],\n+        \"group_width\": 56,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x080\": {\n+        \"depths\": [2, 5, 15, 1],\n+        \"widths\": [80, 240, 720, 1920],\n+        \"group_width\": 120,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x120\": {\n+        \"depths\": [2, 5, 11, 1],\n+        \"widths\": [224, 448, 896, 2240],\n+        \"group_width\": 112,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x160\": {\n+        \"depths\": [2, 6, 13, 1],\n+        \"widths\": [256, 512, 896, 2048],\n+        \"group_width\": 128,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x320\": {\n+        \"depths\": [2, 7, 13, 1],\n+        \"widths\": [336, 672, 1344, 2520],\n+        \"group_width\": 168,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"y002\": {\n+        \"depths\": [1, 1, 4, 7],\n+        \"widths\": [24, 56, 152, 368],\n+        \"group_width\": 8,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y004\": {\n+        \"depths\": [1, 3, 6, 6],\n+        \"widths\": [48, 104, 208, 440],\n+        \"group_width\": 8,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y006\": {\n+        \"depths\": [1, 3, 7, 4],\n+        \"widths\": [48, 112, 256, 608],\n+        \"group_width\": 16,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y008\": {\n+        \"depths\": [1, 3, 8, 2],\n+        \"widths\": [64, 128, 320, 768],\n+        \"group_width\": 16,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y016\": {\n+        \"depths\": [2, 6, 17, 2],\n+        \"widths\": [48, 120, 336, 888],\n+        \"group_width\": 24,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y032\": {\n+        \"depths\": [2, 5, 13, 1],\n+        \"widths\": [72, 216, 576, 1512],\n+        \"group_width\": 24,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y040\": {\n+        \"depths\": [2, 6, 12, 2],\n+        \"widths\": [128, 192, 512, 1088],\n+        \"group_width\": 64,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y064\": {\n+        \"depths\": [2, 7, 14, 2],\n+        \"widths\": [144, 288, 576, 1296],\n+        \"group_width\": 72,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y080\": {\n+        \"depths\": [2, 4, 10, 1],\n+        \"widths\": [168, 448, 896, 2016],\n+        \"group_width\": 56,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y120\": {\n+        \"depths\": [2, 5, 11, 1],\n+        \"widths\": [224, 448, 896, 2240],\n+        \"group_width\": 112,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y160\": {\n+        \"depths\": [2, 4, 11, 1],\n+        \"widths\": [224, 448, 1232, 3024],\n+        \"group_width\": 112,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y320\": {\n+        \"depths\": [2, 5, 12, 1],\n+        \"widths\": [232, 696, 1392, 3712],\n+        \"group_width\": 232,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+}\n+\n+BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n+\n+  References:\n+    - [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+    (CVPR 2020)\n+    - [Fast and Accurate Model Scaling](https://arxiv.org/abs/2103.06877)\n+    (CVPR 2021)\n+\n+  For image classification use cases, see\n+  [this page for detailed examples](\n+  https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+  For transfer learning use cases, make sure to read the\n+  [guide to transfer learning & fine-tuning](\n+    https://keras.io/guides/transfer_learning/).\n+\n+  Note: Each Keras Application expects a specific kind of input preprocessing.\n+  For Regnets, preprocessing is included in the model using a `Rescaling` layer.\n+  RegNet models expect their inputs to be float or uint8 tensors of pixels with \n+  values in the [0-255] range.\n+\n+  The naming of models is as follows: `RegNet<block_type><flops>` where \n+  `block_type` is one of `(Y, Z)` and `flops` signifies hundred million \n+  floating point operations. For example RegNetY64 corresponds to RegNet with \n+  Y block and 6.4 giga flops (64 hundred million flops). \n+\n+  Args:\n+    include_top: Whether to include the fully-connected\n+        layer at the top of the network. Defaults to True.\n+    weights: One of `None` (random initialization),\n+          \"imagenet\" (pre-training on ImageNet),\n+          or the path to the weights file to be loaded. Defaults to \"imagenet\".\n+    input_tensor: Optional Keras tensor\n+        (i.e. output of `layers.Input()`)\n+        to use as image input for the model.\n+    input_shape: Optional shape tuple, only to be specified\n+        if `include_top` is False.\n+        It should have exactly 3 inputs channels.\n+    pooling: Optional pooling mode for feature extraction\n+        when `include_top` is `False`. Defaults to None.\n+        - `None` means that the output of the model will be\n+            the 4D tensor output of the\n+            last convolutional layer.\n+        - `avg` means that global average pooling\n+            will be applied to the output of the\n+            last convolutional layer, and thus\n+            the output of the model will be a 2D tensor.\n+        - `max` means that global max pooling will\n+            be applied.\n+    classes: Optional number of classes to classify images\n+        into, only to be specified if `include_top` is True, and\n+        if no `weights` argument is specified. Defaults to 1000 (number of\n+        ImageNet classes).\n+    classifier_activation: A `str` or callable. The activation function to use\n+        on the \"top\" layer. Ignored unless `include_top=True`. Set\n+        `classifier_activation=None` to return the logits of the \"top\" layer.\n+        Defaults to \"softmax\".\n+        When loading pretrained weights, `classifier_activation` can only\n+        be `None` or `\"softmax\"`.\n+\n+  Returns:\n+    A `keras.Model` instance.\n+\"\"\"\n+\n+\n+def PreStem(name=None):\n+  \"\"\"\n+  Rescales and normalizes inputs to [0,1] and ImageNet mean and std.\n+  \n+  Args:\n+    name: name prefix\n+    \n+  Returns:\n+    Rescaled and normalized tensor\n+  \"\"\"\n+  if name is None:\n+    name = \"prestem\" + str(backend.get_uid(\"prestem\"))\n+\n+  def apply(x):\n+    x = layers.Rescaling(scale=1. / 255., name=name + \"_prestem_rescaling\")(x)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def Stem(name=None):\n+  \"\"\"\n+  Implementation of RegNet stem. (Common to all model variants)\n+  \n+  Args:\n+    name: name prefix   \n+\n+  Returns:\n+    Output tensor of the Stem\n+  \"\"\"\n+  if name is None:\n+    name = \"stem\" + str(backend.get_uid(\"stem\"))\n+\n+  def apply(x):\n+    x = layers.Conv2D(32, (3, 3),\n+                      strides=2,\n+                      use_bias=False,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_stem_conv\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_stem_bn\")(x)\n+    x = layers.ReLU(name=name + \"_stem_relu\")(x)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def SqueezeAndExciteBlock(filters_in, se_filters, name=None):\n+  \"\"\"\n+  Implements the Squeeze and excite block (https://arxiv.org/abs/1709.01507)\n+  \n+  Args:\n+    filters_in: input filters to the block\n+    se_filters: filters to squeeze to\n+    name: name prefix\n+  \n+  Returns:\n+    A function object   \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"squeeze_and_excite\"))\n+\n+  def apply(inputs):\n+    x = layers.GlobalAveragePooling2D(name=name + \"_squeeze_and_excite_gap\",\n+                                      keepdims=True)(inputs)\n+    x = layers.Conv2D(se_filters, (1, 1),\n+                      activation=\"relu\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_squeeze_and_excite_squeeze\")(x)\n+    x = layers.Conv2D(filters_in, (1, 1),\n+                      activation=\"sigmoid\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_squeeze_and_excite_excite\")(x)\n+    x = tf.math.multiply(x, inputs)\n+    return x\n+\n+  return apply\n+\n+\n+def XBlock(filters_in, filters_out, group_width, stride=1, name=None):\n+  \"\"\"\n+  Implementation of X Block. \n+  Reference: [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+\n+  Args:\n+    filters_in: filters in the input tensor\n+    filters_out: filters in the output tensor\n+    group_width: group width\n+    stride: stride\n+    name: name prefix\n+\n+  Return:\n+    Output tensor of the block \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"xblock\"))\n+\n+  def apply(inputs):\n+    if filters_in != filters_out and stride == 1:\n+      raise ValueError(\n+          f\"Input filters({filters_in}) and output filters({filters_out}) \"\n+          f\"are not equal for stride {stride}. Input and output filters must \"\n+          f\"be equal for stride={stride}.\")\n+\n+    # Declare layers\n+    groups = filters_out // group_width\n+\n+    if stride != 1:\n+      skip = layers.Conv2D(filters_out, (1, 1),\n+                           strides=stride,\n+                           use_bias=False,\n+                           kernel_initializer=\"he_normal\",\n+                           name=name + \"_skip_1x1\")(inputs)\n+      skip = layers.BatchNormalization(momentum=0.9,\n+                                       epsilon=1e-5,\n+                                       name=name + \"_skip_bn\")(skip)\n+    else:\n+      skip = inputs\n+\n+    # Build block\n+    # conv_1x1_1\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_1\")(inputs)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_1_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_1x1_1_relu\")(x)\n+\n+    # conv_3x3\n+    x = layers.Conv2D(filters_out, (3, 3),\n+                      use_bias=False,\n+                      strides=stride,\n+                      groups=groups,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_3x3\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_3x3_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_3x3_relu\")(x)\n+\n+    # conv_1x1_2\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_2\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_2_bn\")(x)\n+\n+    x = layers.ReLU(name=name + \"_exit_relu\")(x + skip)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def YBlock(filters_in,\n+           filters_out,\n+           group_width,\n+           stride=1,\n+           squeeze_excite_ratio=0.25,\n+           name=None):\n+  \"\"\"\n+  Implementation of Y Block. \n+  Reference: [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+\n+  Args:\n+    filters_in: filters in the input tensor\n+    filters_out: filters in the output tensor\n+    group_width: group width\n+    stride: stride\n+    squeeze_excite_ratio: expansion ration for Squeeze and Excite block\n+    name: name prefix\n+\n+  Return:\n+    Output tensor of the block \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"yblock\"))\n+\n+  def apply(inputs):\n+    if filters_in != filters_out and stride == 1:\n+      raise ValueError(\n+          f\"Input filters({filters_in}) and output filters({filters_out}) \"\n+          f\"are not equal for stride {stride}. Input and output filters must  \"\n+          f\"be equal for stride={stride}.\")\n+\n+    groups = filters_out // group_width\n+    se_filters = int(filters_in * squeeze_excite_ratio)\n+\n+    if stride != 1:\n+      skip = layers.Conv2D(filters_out, (1, 1),\n+                           strides=stride,\n+                           use_bias=False,\n+                           kernel_initializer=\"he_normal\",\n+                           name=name + \"_skip_1x1\")(inputs)\n+      skip = layers.BatchNormalization(momentum=0.9,\n+                                       epsilon=1e-5,\n+                                       name=name + \"_skip_bn\")(skip)\n+    else:\n+      skip = inputs\n+\n+    # Build block\n+    # conv_1x1_1\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_1\")(inputs)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_1_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_1x1_1_relu\")(x)\n+\n+    # conv_3x3\n+    x = layers.Conv2D(filters_out, (3, 3),\n+                      use_bias=False,\n+                      strides=stride,\n+                      groups=groups,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_3x3\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_3x3_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_3x3_relu\")(x)\n+\n+    # Squeeze-Excitation block\n+    x = SqueezeAndExciteBlock(filters_out, se_filters, name=name)(x)\n+\n+    # conv_1x1_2\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_2\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_2_bn\")(x)\n+\n+    x = layers.ReLU(name=name + \"_exit_relu\")(x + skip)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def ZBlock(filters_in,\n+           filters_out,\n+           group_width,\n+           stride=1,\n+           squeeze_excite_ratio=0.25,\n+           bottleneck_ratio=0.25,\n+           name=None):\n+  \"\"\"\n+  Implementation of Z block\n+  Reference: [Fast and Accurate Model Scaling](https://arxiv.org/abs/2103.06877).\n+  \n+  Args:\n+    filters_in: filters in the input tensor\n+    filters_out: filters in the output tensor\n+    group_width: group width\n+    stride: stride\n+    squeeze_excite_ratio: expansion ration for Squeeze and Excite block\n+    bottleneck_ratio: inverted bottleneck ratio \n+    name: name prefix\n+\n+  Return:\n+    Output tensor of the block \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"zblock\"))\n+\n+  def apply(inputs):\n+    if filters_in != filters_out and stride == 1:\n+      raise ValueError(\n+          f\"Input filters({filters_in}) and output filters({filters_out})\"\n+          f\"are not equal for stride {stride}. Input and output filters must be\"\n+          f\" equal for stride={stride}.\")\n+\n+    groups = filters_out // group_width\n+    se_filters = int(filters_in * squeeze_excite_ratio)\n+\n+    inv_btlneck_filters = int(filters_out / bottleneck_ratio)\n+\n+    # Build block\n+    # conv_1x1_1\n+    x = layers.Conv2D(inv_btlneck_filters, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_1\")(inputs)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_1_bn\")(x)\n+    x = tf.nn.silu(x)\n+\n+    # conv_3x3\n+    x = layers.Conv2D(inv_btlneck_filters, (3, 3),\n+                      use_bias=False,\n+                      strides=stride,\n+                      groups=groups,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_3x3\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_3x3_bn\")(x)\n+    x = tf.nn.silu(x)\n+\n+    # Squeeze-Excitation block\n+    x = SqueezeAndExciteBlock(inv_btlneck_filters, se_filters, name=name)\n+\n+    # conv_1x1_2\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_2\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_2_bn\")(x)\n+\n+    if stride != 1:\n+      return x\n+    else:\n+      return x + inputs\n+\n+  return apply\n+\n+\n+def Stage(block_type, depth, group_width, filters_in, filters_out, name=None):\n+  \"\"\"\n+  Implementation of Stage in RegNet.\n+\n+  Args:\n+    block_type: must be one of \"X\", \"Y\", \"Z\"\n+    depth: depth of stage, number of blocks to use\n+    group_width: group width of all blocks in  this stage\n+    filters_in: input filters to this stage\n+    filters_out: output filters from this stage\n+    name: name prefix\n+\n+  Returns:\n+    Output tensor of Stage\n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"stage\"))\n+\n+  def apply(inputs):\n+    x = inputs\n+    if block_type == \"X\":\n+      x = XBlock(filters_in,\n+                 filters_out,\n+                 group_width,\n+                 stride=2,\n+                 name=f\"{name}_XBlock_0\")(x)\n+      for i in range(1, depth):\n+        x = XBlock(filters_out,\n+                   filters_out,\n+                   group_width,\n+                   name=f\"{name}_XBlock_{i}\")(x)\n+    elif block_type == \"Y\":\n+      x = YBlock(filters_in,\n+                 filters_out,\n+                 group_width,\n+                 stride=2,\n+                 name=name + \"_YBlock_0\")(x)\n+      for i in range(1, depth):\n+        x = YBlock(filters_out,\n+                   filters_out,\n+                   group_width,\n+                   name=f\"{name}_YBlock_{i}\")(x)\n+    elif block_type == \"Z\":\n+      x = ZBlock(filters_in,\n+                 filters_out,\n+                 group_width,\n+                 stride=2,\n+                 name=f\"{name}_ZBlock_0\")(x)\n+      for i in range(1, depth):\n+        x = ZBlock(filters_out,\n+                   filters_out,\n+                   group_width,\n+                   name=f\"{name}_ZBlock_{i}\")(x)\n+    else:\n+      raise NotImplementedError(f\"Block type `{block_type}` not recognized.\"\n+                                f\"block_type must be one of (`X`, `Y`, `Z`). \")\n+    return x\n+\n+  return apply\n+\n+\n+def Head(num_classes=1000, name=None):\n+  \"\"\"\n+  Implementation of classification head of RegNet\n+  \n+  Args:\n+    x: Input tensor\n+    num_classes: number of classes for Dense layer\n+  \n+  Returns:\n+    Output logits tensor. \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"head\"))\n+\n+  def apply(x):\n+    x = layers.GlobalAveragePooling2D(name=name + \"_head_gap\")(x)\n+    x = layers.Dense(num_classes, name=name + \"head_dense\")(x)\n+    return x\n+\n+  return apply\n+\n+\n+def RegNet(depths,\n+           widths,\n+           group_width,\n+           block_type,\n+           default_size,\n+           model_name=\"regnet\",\n+           include_preprocessing=True,\n+           include_top=True,\n+           weights=\"imagenet\",\n+           input_tensor=None,\n+           input_shape=None,\n+           pooling=None,\n+           classes=1000,\n+           classifier_activation=\"softmax\"):\n+  \"\"\" \n+  Instantiates RegNet architecture given specific configuration.\n+\n+  Args:\n+    depths: An iterable containing depths for each individual stages. \n+    widths: An iterable containing output channel width of each individual \n+      stages\n+    group_width: Number of channels to be used in each group. See grouped \n+      convolutions for more information.\n+    block_type: Must be one of `{\"X\", \"Y\", \"Z\"}`. For more details see the\n+      papers \"Designing network design spaces\" and \"Fast and Accurate Model \n+      Scaling\"\n+    default_size: Default input image size. \n+    model_name: An optional name for the model.\n+    include_preprocessing: boolean denoting whther to include preprocessing in \n+      the model\n+    include_top: Boolean denoting whether to include classification head to \n+      the model.\n+    weights: one of `None` (random initialization),\n+      \"imagenet\" (pre-training on ImageNet),\n+      or the path to the weights file to be loaded.\n+    input_tensor: optional Keras tensor\n+      (i.e. output of `layers.Input()`)\n+      to use as image input for the model.\n+    input_shape: optional shape tuple, only to be specified\n+      if `include_top` is False.\n+      It should have exactly 3 inputs channels.\n+    pooling: optional pooling mode for feature extraction\n+      when `include_top` is `False`.\n+      - `None` means that the output of the model will be\n+          the 4D tensor output of the\n+          last convolutional layer.\n+      - `avg` means that global average pooling\n+          will be applied to the output of the\n+          last convolutional layer, and thus\n+          the output of the model will be a 2D tensor.\n+      - `max` means that global max pooling will\n+          be applied.\n+    classes: optional number of classes to classify images\n+      into, only to be specified if `include_top` is True, and\n+      if no `weights` argument is specified.\n+    classifier_activation: A `str` or callable. The activation function to use\n+      on the \"top\" layer. Ignored unless `include_top=True`. Set\n+      `classifier_activation=None` to return the logits of the \"top\" layer.        \n+  \n+  Returns:\n+    A `keras.Model` instance.\n+  \n+  Raises:\n+      ValueError: in case of invalid argument for `weights`,\n+        or invalid input shape.\n+      ValueError: if `classifier_activation` is not `softmax` or `None` when\n+        using a pretrained top layer.\n+      ValueError: if `include_top` is True but `num_classes` is not 1000.\n+      ValueError: if `block_type` is not one of `{\"X\", \"Y\", \"Z\"}`\n+  \n+  \"\"\"\n+  if not (weights in {\"imagenet\", None} or tf.io.gfile.exists(weights)):\n+    raise ValueError(\"The `weights` argument should be either \"\n+                     \"`None` (random initialization), `imagenet` \"\n+                     \"(pre-training on ImageNet), \"\n+                     \"or the path to the weights file to be loaded.\")\n+\n+  if weights == \"imagenet\" and include_top and classes != 1000:\n+    raise ValueError(\"If using `weights` as `'imagenet'` with `include_top`\"\n+                     \" as true, `classes` should be 1000\")\n+\n+  # Determine proper input shape\n+  input_shape = imagenet_utils.obtain_input_shape(\n+      input_shape,\n+      default_size=default_size,\n+      min_size=32,\n+      data_format=backend.image_data_format(),\n+      require_flatten=include_top,\n+      weights=weights)\n+\n+  if input_tensor is None:\n+    img_input = layers.Input(shape=input_shape)\n+  else:\n+    if not backend.is_keras_tensor(input_tensor):\n+      img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n+    else:\n+      img_input = input_tensor\n+\n+  if input_tensor is not None:\n+    inputs = layer_utils.get_source_inputs(input_tensor)\n+  else:\n+    inputs = img_input\n+\n+  x = inputs\n+  if include_preprocessing:\n+    x = PreStem(name=model_name)(x)\n+  x = Stem(name=model_name)(x)\n+\n+  in_channels = 32  # Output from Stem\n+\n+  for num_stage in range(4):\n+    depth = depths[num_stage]\n+    out_channels = widths[num_stage]\n+\n+    x = Stage(block_type,\n+              depth,\n+              group_width,\n+              in_channels,\n+              out_channels,\n+              name=model_name + \"_Stage_\" + str(num_stage))(x)\n+    in_channels = out_channels\n+\n+  if include_top:\n+    x = Head(num_classes=classes)(x)\n+    imagenet_utils.validate_activation(classifier_activation, weights)\n+\n+  else:\n+    if pooling == \"avg\":\n+      x = layers.GlobalAveragePooling2D()(x)\n+    elif pooling == \"max\":\n+      x = layers.GlobalMaxPooling2D()(x)\n+\n+  model = training.Model(inputs=inputs, outputs=x, name=model_name)\n+\n+  # Load weights.\n+  if weights == \"imagenet\":\n+    if include_top:\n+      file_suffix = \".h5\"\n+      file_hash = WEIGHTS_HASHES[model_name[-4:]][0]\n+    else:\n+      file_suffix = \"_notop.h5\"\n+      file_hash = WEIGHTS_HASHES[model_name[-4:]][1]\n+    file_name = model_name + file_suffix\n+    weights_path = data_utils.get_file(file_name,\n+                                       BASE_WEIGHTS_PATH + file_name,\n+                                       cache_subdir=\"models\",\n+                                       file_hash=file_hash)\n+    model.load_weights(weights_path)\n+  elif weights is not None:\n+    model.load_weights(weights)\n+\n+  return model\n+\n+\n+## Instantiating variants ##\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX002\",\n+              \"keras.applications.RegNetX002\")\n+def RegNetX002(model_name=\"regnetx002\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x002\"][\"depths\"],\n+                MODEL_CONFIGS[\"x002\"][\"widths\"],\n+                MODEL_CONFIGS[\"x002\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x002\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x002\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX004\",\n+              \"keras.applications.RegNetX004\")\n+def RegNetX004(model_name=\"regnetx004\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x004\"][\"depths\"],\n+                MODEL_CONFIGS[\"x004\"][\"widths\"],\n+                MODEL_CONFIGS[\"x004\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x004\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x004\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX006\",\n+              \"keras.applications.RegNetX006\")\n+def RegNetX006(model_name=\"regnetx006\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x006\"][\"depths\"],\n+                MODEL_CONFIGS[\"x006\"][\"widths\"],\n+                MODEL_CONFIGS[\"x006\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x006\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x006\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX008\",\n+              \"keras.applications.RegNetX008\")\n+def RegNetX008(model_name=\"regnetx008\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x008\"][\"depths\"],\n+                MODEL_CONFIGS[\"x008\"][\"widths\"],\n+                MODEL_CONFIGS[\"x008\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x008\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x008\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX016\",\n+              \"keras.applications.RegNetX016\")\n+def RegNetX016(model_name=\"regnetx016\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x016\"][\"depths\"],\n+                MODEL_CONFIGS[\"x016\"][\"widths\"],\n+                MODEL_CONFIGS[\"x016\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x016\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x016\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX032\",\n+              \"keras.applications.RegNetX032\")\n+def RegNetX032(model_name=\"regnetx032\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x032\"][\"depths\"],\n+                MODEL_CONFIGS[\"x032\"][\"widths\"],\n+                MODEL_CONFIGS[\"x032\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x032\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x032\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX040\",\n+              \"keras.applications.RegNetX040\")\n+def RegNetX040(model_name=\"regnetx040\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x040\"][\"depths\"],\n+                MODEL_CONFIGS[\"x040\"][\"widths\"],\n+                MODEL_CONFIGS[\"x040\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x040\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x040\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX064\",\n+              \"keras.applications.RegNetX064\")\n+def RegNetX064(model_name=\"regnetx064\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x064\"][\"depths\"],\n+                MODEL_CONFIGS[\"x064\"][\"widths\"],\n+                MODEL_CONFIGS[\"x064\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x064\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x064\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX080\",\n+              \"keras.applications.RegNetX080\")\n+def RegNetX080(model_name=\"regnetx080\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x080\"][\"depths\"],\n+                MODEL_CONFIGS[\"x080\"][\"widths\"],\n+                MODEL_CONFIGS[\"x080\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x080\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x080\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX120\",\n+              \"keras.applications.RegNetX120\")\n+def RegNetX120(model_name=\"regnetx120\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x120\"][\"depths\"],\n+                MODEL_CONFIGS[\"x120\"][\"widths\"],\n+                MODEL_CONFIGS[\"x120\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x120\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x120\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX160\",\n+              \"keras.applications.RegNetX160\")\n+def RegNetX160(model_name=\"regnetx160\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x160\"][\"depths\"],\n+                MODEL_CONFIGS[\"x160\"][\"widths\"],\n+                MODEL_CONFIGS[\"x160\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x160\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x160\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX320\",\n+              \"keras.applications.RegNetX320\")\n+def RegNetX320(model_name=\"regnetx320\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x320\"][\"depths\"],\n+                MODEL_CONFIGS[\"x320\"][\"widths\"],\n+                MODEL_CONFIGS[\"x320\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x320\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x320\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY002\",\n+              \"keras.applications.RegNetY002\")\n+def RegNetY002(model_name=\"regnety002\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y002\"][\"depths\"],\n+                MODEL_CONFIGS[\"y002\"][\"widths\"],\n+                MODEL_CONFIGS[\"y002\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y002\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y002\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY004\",\n+              \"keras.applications.RegNetY004\")\n+def RegNetY004(model_name=\"regnety004\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y004\"][\"depths\"],\n+                MODEL_CONFIGS[\"y004\"][\"widths\"],\n+                MODEL_CONFIGS[\"y004\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y004\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y004\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY006\",\n+              \"keras.applications.RegNetY006\")\n+def RegNetY006(model_name=\"regnety006\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y006\"][\"depths\"],\n+                MODEL_CONFIGS[\"y006\"][\"widths\"],\n+                MODEL_CONFIGS[\"y006\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y006\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y006\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY008\",\n+              \"keras.applications.RegNetY008\")\n+def RegNetY008(model_name=\"regnety008\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y008\"][\"depths\"],\n+                MODEL_CONFIGS[\"y008\"][\"widths\"],\n+                MODEL_CONFIGS[\"y008\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y008\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y008\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY016\",\n+              \"keras.applications.RegNetY016\")\n+def RegNetY016(model_name=\"regnety016\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y016\"][\"depths\"],\n+                MODEL_CONFIGS[\"y016\"][\"widths\"],\n+                MODEL_CONFIGS[\"y016\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y016\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y016\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY032\",\n+              \"keras.applications.RegNetY032\")\n+def RegNetY032(model_name=\"regnety032\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y032\"][\"depths\"],\n+                MODEL_CONFIGS[\"y032\"][\"widths\"],\n+                MODEL_CONFIGS[\"y032\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y032\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y032\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY040\",\n+              \"keras.applications.RegNetY040\")\n+def RegNetY040(model_name=\"regnety040\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y040\"][\"depths\"],\n+                MODEL_CONFIGS[\"y040\"][\"widths\"],\n+                MODEL_CONFIGS[\"y040\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y040\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y040\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY064\",\n+              \"keras.applications.RegNetY064\")\n+def RegNetY064(model_name=\"regnety064\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y064\"][\"depths\"],\n+                MODEL_CONFIGS[\"y064\"][\"widths\"],\n+                MODEL_CONFIGS[\"y064\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y064\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y064\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY080\",\n+              \"keras.applications.RegNetY080\")\n+def RegNetY080(model_name=\"regnety080\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y080\"][\"depths\"],\n+                MODEL_CONFIGS[\"y080\"][\"widths\"],\n+                MODEL_CONFIGS[\"y080\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y080\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y080\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY120\",\n+              \"keras.applications.RegNetY120\")\n+def RegNetY120(model_name=\"regnety120\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y120\"][\"depths\"],\n+                MODEL_CONFIGS[\"y120\"][\"widths\"],\n+                MODEL_CONFIGS[\"y120\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y120\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y120\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY160\",\n+              \"keras.applications.RegNetY160\")\n+def RegNetY160(model_name=\"regnety160\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y160\"][\"depths\"],\n+                MODEL_CONFIGS[\"y160\"][\"widths\"],\n+                MODEL_CONFIGS[\"y160\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y160\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y160\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY320\",\n+              \"keras.applications.RegNetY320\")\n+def RegNetY320(model_name=\"regnety320\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y320\"][\"depths\"],\n+                MODEL_CONFIGS[\"y320\"][\"widths\"],\n+                MODEL_CONFIGS[\"y320\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y320\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y320\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+RegNetX002.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX002\")\n+RegNetX004.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX004\")\n+RegNetX006.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX006\")\n+RegNetX008.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX008\")\n+RegNetX016.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX016\")\n+RegNetX032.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX032\")\n+RegNetX040.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX040\")\n+RegNetX064.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX064\")\n+RegNetX080.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX080\")\n+RegNetX120.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX120\")\n+RegNetX160.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX160\")\n+RegNetX320.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX320\")\n+\n+RegNetY002.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY002\")\n+RegNetY004.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY004\")\n+RegNetY006.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY006\")\n+RegNetY008.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY008\")\n+RegNetY016.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY016\")\n+RegNetY032.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY032\")\n+RegNetY040.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY040\")\n+RegNetY064.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY064\")\n+RegNetY080.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY080\")\n+RegNetY120.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY120\")\n+RegNetY160.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY160\")\n+RegNetY320.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY320\")\n+\n+\n+@keras_export('keras.applications.regnet.preprocess_input')\n+def preprocess_input(x, data_format=None):  # pylint: disable=unused-argument\n+  \"\"\"A placeholder method for backward compatibility.\n+\n+  The preprocessing logic has been included in the efficientnet model\n+  implementation. Users are no longer required to call this method to normalize\n+  the input data. This method does nothing and only kept as a placeholder to\n+  align the API surface between old and new version of model.\n+\n+  Args:\n+    x: A floating point `numpy.array` or a `tf.Tensor`.\n+    data_format: Optional data format of the image tensor/array. Defaults to\n+      None, in which case the global setting\n+      `tf.keras.backend.image_data_format()` is used (unless you changed it,\n+      it defaults to \"channels_last\").{mode}\n+\n+  Returns:\n+    Unchanged `numpy.array` or `tf.Tensor`.\n+  \"\"\"\n+  return x\n+\n+\n+@keras_export('keras.applications.regnet.decode_predictions')\n+def decode_predictions(preds, top=5):\n+  return imagenet_utils.decode_predictions(preds, top=top)\n+\n+\n+decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__"
            }
        ],
        "diff": "diff --git a/keras/api/BUILD b/keras/api/BUILD\nindex 71ef2d93167..93751cf705d 100644\n--- a/keras/api/BUILD\n+++ b/keras/api/BUILD\n@@ -31,6 +31,7 @@ keras_packages = [\n     \"keras.applications.mobilenet_v2\",\n     \"keras.applications.mobilenet_v3\",\n     \"keras.applications.nasnet\",\n+    \"keras.applications.regnet\",\n     \"keras.applications.resnet\",\n     \"keras.applications.resnet_v2\",\n     \"keras.applications.vgg16\",\ndiff --git a/keras/api/api_init_files.bzl b/keras/api/api_init_files.bzl\nindex eb2e7c5aabc..de690e09c07 100644\n--- a/keras/api/api_init_files.bzl\n+++ b/keras/api/api_init_files.bzl\n@@ -21,6 +21,7 @@ KERAS_API_INIT_FILES = [\n     \"keras/applications/mobilenet_v2/__init__.py\",\n     \"keras/applications/mobilenet_v3/__init__.py\",\n     \"keras/applications/nasnet/__init__.py\",\n+    \"keras/applications/regnet/__init__.py\",\n     \"keras/applications/resnet/__init__.py\",\n     \"keras/applications/resnet50/__init__.py\",\n     \"keras/applications/resnet_v2/__init__.py\",\n@@ -85,6 +86,7 @@ KERAS_API_INIT_FILES_V1 = [\n     \"keras/applications/mobilenet_v2/__init__.py\",\n     \"keras/applications/mobilenet_v3/__init__.py\",\n     \"keras/applications/nasnet/__init__.py\",\n+    \"keras/applications/regnet/__init__.py\",\n     \"keras/applications/resnet/__init__.py\",\n     \"keras/applications/resnet_v2/__init__.py\",\n     \"keras/applications/resnet50/__init__.py\",\ndiff --git a/keras/applications/BUILD b/keras/applications/BUILD\nindex 7d464c3f665..b3dff108f25 100644\n--- a/keras/applications/BUILD\n+++ b/keras/applications/BUILD\n@@ -25,6 +25,7 @@ py_library(\n         \"mobilenet_v2.py\",\n         \"mobilenet_v3.py\",\n         \"nasnet.py\",\n+        \"regnet.py\",\n         \"resnet.py\",\n         \"resnet_v2.py\",\n         \"vgg16.py\",\n@@ -312,6 +313,23 @@ tf_py_test(\n     ],\n )\n \n+tf_py_test(\n+    name = \"applications_load_weight_test_regnet\",\n+    srcs = [\"applications_load_weight_test.py\"],\n+    args = [\"--module=regnet\"],\n+    main = \"applications_load_weight_test.py\",\n+    tags = [\n+        \"no_oss\",\n+        \"no_pip\",\n+    ],\n+    deps = [\n+        \":applications\",\n+        \"//:expect_absl_installed\",\n+        \"//:expect_tensorflow_installed\",\n+        \"//keras/preprocessing\",\n+    ],\n+)\n+\n tf_py_test(\n     name = \"applications_load_weight_test_nasnet_mobile\",\n     srcs = [\"applications_load_weight_test.py\"],\ndiff --git a/keras/applications/applications_load_weight_test.py b/keras/applications/applications_load_weight_test.py\nindex 07ac482a596..41942c58854 100644\n--- a/keras/applications/applications_load_weight_test.py\n+++ b/keras/applications/applications_load_weight_test.py\n@@ -29,6 +29,7 @@\n from keras.applications import mobilenet_v2\n from keras.applications import mobilenet_v3\n from keras.applications import nasnet\n+from keras.applications import regnet\n from keras.applications import resnet\n from keras.applications import resnet_v2\n from keras.applications import vgg16\n@@ -69,7 +70,16 @@\n         efficientnet_v2.EfficientNetV2B2, efficientnet_v2.EfficientNetV2B3,\n         efficientnet_v2.EfficientNetV2S, efficientnet_v2.EfficientNetV2M,\n         efficientnet_v2.EfficientNetV2L\n-    ])\n+    ]),\n+    'regnet': (regnet,\n+        [regnet.RegNetX002, regnet.RegNetX004, regnet.RegNetX006,\n+         regnet.RegNetX008, regnet.RegNetX016, regnet.RegNetX032,\n+         regnet.RegNetX040, regnet.RegNetX064, regnet.RegNetX080,\n+         regnet.RegNetX120, regnet.RegNetX160, regnet.RegNetX320,\n+         regnet.RegNetY002, regnet.RegNetY004, regnet.RegNetY006,\n+         regnet.RegNetY008, regnet.RegNetY016, regnet.RegNetY032,\n+         regnet.RegNetY040, regnet.RegNetY064, regnet.RegNetY080,\n+         regnet.RegNetY120, regnet.RegNetY160, regnet.RegNetY320])\n }\n \n TEST_IMAGE_PATH = ('https://storage.googleapis.com/tensorflow/'\ndiff --git a/keras/applications/applications_test.py b/keras/applications/applications_test.py\nindex 78e1e510786..9d70d374c93 100644\n--- a/keras/applications/applications_test.py\n+++ b/keras/applications/applications_test.py\n@@ -28,6 +28,7 @@\n from keras.applications import mobilenet_v2\n from keras.applications import mobilenet_v3\n from keras.applications import nasnet\n+from keras.applications import regnet\n from keras.applications import resnet\n from keras.applications import resnet_v2\n from keras.applications import vgg16\n@@ -69,6 +70,30 @@\n     (efficientnet_v2.EfficientNetV2S, 1280),\n     (efficientnet_v2.EfficientNetV2M, 1280),\n     (efficientnet_v2.EfficientNetV2L, 1280),\n+    (regnet.RegNetX002, 368),\n+    (regnet.RegNetX004, 384),\n+    (regnet.RegNetX006, 528),\n+    (regnet.RegNetX008, 672),\n+    (regnet.RegNetX016, 912),\n+    (regnet.RegNetX032, 1008),\n+    (regnet.RegNetX040, 1360),\n+    (regnet.RegNetX064, 1624),\n+    (regnet.RegNetX080, 1920),\n+    (regnet.RegNetX120, 2240),\n+    (regnet.RegNetX160, 2048),\n+    (regnet.RegNetX320, 2520),\n+    (regnet.RegNetY002, 368),\n+    (regnet.RegNetY004, 440),\n+    (regnet.RegNetY006, 608),\n+    (regnet.RegNetY008, 768),\n+    (regnet.RegNetY016, 888),\n+    (regnet.RegNetY032, 1512),\n+    (regnet.RegNetY040, 1088),\n+    (regnet.RegNetY064, 1296),\n+    (regnet.RegNetY080, 2016),\n+    (regnet.RegNetY120, 2240),\n+    (regnet.RegNetY160, 3024),\n+    (regnet.RegNetY320, 3712)\n ]\n \n NASNET_LIST = [\ndiff --git a/keras/applications/regnet.py b/keras/applications/regnet.py\nnew file mode 100644\nindex 00000000000..db88db1c32d\n--- /dev/null\n+++ b/keras/applications/regnet.py\n@@ -0,0 +1,1631 @@\n+# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+# pylint: disable=invalid-name\n+# pylint: disable=missing-docstring\n+\"\"\"RegNet models for Keras.\n+\n+References:\n+\n+- [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+  (CVPR 2020)\n+- [Fast and Accurate Model Scaling](https://arxiv.org/abs/2103.06877)\n+  (CVPR 2021)\n+\"\"\"\n+\n+import tensorflow as tf\n+\n+from keras import backend\n+from keras import layers\n+from keras.applications import imagenet_utils\n+from keras.engine import training\n+from keras.utils import layer_utils\n+from keras.utils import data_utils\n+from tensorflow.python.util.tf_export import keras_export\n+\n+BASE_WEIGHTS_PATH = \"https://storage.googleapis.com/keras-applications/\"\n+\n+WEIGHTS_HASHES = {\n+    \"x002\":\n+        (\"49fb46e56cde07fdaf57bffd851461a86548f6a3a4baef234dd37290b826c0b8\",\n+         \"5445b66cd50445eb7ecab094c1e78d4d3d29375439d1a7798861c4af15ffff21\"),\n+    \"x004\":\n+        (\"3523c7f5ac0dbbcc2fd6d83b3570e7540f7449d3301cc22c29547302114e4088\",\n+         \"de139bf07a66c9256f2277bf5c1b6dd2d5a3a891a5f8a925a10c8a0a113fd6f3\"),\n+    \"x006\":\n+        (\"340216ef334a7bae30daac9f414e693c136fac9ab868704bbfcc9ce6a5ec74bb\",\n+         \"a43ec97ad62f86b2a96a783bfdc63a5a54de02eef54f26379ea05e1bf90a9505\"),\n+    \"x008\":\n+        (\"8f145d6a5fae6da62677bb8d26eb92d0b9dfe143ec1ebf68b24a57ae50a2763d\",\n+         \"3c7e4b0917359304dc18e644475c5c1f5e88d795542b676439c4a3acd63b7207\"),\n+    \"x016\":\n+        (\"31c386f4c7bfef4c021a583099aa79c1b3928057ba1b7d182f174674c5ef3510\",\n+         \"1b8e3d545d190271204a7b2165936a227d26b79bb7922bac5ee4d303091bf17a\"),\n+    \"x032\":\n+        (\"6c025df1409e5ea846375bc9dfa240956cca87ef57384d93fef7d6fa90ca8c7f\",\n+         \"9cd4522806c0fcca01b37874188b2bd394d7c419956d77472a4e072b01d99041\"),\n+    \"x040\":\n+        (\"ba128046c588a26dbd3b3a011b26cb7fa3cf8f269c184c132372cb20b6eb54c1\",\n+         \"b4ed0ca0b9a98e789e05000e830403a7ade4d8afa01c73491c44610195198afe\"),\n+    \"x064\":\n+        (\"0f4489c3cd3ad979bd6b0324213998bcb36dc861d178f977997ebfe53c3ba564\",\n+         \"3e706fa416a18dfda14c713423eba8041ae2509db3e0a611d5f599b5268a46c4\"),\n+    \"x080\":\n+        (\"76320e43272719df648db37271a247c22eb6e810fe469c37a5db7e2cb696d162\",\n+         \"7b1ce8e29ceefec10a6569640ee329dba7fbc98b5d0f6346aabade058b66cf29\"),\n+    \"x120\":\n+        (\"5cafc461b78897d5e4f24e68cb406d18e75f31105ef620e7682b611bb355eb3a\",\n+         \"36174ddd0299db04a42631d028abcb1cc7afec2b705e42bd28fcd325e5d596bf\"),\n+    \"x160\":\n+        (\"8093f57a5824b181fb734ea21ae34b1f7ee42c5298e63cf6d587c290973195d2\",\n+         \"9d1485050bdf19531ffa1ed7827c75850e0f2972118a996b91aa9264b088fd43\"),\n+    \"x320\":\n+        (\"91fb3e6f4e9e44b3687e80977f7f4412ee9937c0c704232664fc83e4322ea01e\",\n+         \"9db7eacc37b85c98184070e1a172e6104c00846f44bcd4e727da9e50d9692398\"),\n+    \"y002\":\n+        (\"1e8091c674532b1a61c04f6393a9c570113e0197f22bd1b98cc4c4fe800c6465\",\n+         \"f63221f63d625b8e201221499682587bfe29d33f50a4c4f4d53be00f66c0f12c\"),\n+    \"y004\":\n+        (\"752fdbad21c78911bf1dcb8c513e5a0e14697b068e5d9e73525dbaa416d18d8e\",\n+         \"45e6ba8309a17a77e67afc05228454b2e0ee6be0dae65edc0f31f1da10cc066b\"),\n+    \"y006\":\n+        (\"98942e07b273da500ff9699a1f88aca78dfad4375faabb0bab784bb0dace80a9\",\n+         \"b70261cba4e60013c99d130cc098d2fce629ff978a445663b6fa4f8fc099a2be\"),\n+    \"y008\":\n+        (\"1b099377cc9a4fb183159a6f9b24bc998e5659d25a449f40c90cbffcbcfdcae4\",\n+         \"b11f5432a216ee640fe9be6e32939defa8d08b8d136349bf3690715a98752ca1\"),\n+    \"y016\":\n+        (\"b7ce1f5e223f0941c960602de922bcf846288ce7a4c33b2a4f2e4ac4b480045b\",\n+         \"d7404f50205e82d793e219afb9eb2bfeb781b6b2d316a6128c6d7d7dacab7f57\"),\n+    \"y032\":\n+        (\"6a6a545cf3549973554c9b94f0cd40e25f229fffb1e7f7ac779a59dcbee612bd\",\n+         \"eb3ac1c45ec60f4f031c3f5180573422b1cf7bebc26c004637517372f68f8937\"),\n+    \"y040\":\n+        (\"98d00118b335162bbffe8f1329e54e5c8e75ee09b2a5414f97b0ddfc56e796f6\",\n+         \"b5be2a5e5f072ecdd9c0b8a437cd896df0efa1f6a1f77e41caa8719b7dfcb05d\"),\n+    \"y064\":\n+        (\"65c948c7a18aaecaad2d1bd4fd978987425604ba6669ef55a1faa0069a2804b7\",\n+         \"885c4b7ed7ea339daca7dafa1a62cb7d41b1068897ef90a5a3d71b4a2e2db31a\"),\n+    \"y080\":\n+        (\"7a2c62da2982e369a4984d3c7c3b32d6f8d3748a71cb37a31156c436c37f3e95\",\n+         \"3d119577e1e3bf8d153b895e8ea9e4ec150ff2d92abdca711b6e949c3fd7115d\"),\n+    \"y120\":\n+        (\"a96ab0d27d3ae35a422ee7df0d789069b3e3217a99334e0ce861a96595bc5986\",\n+         \"4a6fa387108380b730b71feea2ad80b5224b5ea9dc21dc156c93fe3c6186485c\"),\n+    \"y160\":\n+        (\"45067240ffbc7ca2591313fee2f80dbdda6d66ec1a7451446f9a6d00d8f7ac6e\",\n+         \"ead1e6b568be8f34447ec8941299a9df4368736ba9a8205de5427fa20a1fb316\"),\n+    \"y320\": (\"b05e173e4ae635cfa22d06392ee3741284d17dadfee68f2aa6fd8cb2b7561112\",\n+             \"cad78f74a586e24c61d38be17f3ae53bb9674380174d2585da1a526b8c20e1fd\")\n+}\n+\n+# The widths and depths are deduced from a quantized linear function. For\n+# more information, please refer to \"Designing Network Design Spaces\" by\n+# Radosavovic et al.\n+\n+# BatchNorm momentum and epsilon values taken from original implementation.\n+\n+MODEL_CONFIGS = {\n+    \"x002\": {\n+        \"depths\": [1, 1, 4, 7],\n+        \"widths\": [24, 56, 152, 368],\n+        \"group_width\": 8,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x004\": {\n+        \"depths\": [1, 2, 7, 12],\n+        \"widths\": [32, 64, 160, 384],\n+        \"group_width\": 16,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x006\": {\n+        \"depths\": [1, 3, 5, 7],\n+        \"widths\": [48, 96, 240, 528],\n+        \"group_width\": 24,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x008\": {\n+        \"depths\": [1, 3, 7, 5],\n+        \"widths\": [64, 128, 288, 672],\n+        \"group_width\": 16,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x016\": {\n+        \"depths\": [2, 4, 10, 2],\n+        \"widths\": [72, 168, 408, 912],\n+        \"group_width\": 24,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x032\": {\n+        \"depths\": [2, 6, 15, 2],\n+        \"widths\": [96, 192, 432, 1008],\n+        \"group_width\": 48,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x040\": {\n+        \"depths\": [2, 5, 14, 2],\n+        \"widths\": [80, 240, 560, 1360],\n+        \"group_width\": 40,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x064\": {\n+        \"depths\": [2, 4, 10, 1],\n+        \"widths\": [168, 392, 784, 1624],\n+        \"group_width\": 56,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x080\": {\n+        \"depths\": [2, 5, 15, 1],\n+        \"widths\": [80, 240, 720, 1920],\n+        \"group_width\": 120,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x120\": {\n+        \"depths\": [2, 5, 11, 1],\n+        \"widths\": [224, 448, 896, 2240],\n+        \"group_width\": 112,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x160\": {\n+        \"depths\": [2, 6, 13, 1],\n+        \"widths\": [256, 512, 896, 2048],\n+        \"group_width\": 128,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"x320\": {\n+        \"depths\": [2, 7, 13, 1],\n+        \"widths\": [336, 672, 1344, 2520],\n+        \"group_width\": 168,\n+        \"default_size\": 224,\n+        \"block_type\": \"X\"\n+    },\n+    \"y002\": {\n+        \"depths\": [1, 1, 4, 7],\n+        \"widths\": [24, 56, 152, 368],\n+        \"group_width\": 8,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y004\": {\n+        \"depths\": [1, 3, 6, 6],\n+        \"widths\": [48, 104, 208, 440],\n+        \"group_width\": 8,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y006\": {\n+        \"depths\": [1, 3, 7, 4],\n+        \"widths\": [48, 112, 256, 608],\n+        \"group_width\": 16,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y008\": {\n+        \"depths\": [1, 3, 8, 2],\n+        \"widths\": [64, 128, 320, 768],\n+        \"group_width\": 16,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y016\": {\n+        \"depths\": [2, 6, 17, 2],\n+        \"widths\": [48, 120, 336, 888],\n+        \"group_width\": 24,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y032\": {\n+        \"depths\": [2, 5, 13, 1],\n+        \"widths\": [72, 216, 576, 1512],\n+        \"group_width\": 24,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y040\": {\n+        \"depths\": [2, 6, 12, 2],\n+        \"widths\": [128, 192, 512, 1088],\n+        \"group_width\": 64,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y064\": {\n+        \"depths\": [2, 7, 14, 2],\n+        \"widths\": [144, 288, 576, 1296],\n+        \"group_width\": 72,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y080\": {\n+        \"depths\": [2, 4, 10, 1],\n+        \"widths\": [168, 448, 896, 2016],\n+        \"group_width\": 56,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y120\": {\n+        \"depths\": [2, 5, 11, 1],\n+        \"widths\": [224, 448, 896, 2240],\n+        \"group_width\": 112,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y160\": {\n+        \"depths\": [2, 4, 11, 1],\n+        \"widths\": [224, 448, 1232, 3024],\n+        \"group_width\": 112,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+    \"y320\": {\n+        \"depths\": [2, 5, 12, 1],\n+        \"widths\": [232, 696, 1392, 3712],\n+        \"group_width\": 232,\n+        \"default_size\": 224,\n+        \"block_type\": \"Y\"\n+    },\n+}\n+\n+BASE_DOCSTRING = \"\"\"Instantiates the {name} architecture.\n+\n+  References:\n+    - [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+    (CVPR 2020)\n+    - [Fast and Accurate Model Scaling](https://arxiv.org/abs/2103.06877)\n+    (CVPR 2021)\n+\n+  For image classification use cases, see\n+  [this page for detailed examples](\n+  https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n+\n+  For transfer learning use cases, make sure to read the\n+  [guide to transfer learning & fine-tuning](\n+    https://keras.io/guides/transfer_learning/).\n+\n+  Note: Each Keras Application expects a specific kind of input preprocessing.\n+  For Regnets, preprocessing is included in the model using a `Rescaling` layer.\n+  RegNet models expect their inputs to be float or uint8 tensors of pixels with \n+  values in the [0-255] range.\n+\n+  The naming of models is as follows: `RegNet<block_type><flops>` where \n+  `block_type` is one of `(Y, Z)` and `flops` signifies hundred million \n+  floating point operations. For example RegNetY64 corresponds to RegNet with \n+  Y block and 6.4 giga flops (64 hundred million flops). \n+\n+  Args:\n+    include_top: Whether to include the fully-connected\n+        layer at the top of the network. Defaults to True.\n+    weights: One of `None` (random initialization),\n+          \"imagenet\" (pre-training on ImageNet),\n+          or the path to the weights file to be loaded. Defaults to \"imagenet\".\n+    input_tensor: Optional Keras tensor\n+        (i.e. output of `layers.Input()`)\n+        to use as image input for the model.\n+    input_shape: Optional shape tuple, only to be specified\n+        if `include_top` is False.\n+        It should have exactly 3 inputs channels.\n+    pooling: Optional pooling mode for feature extraction\n+        when `include_top` is `False`. Defaults to None.\n+        - `None` means that the output of the model will be\n+            the 4D tensor output of the\n+            last convolutional layer.\n+        - `avg` means that global average pooling\n+            will be applied to the output of the\n+            last convolutional layer, and thus\n+            the output of the model will be a 2D tensor.\n+        - `max` means that global max pooling will\n+            be applied.\n+    classes: Optional number of classes to classify images\n+        into, only to be specified if `include_top` is True, and\n+        if no `weights` argument is specified. Defaults to 1000 (number of\n+        ImageNet classes).\n+    classifier_activation: A `str` or callable. The activation function to use\n+        on the \"top\" layer. Ignored unless `include_top=True`. Set\n+        `classifier_activation=None` to return the logits of the \"top\" layer.\n+        Defaults to \"softmax\".\n+        When loading pretrained weights, `classifier_activation` can only\n+        be `None` or `\"softmax\"`.\n+\n+  Returns:\n+    A `keras.Model` instance.\n+\"\"\"\n+\n+\n+def PreStem(name=None):\n+  \"\"\"\n+  Rescales and normalizes inputs to [0,1] and ImageNet mean and std.\n+  \n+  Args:\n+    name: name prefix\n+    \n+  Returns:\n+    Rescaled and normalized tensor\n+  \"\"\"\n+  if name is None:\n+    name = \"prestem\" + str(backend.get_uid(\"prestem\"))\n+\n+  def apply(x):\n+    x = layers.Rescaling(scale=1. / 255., name=name + \"_prestem_rescaling\")(x)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def Stem(name=None):\n+  \"\"\"\n+  Implementation of RegNet stem. (Common to all model variants)\n+  \n+  Args:\n+    name: name prefix   \n+\n+  Returns:\n+    Output tensor of the Stem\n+  \"\"\"\n+  if name is None:\n+    name = \"stem\" + str(backend.get_uid(\"stem\"))\n+\n+  def apply(x):\n+    x = layers.Conv2D(32, (3, 3),\n+                      strides=2,\n+                      use_bias=False,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_stem_conv\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_stem_bn\")(x)\n+    x = layers.ReLU(name=name + \"_stem_relu\")(x)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def SqueezeAndExciteBlock(filters_in, se_filters, name=None):\n+  \"\"\"\n+  Implements the Squeeze and excite block (https://arxiv.org/abs/1709.01507)\n+  \n+  Args:\n+    filters_in: input filters to the block\n+    se_filters: filters to squeeze to\n+    name: name prefix\n+  \n+  Returns:\n+    A function object   \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"squeeze_and_excite\"))\n+\n+  def apply(inputs):\n+    x = layers.GlobalAveragePooling2D(name=name + \"_squeeze_and_excite_gap\",\n+                                      keepdims=True)(inputs)\n+    x = layers.Conv2D(se_filters, (1, 1),\n+                      activation=\"relu\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_squeeze_and_excite_squeeze\")(x)\n+    x = layers.Conv2D(filters_in, (1, 1),\n+                      activation=\"sigmoid\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_squeeze_and_excite_excite\")(x)\n+    x = tf.math.multiply(x, inputs)\n+    return x\n+\n+  return apply\n+\n+\n+def XBlock(filters_in, filters_out, group_width, stride=1, name=None):\n+  \"\"\"\n+  Implementation of X Block. \n+  Reference: [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+\n+  Args:\n+    filters_in: filters in the input tensor\n+    filters_out: filters in the output tensor\n+    group_width: group width\n+    stride: stride\n+    name: name prefix\n+\n+  Return:\n+    Output tensor of the block \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"xblock\"))\n+\n+  def apply(inputs):\n+    if filters_in != filters_out and stride == 1:\n+      raise ValueError(\n+          f\"Input filters({filters_in}) and output filters({filters_out}) \"\n+          f\"are not equal for stride {stride}. Input and output filters must \"\n+          f\"be equal for stride={stride}.\")\n+\n+    # Declare layers\n+    groups = filters_out // group_width\n+\n+    if stride != 1:\n+      skip = layers.Conv2D(filters_out, (1, 1),\n+                           strides=stride,\n+                           use_bias=False,\n+                           kernel_initializer=\"he_normal\",\n+                           name=name + \"_skip_1x1\")(inputs)\n+      skip = layers.BatchNormalization(momentum=0.9,\n+                                       epsilon=1e-5,\n+                                       name=name + \"_skip_bn\")(skip)\n+    else:\n+      skip = inputs\n+\n+    # Build block\n+    # conv_1x1_1\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_1\")(inputs)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_1_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_1x1_1_relu\")(x)\n+\n+    # conv_3x3\n+    x = layers.Conv2D(filters_out, (3, 3),\n+                      use_bias=False,\n+                      strides=stride,\n+                      groups=groups,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_3x3\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_3x3_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_3x3_relu\")(x)\n+\n+    # conv_1x1_2\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_2\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_2_bn\")(x)\n+\n+    x = layers.ReLU(name=name + \"_exit_relu\")(x + skip)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def YBlock(filters_in,\n+           filters_out,\n+           group_width,\n+           stride=1,\n+           squeeze_excite_ratio=0.25,\n+           name=None):\n+  \"\"\"\n+  Implementation of Y Block. \n+  Reference: [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678)\n+\n+  Args:\n+    filters_in: filters in the input tensor\n+    filters_out: filters in the output tensor\n+    group_width: group width\n+    stride: stride\n+    squeeze_excite_ratio: expansion ration for Squeeze and Excite block\n+    name: name prefix\n+\n+  Return:\n+    Output tensor of the block \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"yblock\"))\n+\n+  def apply(inputs):\n+    if filters_in != filters_out and stride == 1:\n+      raise ValueError(\n+          f\"Input filters({filters_in}) and output filters({filters_out}) \"\n+          f\"are not equal for stride {stride}. Input and output filters must  \"\n+          f\"be equal for stride={stride}.\")\n+\n+    groups = filters_out // group_width\n+    se_filters = int(filters_in * squeeze_excite_ratio)\n+\n+    if stride != 1:\n+      skip = layers.Conv2D(filters_out, (1, 1),\n+                           strides=stride,\n+                           use_bias=False,\n+                           kernel_initializer=\"he_normal\",\n+                           name=name + \"_skip_1x1\")(inputs)\n+      skip = layers.BatchNormalization(momentum=0.9,\n+                                       epsilon=1e-5,\n+                                       name=name + \"_skip_bn\")(skip)\n+    else:\n+      skip = inputs\n+\n+    # Build block\n+    # conv_1x1_1\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_1\")(inputs)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_1_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_1x1_1_relu\")(x)\n+\n+    # conv_3x3\n+    x = layers.Conv2D(filters_out, (3, 3),\n+                      use_bias=False,\n+                      strides=stride,\n+                      groups=groups,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_3x3\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_3x3_bn\")(x)\n+    x = layers.ReLU(name=name + \"_conv_3x3_relu\")(x)\n+\n+    # Squeeze-Excitation block\n+    x = SqueezeAndExciteBlock(filters_out, se_filters, name=name)(x)\n+\n+    # conv_1x1_2\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_2\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_2_bn\")(x)\n+\n+    x = layers.ReLU(name=name + \"_exit_relu\")(x + skip)\n+\n+    return x\n+\n+  return apply\n+\n+\n+def ZBlock(filters_in,\n+           filters_out,\n+           group_width,\n+           stride=1,\n+           squeeze_excite_ratio=0.25,\n+           bottleneck_ratio=0.25,\n+           name=None):\n+  \"\"\"\n+  Implementation of Z block\n+  Reference: [Fast and Accurate Model Scaling](https://arxiv.org/abs/2103.06877).\n+  \n+  Args:\n+    filters_in: filters in the input tensor\n+    filters_out: filters in the output tensor\n+    group_width: group width\n+    stride: stride\n+    squeeze_excite_ratio: expansion ration for Squeeze and Excite block\n+    bottleneck_ratio: inverted bottleneck ratio \n+    name: name prefix\n+\n+  Return:\n+    Output tensor of the block \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"zblock\"))\n+\n+  def apply(inputs):\n+    if filters_in != filters_out and stride == 1:\n+      raise ValueError(\n+          f\"Input filters({filters_in}) and output filters({filters_out})\"\n+          f\"are not equal for stride {stride}. Input and output filters must be\"\n+          f\" equal for stride={stride}.\")\n+\n+    groups = filters_out // group_width\n+    se_filters = int(filters_in * squeeze_excite_ratio)\n+\n+    inv_btlneck_filters = int(filters_out / bottleneck_ratio)\n+\n+    # Build block\n+    # conv_1x1_1\n+    x = layers.Conv2D(inv_btlneck_filters, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_1\")(inputs)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_1_bn\")(x)\n+    x = tf.nn.silu(x)\n+\n+    # conv_3x3\n+    x = layers.Conv2D(inv_btlneck_filters, (3, 3),\n+                      use_bias=False,\n+                      strides=stride,\n+                      groups=groups,\n+                      padding=\"same\",\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_3x3\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_3x3_bn\")(x)\n+    x = tf.nn.silu(x)\n+\n+    # Squeeze-Excitation block\n+    x = SqueezeAndExciteBlock(inv_btlneck_filters, se_filters, name=name)\n+\n+    # conv_1x1_2\n+    x = layers.Conv2D(filters_out, (1, 1),\n+                      use_bias=False,\n+                      kernel_initializer=\"he_normal\",\n+                      name=name + \"_conv_1x1_2\")(x)\n+    x = layers.BatchNormalization(momentum=0.9,\n+                                  epsilon=1e-5,\n+                                  name=name + \"_conv_1x1_2_bn\")(x)\n+\n+    if stride != 1:\n+      return x\n+    else:\n+      return x + inputs\n+\n+  return apply\n+\n+\n+def Stage(block_type, depth, group_width, filters_in, filters_out, name=None):\n+  \"\"\"\n+  Implementation of Stage in RegNet.\n+\n+  Args:\n+    block_type: must be one of \"X\", \"Y\", \"Z\"\n+    depth: depth of stage, number of blocks to use\n+    group_width: group width of all blocks in  this stage\n+    filters_in: input filters to this stage\n+    filters_out: output filters from this stage\n+    name: name prefix\n+\n+  Returns:\n+    Output tensor of Stage\n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"stage\"))\n+\n+  def apply(inputs):\n+    x = inputs\n+    if block_type == \"X\":\n+      x = XBlock(filters_in,\n+                 filters_out,\n+                 group_width,\n+                 stride=2,\n+                 name=f\"{name}_XBlock_0\")(x)\n+      for i in range(1, depth):\n+        x = XBlock(filters_out,\n+                   filters_out,\n+                   group_width,\n+                   name=f\"{name}_XBlock_{i}\")(x)\n+    elif block_type == \"Y\":\n+      x = YBlock(filters_in,\n+                 filters_out,\n+                 group_width,\n+                 stride=2,\n+                 name=name + \"_YBlock_0\")(x)\n+      for i in range(1, depth):\n+        x = YBlock(filters_out,\n+                   filters_out,\n+                   group_width,\n+                   name=f\"{name}_YBlock_{i}\")(x)\n+    elif block_type == \"Z\":\n+      x = ZBlock(filters_in,\n+                 filters_out,\n+                 group_width,\n+                 stride=2,\n+                 name=f\"{name}_ZBlock_0\")(x)\n+      for i in range(1, depth):\n+        x = ZBlock(filters_out,\n+                   filters_out,\n+                   group_width,\n+                   name=f\"{name}_ZBlock_{i}\")(x)\n+    else:\n+      raise NotImplementedError(f\"Block type `{block_type}` not recognized.\"\n+                                f\"block_type must be one of (`X`, `Y`, `Z`). \")\n+    return x\n+\n+  return apply\n+\n+\n+def Head(num_classes=1000, name=None):\n+  \"\"\"\n+  Implementation of classification head of RegNet\n+  \n+  Args:\n+    x: Input tensor\n+    num_classes: number of classes for Dense layer\n+  \n+  Returns:\n+    Output logits tensor. \n+  \"\"\"\n+  if name is None:\n+    name = str(backend.get_uid(\"head\"))\n+\n+  def apply(x):\n+    x = layers.GlobalAveragePooling2D(name=name + \"_head_gap\")(x)\n+    x = layers.Dense(num_classes, name=name + \"head_dense\")(x)\n+    return x\n+\n+  return apply\n+\n+\n+def RegNet(depths,\n+           widths,\n+           group_width,\n+           block_type,\n+           default_size,\n+           model_name=\"regnet\",\n+           include_preprocessing=True,\n+           include_top=True,\n+           weights=\"imagenet\",\n+           input_tensor=None,\n+           input_shape=None,\n+           pooling=None,\n+           classes=1000,\n+           classifier_activation=\"softmax\"):\n+  \"\"\" \n+  Instantiates RegNet architecture given specific configuration.\n+\n+  Args:\n+    depths: An iterable containing depths for each individual stages. \n+    widths: An iterable containing output channel width of each individual \n+      stages\n+    group_width: Number of channels to be used in each group. See grouped \n+      convolutions for more information.\n+    block_type: Must be one of `{\"X\", \"Y\", \"Z\"}`. For more details see the\n+      papers \"Designing network design spaces\" and \"Fast and Accurate Model \n+      Scaling\"\n+    default_size: Default input image size. \n+    model_name: An optional name for the model.\n+    include_preprocessing: boolean denoting whther to include preprocessing in \n+      the model\n+    include_top: Boolean denoting whether to include classification head to \n+      the model.\n+    weights: one of `None` (random initialization),\n+      \"imagenet\" (pre-training on ImageNet),\n+      or the path to the weights file to be loaded.\n+    input_tensor: optional Keras tensor\n+      (i.e. output of `layers.Input()`)\n+      to use as image input for the model.\n+    input_shape: optional shape tuple, only to be specified\n+      if `include_top` is False.\n+      It should have exactly 3 inputs channels.\n+    pooling: optional pooling mode for feature extraction\n+      when `include_top` is `False`.\n+      - `None` means that the output of the model will be\n+          the 4D tensor output of the\n+          last convolutional layer.\n+      - `avg` means that global average pooling\n+          will be applied to the output of the\n+          last convolutional layer, and thus\n+          the output of the model will be a 2D tensor.\n+      - `max` means that global max pooling will\n+          be applied.\n+    classes: optional number of classes to classify images\n+      into, only to be specified if `include_top` is True, and\n+      if no `weights` argument is specified.\n+    classifier_activation: A `str` or callable. The activation function to use\n+      on the \"top\" layer. Ignored unless `include_top=True`. Set\n+      `classifier_activation=None` to return the logits of the \"top\" layer.        \n+  \n+  Returns:\n+    A `keras.Model` instance.\n+  \n+  Raises:\n+      ValueError: in case of invalid argument for `weights`,\n+        or invalid input shape.\n+      ValueError: if `classifier_activation` is not `softmax` or `None` when\n+        using a pretrained top layer.\n+      ValueError: if `include_top` is True but `num_classes` is not 1000.\n+      ValueError: if `block_type` is not one of `{\"X\", \"Y\", \"Z\"}`\n+  \n+  \"\"\"\n+  if not (weights in {\"imagenet\", None} or tf.io.gfile.exists(weights)):\n+    raise ValueError(\"The `weights` argument should be either \"\n+                     \"`None` (random initialization), `imagenet` \"\n+                     \"(pre-training on ImageNet), \"\n+                     \"or the path to the weights file to be loaded.\")\n+\n+  if weights == \"imagenet\" and include_top and classes != 1000:\n+    raise ValueError(\"If using `weights` as `'imagenet'` with `include_top`\"\n+                     \" as true, `classes` should be 1000\")\n+\n+  # Determine proper input shape\n+  input_shape = imagenet_utils.obtain_input_shape(\n+      input_shape,\n+      default_size=default_size,\n+      min_size=32,\n+      data_format=backend.image_data_format(),\n+      require_flatten=include_top,\n+      weights=weights)\n+\n+  if input_tensor is None:\n+    img_input = layers.Input(shape=input_shape)\n+  else:\n+    if not backend.is_keras_tensor(input_tensor):\n+      img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n+    else:\n+      img_input = input_tensor\n+\n+  if input_tensor is not None:\n+    inputs = layer_utils.get_source_inputs(input_tensor)\n+  else:\n+    inputs = img_input\n+\n+  x = inputs\n+  if include_preprocessing:\n+    x = PreStem(name=model_name)(x)\n+  x = Stem(name=model_name)(x)\n+\n+  in_channels = 32  # Output from Stem\n+\n+  for num_stage in range(4):\n+    depth = depths[num_stage]\n+    out_channels = widths[num_stage]\n+\n+    x = Stage(block_type,\n+              depth,\n+              group_width,\n+              in_channels,\n+              out_channels,\n+              name=model_name + \"_Stage_\" + str(num_stage))(x)\n+    in_channels = out_channels\n+\n+  if include_top:\n+    x = Head(num_classes=classes)(x)\n+    imagenet_utils.validate_activation(classifier_activation, weights)\n+\n+  else:\n+    if pooling == \"avg\":\n+      x = layers.GlobalAveragePooling2D()(x)\n+    elif pooling == \"max\":\n+      x = layers.GlobalMaxPooling2D()(x)\n+\n+  model = training.Model(inputs=inputs, outputs=x, name=model_name)\n+\n+  # Load weights.\n+  if weights == \"imagenet\":\n+    if include_top:\n+      file_suffix = \".h5\"\n+      file_hash = WEIGHTS_HASHES[model_name[-4:]][0]\n+    else:\n+      file_suffix = \"_notop.h5\"\n+      file_hash = WEIGHTS_HASHES[model_name[-4:]][1]\n+    file_name = model_name + file_suffix\n+    weights_path = data_utils.get_file(file_name,\n+                                       BASE_WEIGHTS_PATH + file_name,\n+                                       cache_subdir=\"models\",\n+                                       file_hash=file_hash)\n+    model.load_weights(weights_path)\n+  elif weights is not None:\n+    model.load_weights(weights)\n+\n+  return model\n+\n+\n+## Instantiating variants ##\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX002\",\n+              \"keras.applications.RegNetX002\")\n+def RegNetX002(model_name=\"regnetx002\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x002\"][\"depths\"],\n+                MODEL_CONFIGS[\"x002\"][\"widths\"],\n+                MODEL_CONFIGS[\"x002\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x002\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x002\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX004\",\n+              \"keras.applications.RegNetX004\")\n+def RegNetX004(model_name=\"regnetx004\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x004\"][\"depths\"],\n+                MODEL_CONFIGS[\"x004\"][\"widths\"],\n+                MODEL_CONFIGS[\"x004\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x004\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x004\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX006\",\n+              \"keras.applications.RegNetX006\")\n+def RegNetX006(model_name=\"regnetx006\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x006\"][\"depths\"],\n+                MODEL_CONFIGS[\"x006\"][\"widths\"],\n+                MODEL_CONFIGS[\"x006\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x006\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x006\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX008\",\n+              \"keras.applications.RegNetX008\")\n+def RegNetX008(model_name=\"regnetx008\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x008\"][\"depths\"],\n+                MODEL_CONFIGS[\"x008\"][\"widths\"],\n+                MODEL_CONFIGS[\"x008\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x008\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x008\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX016\",\n+              \"keras.applications.RegNetX016\")\n+def RegNetX016(model_name=\"regnetx016\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x016\"][\"depths\"],\n+                MODEL_CONFIGS[\"x016\"][\"widths\"],\n+                MODEL_CONFIGS[\"x016\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x016\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x016\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX032\",\n+              \"keras.applications.RegNetX032\")\n+def RegNetX032(model_name=\"regnetx032\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x032\"][\"depths\"],\n+                MODEL_CONFIGS[\"x032\"][\"widths\"],\n+                MODEL_CONFIGS[\"x032\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x032\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x032\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX040\",\n+              \"keras.applications.RegNetX040\")\n+def RegNetX040(model_name=\"regnetx040\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x040\"][\"depths\"],\n+                MODEL_CONFIGS[\"x040\"][\"widths\"],\n+                MODEL_CONFIGS[\"x040\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x040\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x040\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX064\",\n+              \"keras.applications.RegNetX064\")\n+def RegNetX064(model_name=\"regnetx064\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x064\"][\"depths\"],\n+                MODEL_CONFIGS[\"x064\"][\"widths\"],\n+                MODEL_CONFIGS[\"x064\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x064\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x064\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX080\",\n+              \"keras.applications.RegNetX080\")\n+def RegNetX080(model_name=\"regnetx080\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x080\"][\"depths\"],\n+                MODEL_CONFIGS[\"x080\"][\"widths\"],\n+                MODEL_CONFIGS[\"x080\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x080\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x080\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX120\",\n+              \"keras.applications.RegNetX120\")\n+def RegNetX120(model_name=\"regnetx120\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x120\"][\"depths\"],\n+                MODEL_CONFIGS[\"x120\"][\"widths\"],\n+                MODEL_CONFIGS[\"x120\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x120\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x120\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX160\",\n+              \"keras.applications.RegNetX160\")\n+def RegNetX160(model_name=\"regnetx160\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x160\"][\"depths\"],\n+                MODEL_CONFIGS[\"x160\"][\"widths\"],\n+                MODEL_CONFIGS[\"x160\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x160\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x160\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetX320\",\n+              \"keras.applications.RegNetX320\")\n+def RegNetX320(model_name=\"regnetx320\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"x320\"][\"depths\"],\n+                MODEL_CONFIGS[\"x320\"][\"widths\"],\n+                MODEL_CONFIGS[\"x320\"][\"group_width\"],\n+                MODEL_CONFIGS[\"x320\"][\"block_type\"],\n+                MODEL_CONFIGS[\"x320\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY002\",\n+              \"keras.applications.RegNetY002\")\n+def RegNetY002(model_name=\"regnety002\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y002\"][\"depths\"],\n+                MODEL_CONFIGS[\"y002\"][\"widths\"],\n+                MODEL_CONFIGS[\"y002\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y002\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y002\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY004\",\n+              \"keras.applications.RegNetY004\")\n+def RegNetY004(model_name=\"regnety004\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y004\"][\"depths\"],\n+                MODEL_CONFIGS[\"y004\"][\"widths\"],\n+                MODEL_CONFIGS[\"y004\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y004\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y004\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY006\",\n+              \"keras.applications.RegNetY006\")\n+def RegNetY006(model_name=\"regnety006\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y006\"][\"depths\"],\n+                MODEL_CONFIGS[\"y006\"][\"widths\"],\n+                MODEL_CONFIGS[\"y006\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y006\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y006\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY008\",\n+              \"keras.applications.RegNetY008\")\n+def RegNetY008(model_name=\"regnety008\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y008\"][\"depths\"],\n+                MODEL_CONFIGS[\"y008\"][\"widths\"],\n+                MODEL_CONFIGS[\"y008\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y008\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y008\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY016\",\n+              \"keras.applications.RegNetY016\")\n+def RegNetY016(model_name=\"regnety016\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y016\"][\"depths\"],\n+                MODEL_CONFIGS[\"y016\"][\"widths\"],\n+                MODEL_CONFIGS[\"y016\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y016\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y016\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY032\",\n+              \"keras.applications.RegNetY032\")\n+def RegNetY032(model_name=\"regnety032\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y032\"][\"depths\"],\n+                MODEL_CONFIGS[\"y032\"][\"widths\"],\n+                MODEL_CONFIGS[\"y032\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y032\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y032\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY040\",\n+              \"keras.applications.RegNetY040\")\n+def RegNetY040(model_name=\"regnety040\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y040\"][\"depths\"],\n+                MODEL_CONFIGS[\"y040\"][\"widths\"],\n+                MODEL_CONFIGS[\"y040\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y040\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y040\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY064\",\n+              \"keras.applications.RegNetY064\")\n+def RegNetY064(model_name=\"regnety064\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y064\"][\"depths\"],\n+                MODEL_CONFIGS[\"y064\"][\"widths\"],\n+                MODEL_CONFIGS[\"y064\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y064\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y064\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY080\",\n+              \"keras.applications.RegNetY080\")\n+def RegNetY080(model_name=\"regnety080\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y080\"][\"depths\"],\n+                MODEL_CONFIGS[\"y080\"][\"widths\"],\n+                MODEL_CONFIGS[\"y080\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y080\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y080\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY120\",\n+              \"keras.applications.RegNetY120\")\n+def RegNetY120(model_name=\"regnety120\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y120\"][\"depths\"],\n+                MODEL_CONFIGS[\"y120\"][\"widths\"],\n+                MODEL_CONFIGS[\"y120\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y120\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y120\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY160\",\n+              \"keras.applications.RegNetY160\")\n+def RegNetY160(model_name=\"regnety160\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y160\"][\"depths\"],\n+                MODEL_CONFIGS[\"y160\"][\"widths\"],\n+                MODEL_CONFIGS[\"y160\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y160\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y160\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+@keras_export(\"keras.applications.regnet.RegNetY320\",\n+              \"keras.applications.RegNetY320\")\n+def RegNetY320(model_name=\"regnety320\",\n+               include_top=True,\n+               include_preprocessing=True,\n+               weights=None,\n+               input_tensor=None,\n+               input_shape=None,\n+               pooling=None,\n+               classes=1000,\n+               classifier_activation='softmax'):\n+  return RegNet(MODEL_CONFIGS[\"y320\"][\"depths\"],\n+                MODEL_CONFIGS[\"y320\"][\"widths\"],\n+                MODEL_CONFIGS[\"y320\"][\"group_width\"],\n+                MODEL_CONFIGS[\"y320\"][\"block_type\"],\n+                MODEL_CONFIGS[\"y320\"][\"default_size\"],\n+                model_name=model_name,\n+                include_top=include_top,\n+                include_preprocessing=include_preprocessing,\n+                weights=weights,\n+                input_tensor=input_tensor,\n+                input_shape=input_shape,\n+                pooling=pooling,\n+                classes=classes,\n+                classifier_activation=classifier_activation)\n+\n+\n+RegNetX002.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX002\")\n+RegNetX004.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX004\")\n+RegNetX006.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX006\")\n+RegNetX008.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX008\")\n+RegNetX016.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX016\")\n+RegNetX032.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX032\")\n+RegNetX040.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX040\")\n+RegNetX064.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX064\")\n+RegNetX080.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX080\")\n+RegNetX120.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX120\")\n+RegNetX160.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX160\")\n+RegNetX320.__doc__ = BASE_DOCSTRING.format(name=\"RegNetX320\")\n+\n+RegNetY002.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY002\")\n+RegNetY004.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY004\")\n+RegNetY006.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY006\")\n+RegNetY008.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY008\")\n+RegNetY016.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY016\")\n+RegNetY032.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY032\")\n+RegNetY040.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY040\")\n+RegNetY064.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY064\")\n+RegNetY080.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY080\")\n+RegNetY120.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY120\")\n+RegNetY160.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY160\")\n+RegNetY320.__doc__ = BASE_DOCSTRING.format(name=\"RegNetY320\")\n+\n+\n+@keras_export('keras.applications.regnet.preprocess_input')\n+def preprocess_input(x, data_format=None):  # pylint: disable=unused-argument\n+  \"\"\"A placeholder method for backward compatibility.\n+\n+  The preprocessing logic has been included in the efficientnet model\n+  implementation. Users are no longer required to call this method to normalize\n+  the input data. This method does nothing and only kept as a placeholder to\n+  align the API surface between old and new version of model.\n+\n+  Args:\n+    x: A floating point `numpy.array` or a `tf.Tensor`.\n+    data_format: Optional data format of the image tensor/array. Defaults to\n+      None, in which case the global setting\n+      `tf.keras.backend.image_data_format()` is used (unless you changed it,\n+      it defaults to \"channels_last\").{mode}\n+\n+  Returns:\n+    Unchanged `numpy.array` or `tf.Tensor`.\n+  \"\"\"\n+  return x\n+\n+\n+@keras_export('keras.applications.regnet.decode_predictions')\n+def decode_predictions(preds, top=5):\n+  return imagenet_utils.decode_predictions(preds, top=top)\n+\n+\n+decode_predictions.__doc__ = imagenet_utils.decode_predictions.__doc__\n",
        "reviews": [
            {
                "reviewer": "lgeiger",
                "state": "COMMENTED",
                "body": "Thanks again for opening this PR! I have two tiny suggestions to slightly improve readability."
            },
            {
                "reviewer": "mattdangerw",
                "state": "COMMENTED",
                "body": "Thanks for the PR! Left a few comments. Do you have the weights for the applications available online somewhere?"
            },
            {
                "reviewer": "AdityaKane2001",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "AdityaKane2001",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "AdityaKane2001",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "mattdangerw",
                "state": "APPROVED",
                "body": "Looks great! Approving with two last comments.\r\n\r\nNote that we will still need to go through a bit of process on our side to update weights, generate files for the new API and test everything out. If anything comes up there might need to message back here for changes.\r\n\r\nThank you!"
            },
            {
                "reviewer": "mattdangerw",
                "state": "APPROVED",
                "body": "No comment"
            },
            {
                "reviewer": "mattdangerw",
                "state": "COMMENTED",
                "body": "I've uploaded weights and gen'd api files for this PR, things are looking overall good. However the change to applications_load_weight_tests is breaking right now. Commented on the line. Is that change necessary? Thanks!"
            },
            {
                "reviewer": "AdityaKane2001",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "mattdangerw",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "AdityaKane2001",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "mattdangerw",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "AdityaKane2001",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "AdityaKane2001",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "mattdangerw",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "AdityaKane2001",
                "state": "COMMENTED",
                "body": "No comment"
            }
        ],
        "comments": [
            {
                "commenter": "innat",
                "body": "@AdityaKane2001 \r\nWondering, looks like it's the first time we're going to have lots of variants of the same model in `tf.keras.applications`. Great job anyway. "
            },
            {
                "commenter": "AdityaKane2001",
                "body": "@innat \r\n\r\nYes, that is the case. Thank you :) "
            },
            {
                "commenter": "MrinalTyagi",
                "body": "> @AdityaKane2001 Wondering, looks like it's the first time we're going to have lots of variants of the same model in `tf.keras.applications`. Great job anyway.\r\n\r\n@innat Isn't addition of ResNet18 and 34 possible in similar fashion?"
            },
            {
                "commenter": "innat",
                "body": "@MrinalTyagi \r\nI agree. But I don't know why these models aren't there. There're some requests [1](https://github.com/keras-team/keras/issues/15269), [2](https://github.com/keras-team/keras-cv/issues/917), [3](https://github.com/keras-team/keras/issues/15267), [4](https://github.com/keras-team/keras/issues/15268) are pending. Maybe there're some criteria that I'm unaware of. "
            },
            {
                "commenter": "AdityaKane2001",
                "body": "@lgeiger  Always appreciated! Thanks for the changes. I'll merge them tomorrow."
            },
            {
                "commenter": "AdityaKane2001",
                "body": "@mattdangerw \r\n\r\nThanks for the review! Made requested changes.\r\n\r\n> Do you have the weights for the applications available online somewhere?\r\n\r\nI am still training these models, and I'm updating the [tables](https://github.com/keras-team/keras/pull/15702#issue-788479260) at the start of the thread accordingly. I'll test the loading code parallelly. "
            },
            {
                "commenter": "AdityaKane2001",
                "body": "@fchollet @mattdangerw \r\n\r\nI have completed training of all the models. I have updated the tables at the [start of the thread](https://github.com/keras-team/keras/pull/15702#issue-788479260) accordingly.  There are a couple of things I want to bring to your notice:\r\n\r\n1. `model.predict(X_test)` does not work with grouped convolutions on CPU. For some reason, `model(X_test)` works flawlessly. Thus, I have updated the [`application_load_weight_test.py`](https://github.com/keras-team/keras/pull/15702/files#diff-89b6c8b391af2f95b405f44e3230796aaabf500cad8d49830d2a0fefba86c554R128) file accordingly.  If needed I'll open an issue for the same.\r\n2.  All models are with 2% of the accuracies mentioned in the paper. Larger models are within 1%. \r\n\r\n/cc @sayakpaul"
            },
            {
                "commenter": "AdityaKane2001",
                "body": "@fchollet @mattdangerw \r\n\r\nCould you please take a look at this one? "
            },
            {
                "commenter": "mattdangerw",
                "body": "@AdityaKane2001 thanks! Do you have the weights hosted online available to download somewhere? We will need that in order to test the model (and eventually upload the weights)."
            },
            {
                "commenter": "AdityaKane2001",
                "body": "@mattdangerw \r\n\r\nYes, I have them in a GCS bucket: `gs://ak-regnet-savedmodels/`\r\n\r\nHere's the public URL: `https://storage.googleapis.com/ak-regnet-savedmodels/`\r\n\r\nThe `.h5` file paths are as expected, [`~/regnetx008.h5`](https://storage.googleapis.com/ak-regnet-savedmodels/regnetx008.h5) and [`~/regnetx008_notop.h5`](https://storage.googleapis.com/ak-regnet-savedmodels/regnetx008_notop.h5) for example.\r\n"
            },
            {
                "commenter": "AdityaKane2001",
                "body": "@mattdangerw  @fchollet \r\n\r\nI have made the requested changes. Please run the workflow again.\r\n\r\nI wanted to provide performance metrics for all the models as on [keras.io/applications](https://keras.io/api/applications/). However, I am not able to spin up a VM instance of the given specs[^1] on Google Cloud. \r\n\r\nCould you please tell how to go about this?\r\n\r\n/cc @sayakpaul \r\n[^1]: CPU: AMD EPYC Processor (with IBPB) (92 core) - Ram: 1.7T - GPU: Tesla A100 "
            },
            {
                "commenter": "AdityaKane2001",
                "body": "@fchollet @mattdangerw\r\n\r\nCould you please take a look at this one? TIA"
            },
            {
                "commenter": "AdityaKane2001",
                "body": "Thanks for the approval!"
            },
            {
                "commenter": "sayakpaul",
                "body": "@mattdangerw could you also provide an update on what do we do about this? \r\n\r\n> I wanted to provide performance metrics for all the models as on keras.io/applications. However, I am not able to spin up a VM instance of the given specs1 on Google Cloud."
            },
            {
                "commenter": "mattdangerw",
                "body": "Yeah, re ideal machine for metrics, particularly the performance per step numbers, I am not sure. This is probably a question for @fchollet. We might take a bit to get back to you on this given it's the holidays and a lot of the team is out.\r\n\r\nIn the mean time, I think we can move ahead trying to land this PR, as the table update will be a separate change to keras.io anyway."
            },
            {
                "commenter": "AdityaKane2001",
                "body": "@mattdangerw \r\n\r\nThanks a ton for keras-team/keras#15868!\r\n\r\nI have tested the code on my end and rolled back https://github.com/keras-team/keras/pull/15702/commits/851ca160f7c38e9effd9e60bcd44b6611073ae60 in https://github.com/keras-team/keras/pull/15702/commits/cf25748f546ef062d49e280cfe757c8d74f23f3e. "
            },
            {
                "commenter": "AdityaKane2001",
                "body": "Today these models were pushed to the [official docs](https://www.tensorflow.org/api_docs/python/tf/keras/applications/regnet). I sincerely thank the Keras team for allowing me to add these models. Huge thanks to the [TPU Research Group (TRC)](https://sites.research.google/trc/about/) for providing TPUs for the entire duration of this project, without which this would not have been possible. Thanks a lot to @fchollet for allowing this and guiding me throughout the process. Thanks to @qlzh727 for his guidance in building Keras from source on TPU VMs. Thanks to @mattdangerw for his support regarding grouped convolutions. Special thanks to @lgeiger for his contributions to the code. Last but not least, thanks a ton to @sayakpaul for his continuous guidance and encouragement."
            },
            {
                "commenter": "mattdangerw",
                "body": "Congrats on getting it landed and thanks for all the hard work on this! This is great to have!"
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 8662,
        "body": "# Modified Files\r\n\r\n- `keras\\utils\\data_utils.py`\r\n- `tests\\test_multiprocessing.py`\r\n\r\n# Issues with GeneratorEnqueuer Multithreading on Windows (and Linux...)\r\n\r\nOpen bugs:\r\n\r\nhttps://github.com/fchollet/keras/issues/6582\r\nhttps://github.com/fchollet/keras/issues/5071\r\n\r\nStale but legit bugs:\r\n\r\nhttps://github.com/fchollet/keras/issues/3962\r\nhttps://github.com/fchollet/keras/issues/5510\r\n\r\nAny attempt to use multithreading or multiprocessing on Windows will result in a `AttributeError: Can't pickle local object 'GeneratorEnqueuer.start.<locals>.data_generator_task'` error in the `multiprocessing` package, as shwon below:\r\n\r\n```\r\n(dlwin36tf140kerasmaster) Phil@SERVERP e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\Lib\\site-packages\\keras\\tests\r\n$ py.test test_multiprocessing.py\r\n============================= test session starts =============================\r\nplatform win32 -- Python 3.6.2, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 -- e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\python.exe\r\ncachedir: ..\\.cache\r\nrootdir: e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\Lib\\site-packages\\keras, inifile: pytest.ini\r\ncollected 7 items\r\n\r\ntest_multiprocessing.py::test_multiprocessing_training FAILED\r\ntest_multiprocessing.py::test_multiprocessing_training_fromfile FAILED\r\ntest_multiprocessing.py::test_multiprocessing_training_fromfile ERROR\r\ntest_multiprocessing.py::test_multiprocessing_predicting FAILED\r\ntest_multiprocessing.py::test_multiprocessing_evaluating FAILED\r\ntest_multiprocessing.py::test_multiprocessing_fit_error FAILED\r\ntest_multiprocessing.py::test_multiprocessing_evaluate_error FAILED\r\ntest_multiprocessing.py::test_multiprocessing_predict_error FAILED\r\n\r\n[...]\r\n\r\n================================== FAILURES ===================================\r\n________________________ test_multiprocessing_training ________________________\r\n\r\n    @keras_test\r\n    def test_multiprocessing_training():\r\n        arr_data = np.random.randint(0, 256, (50, 2))\r\n        arr_labels = np.random.randint(0, 2, 50)\r\n        arr_weights = np.random.random(50)\r\n\r\n        def custom_generator(use_weights=False):\r\n            batch_size = 10\r\n            n_samples = 50\r\n\r\n            while True:\r\n                batch_index = np.random.randint(0, n_samples - batch_size)\r\n                start = batch_index\r\n                end = start + batch_size\r\n                X = arr_data[start: end]\r\n                y = arr_labels[start: end]\r\n                if use_weights:\r\n                    w = arr_weights[start: end]\r\n                    yield X, y, w\r\n                else:\r\n                    yield X, y\r\n\r\n        # Build a NN\r\n        model = Sequential()\r\n        model.add(Dense(1, input_shape=(2, )))\r\n        model.compile(loss='mse', optimizer='adadelta')\r\n\r\n        model.fit_generator(custom_generator(),\r\n                            steps_per_epoch=5,\r\n                            epochs=1,\r\n                            verbose=1,\r\n                            max_queue_size=10,\r\n                            workers=4,\r\n>                           use_multiprocessing=True)\r\n\r\ntest_multiprocessing.py:54:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\ne:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\legacy\\interfaces.py:87: in wrapper\r\n    return func(*args, **kwargs)\r\ne:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\models.py:1227: in fit_generator\r\n    initial_epoch=initial_epoch)\r\ne:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\legacy\\interfaces.py:87: in wrapper\r\n    return func(*args, **kwargs)\r\ne:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\engine\\training.py:2104: in fit_generator\r\n    enqueuer.start(workers=workers, max_queue_size=max_queue_size)\r\ne:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\utils\\data_utils.py:674: in start\r\n    thread.start()\r\n..\\..\\..\\multiprocessing\\process.py:105: in start\r\n    self._popen = self._Popen(self)\r\n..\\..\\..\\multiprocessing\\context.py:223: in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n..\\..\\..\\multiprocessing\\context.py:322: in _Popen\r\n    return Popen(process_obj)\r\n..\\..\\..\\multiprocessing\\popen_spawn_win32.py:65: in __init__\r\n    reduction.dump(process_obj, to_child)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nobj = <Process(Process-2, initial daemon)>, file = <_io.BufferedWriter name=11>\r\nprotocol = None\r\n\r\n    def dump(obj, file, protocol=None):\r\n        '''Replacement for pickle.dump() using ForkingPickler.'''\r\n>       ForkingPickler(file, protocol).dump(obj)\r\nE       AttributeError: Can't pickle local object 'GeneratorEnqueuer.start.<locals>.data_generator_task'\r\n\r\n..\\..\\..\\multiprocessing\\reduction.py:60: AttributeError\r\n\r\n[...]\r\n```\r\n\r\nConverting the `data_generator_task()` local function to a `GeneratorEnqueuer` class method fixes the issue. Fixing the error above, however, doesn't fix a more general problem with `multiprocessing` on Windows. Indeed, on Windows, `multiprocessing` **cannot marshall objects that contain generators** across process boundaries. Attempting to do so will systematically generate a `TypeError: can't pickle generator objects` error, as shown here:\r\n\r\n```\r\n[...]\r\n\r\nTraceback (most recent call last):\r\n  File \"E:\\repos\\toolkits\\keras_mpc_bug\\tests\\test_multiprocessing.py\", line 77, in <module>\r\n    test_multiprocessing_training()\r\n  File \"E:\\repos\\toolkits\\keras_mpc_bug\\tests\\test_multiprocessing.py\", line 41, in test_multiprocessing_training\r\n    use_multiprocessing=True)\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\legacy\\interfaces.py\", line 87, in wrapper\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\models.py\", line 1227, in fit_generator\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\legacy\\interfaces.py\", line 87, in wrapper\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\engine\\training.py\", line 2104, in fit_generator\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\utils\\data_utils.py\", line 663, in start\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\multiprocessing\\process.py\", line 105, in start\r\n    self._popen = self._Popen(self)\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\multiprocessing\\context.py\", line 223, in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\multiprocessing\\context.py\", line 322, in _Popen\r\n    return Popen(process_obj)\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\multiprocessing\\popen_spawn_win32.py\", line 65, in __init__\r\n    reduction.dump(process_obj, to_child)\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\multiprocessing\\reduction.py\", line 60, in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\nTypeError: can't pickle generator objects\r\n\r\n[...]\r\n```\r\n\r\nOur two-pronged `data_utils.py` fix for these issues is the following:\r\n- On all platforms, convert the `data_generator_task()` local function to a `GeneratorEnqueuer` class method.\r\n- On Windows, raise a `ValueError` exception instead if `use_multiprocessing` is set to True and suggest alternative in error message, such as using multithreading, BUT --\r\n\r\n-- BUT the current code in `data_utils.py` does not work properly in multithreading mode. Since calls to the generator's `next()` function are not serialized, execution sytematically results in a `ValueError: generator already executing` (both on Windows and Linux!). See notes below on `test_multiprocessing.py` to see why this seldom shows up on Linux.\r\n\r\nOur `data_utils.py` fix for this additional issue is the following:\r\n- On all platforms, serialize calls to `generator_output = next(generator)` using a threading lock.\r\n- Initialize the internal queue max size to `max_queue_size`. Right now, it is not properly initialized and grows indefinitely on all platforms!\r\n\r\nYes, we are aware of Python's **limited multithreaded abailities when it comes to the global interpreter lock (gil)**, as discussed [here](https://wiki.python.org/moin/GlobalInterpreterLock). We are also of the opinion that degraded performance is a better alternative to catastrophic failure in execution (as is the case right now). Without a fix, `GeneratorEnqueuer` is unusable on Windows.\r\n\r\nIf the PR for `data_utils.py` is rejected, please consider using our modified version of `test_multiprocessing.py`. The current version is woefully inadequate at catching multithreading and multiprocessing bugs or stressing the `GeneratorEnqueuer` queueing mechanism. Using our updated version, you will see that the same multithreading issues pop up immediately on Linux as well.\r\n\r\nOur fix for `test_multiprocessing.py` to bring out threading issues and stressing the queue are the following:\r\n- Use at least the same number of tests for each of the seven test scenarios:\r\n  - 4 workers + one main thread (`use_multiprocessing` set to True, then False)\r\n  - 1 worker + one main thread (`use_multiprocessing` set to True, then False)\r\n  - No worker + one main thread (`use_multiprocessing` set to True, then False)\r\n- Bump up the number of steps per epoch from 5 to 100:\r\n  - Currently, the number of steps is 5. Since the maximum size of the queue is 10, this is clearly inadequate to really stress the queue in both multiprocessing and multithreading scenarios.\r\n\r\n# Code to Repro Multiprocessing Bugs and Test Fix\r\n\r\nSimply run `test_multiprocessing.py`. Below, we show execution of this code (with and without the fix) in four different configurations:\r\n\r\n- Python 3.6 on Windows 10 with Tensorflow 1.4\r\n- Python 2.7 on Windows 10 with CNTK 2.3\r\n- Python 3.6 on Ubuntu 16.04 with Tensorflow 1.4\r\n- Python 2.7 on Ubuntu 16.04 with CNTK 2.3\r\n\r\n## `dlwin36tf140kerasmaster` (Python 3.6 on Windows 10 with Tensorflow 1.4) \r\n\r\n*Execution without the fix*\r\n\r\n```\r\n(dlwin36tf140kerasmaster) Phil@SERVERP e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\Lib\\site-packages\\keras\\tests\r\n$ py.test test_multiprocessing.py\r\n============================= test session starts =============================\r\nplatform win32 -- Python 3.6.2, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 -- e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\python.exe\r\ncachedir: ..\\.cache\r\nrootdir: e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\Lib\\site-packages\\keras, inifile: pytest.ini\r\ncollected 7 items\r\n\r\ntest_multiprocessing.py::test_multiprocessing_training FAILED\r\ntest_multiprocessing.py::test_multiprocessing_training_fromfile FAILED\r\ntest_multiprocessing.py::test_multiprocessing_training_fromfile ERROR\r\ntest_multiprocessing.py::test_multiprocessing_predicting FAILED\r\ntest_multiprocessing.py::test_multiprocessing_evaluating FAILED\r\ntest_multiprocessing.py::test_multiprocessing_fit_error FAILED\r\ntest_multiprocessing.py::test_multiprocessing_evaluate_error FAILED\r\ntest_multiprocessing.py::test_multiprocessing_predict_error FAILED\r\n\r\n========================== slowest 10 test durations ==========================\r\n0.51s call     tests/test_multiprocessing.py::test_multiprocessing_training\r\n0.48s call     tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.47s call     tests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n0.25s call     tests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n0.25s call     tests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n0.24s call     tests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n0.24s call     tests/test_multiprocessing.py::test_multiprocessing_predicting\r\n0.01s setup    tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_training\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n=================================== ERRORS ====================================\r\n_________ ERROR at teardown of test_multiprocessing_training_fromfile _________\r\n\r\ntmpdir = local('C:\\\\Users\\\\Phil\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Phil\\\\pytest-109\\\\test_multiprocessing_training_0')\r\n\r\n    @pytest.fixture\r\n    def in_tmpdir(tmpdir):\r\n        \"\"\"Runs a function in a temporary directory.\r\n\r\n        Checks that the directory is empty afterwards.\r\n        \"\"\"\r\n        with tmpdir.as_cwd():\r\n            yield None\r\n>       assert not tmpdir.listdir()\r\nE       AssertionError: assert not [local('C:\\\\Users\\\\Phil\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Phil\\\\pytest-109\\\\test_multiprocessing_training_0\\\\data.npz')]\r\nE        +  where [local('C:\\\\Users\\\\Phil\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Phil\\\\pytest-109\\\\test_multiprocessing_training_0\\\\data.npz')] = <bound method LocalPath.listdir of local('C:\\\\Users\\\\Phil\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Phil\\\\pytest-109\\\\test_multiprocessing_training_0')>()\r\nE        +    where <bound method LocalPath.listdir of local('C:\\\\Users\\\\Phil\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Phil\\\\pytest-109\\\\test_multiprocessing_training_0')> = local('C:\\\\Users\\\\Phil\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-Phil\\\\pytest-109\\\\test_multiprocessing_training_0').listdir\r\n\r\ntest_multiprocessing.py:18: AssertionError\r\n-------------------------- Captured stderr teardown ---------------------------\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\multiprocessing\\spawn.py\", line 105, in spawn_main\r\n    exitcode = _main(fd)\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\multiprocessing\\spawn.py\", line 115, in _main\r\n    self = reduction.pickle.load(from_parent)\r\nEOFError: Ran out of input\r\n================================== FAILURES ===================================\r\n________________________ test_multiprocessing_training ________________________\r\n\r\n    @keras_test\r\n    def test_multiprocessing_training():\r\n        arr_data = np.random.randint(0, 256, (50, 2))\r\n        arr_labels = np.random.randint(0, 2, 50)\r\n        arr_weights = np.random.random(50)\r\n\r\n        def custom_generator(use_weights=False):\r\n            batch_size = 10\r\n            n_samples = 50\r\n\r\n            while True:\r\n                batch_index = np.random.randint(0, n_samples - batch_size)\r\n                start = batch_index\r\n                end = start + batch_size\r\n                X = arr_data[start: end]\r\n                y = arr_labels[start: end]\r\n                if use_weights:\r\n                    w = arr_weights[start: end]\r\n                    yield X, y, w\r\n                else:\r\n                    yield X, y\r\n\r\n        # Build a NN\r\n        model = Sequential()\r\n        model.add(Dense(1, input_shape=(2, )))\r\n        model.compile(loss='mse', optimizer='adadelta')\r\n\r\n        model.fit_generator(custom_generator(),\r\n                            steps_per_epoch=5,\r\n                            epochs=1,\r\n                            verbose=1,\r\n                            max_queue_size=10,\r\n                            workers=4,\r\n>                           use_multiprocessing=True)\r\n\r\ntest_multiprocessing.py:54:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\ne:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\legacy\\interfaces.py:87: in wrapper\r\n    return func(*args, **kwargs)\r\ne:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\models.py:1227: in fit_generator\r\n    initial_epoch=initial_epoch)\r\ne:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\legacy\\interfaces.py:87: in wrapper\r\n    return func(*args, **kwargs)\r\ne:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\engine\\training.py:2104: in fit_generator\r\n    enqueuer.start(workers=workers, max_queue_size=max_queue_size)\r\ne:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\utils\\data_utils.py:674: in start\r\n    thread.start()\r\n..\\..\\..\\multiprocessing\\process.py:105: in start\r\n    self._popen = self._Popen(self)\r\n..\\..\\..\\multiprocessing\\context.py:223: in _Popen\r\n    return _default_context.get_context().Process._Popen(process_obj)\r\n..\\..\\..\\multiprocessing\\context.py:322: in _Popen\r\n    return Popen(process_obj)\r\n..\\..\\..\\multiprocessing\\popen_spawn_win32.py:65: in __init__\r\n    reduction.dump(process_obj, to_child)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nobj = <Process(Process-2, initial daemon)>, file = <_io.BufferedWriter name=11>\r\nprotocol = None\r\n\r\n    def dump(obj, file, protocol=None):\r\n        '''Replacement for pickle.dump() using ForkingPickler.'''\r\n>       ForkingPickler(file, protocol).dump(obj)\r\nE       AttributeError: Can't pickle local object 'GeneratorEnqueuer.start.<locals>.data_generator_task'\r\n\r\n..\\..\\..\\multiprocessing\\reduction.py:60: AttributeError\r\n...\r\n```\r\n\r\n*Execution with the fix*\r\n\r\n```\r\n(dlwin36tf140kerasmaster) Phil@SERVERP e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\Lib\\site-packages\\keras\\tests\r\n$ py.test test_multiprocessing.py\r\n============================= test session starts =============================\r\nplatform win32 -- Python 3.6.2, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 -- e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\python.exe\r\ncachedir: ..\\.cache\r\nrootdir: e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\Lib\\site-packages\\keras, inifile: pytest.ini\r\ncollected 7 items\r\n\r\ntest_multiprocessing.py::test_multiprocessing_training PASSED\r\ntest_multiprocessing.py::test_multiprocessing_training_from_file PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predicting PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluating PASSED\r\ntest_multiprocessing.py::test_multiprocessing_fit_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluate_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predict_error PASSED\r\n\r\n========================== slowest 10 test durations ==========================\r\n4.19s call     tests/test_multiprocessing.py::test_multiprocessing_training\r\n2.04s call     tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n0.61s call     tests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n0.57s call     tests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n0.54s call     tests/test_multiprocessing.py::test_multiprocessing_predicting\r\n0.12s call     tests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n0.11s call     tests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n0.02s setup    tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n============================== warnings summary ===============================\r\ntests/test_multiprocessing.py::test_multiprocessing_training\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\engine\\training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\engine\\training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_predicting\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\engine\\training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\engine\\training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\engine\\training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\engine\\training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin36tf140kerasmaster\\lib\\site-packages\\keras-2.1.2-py3.6.egg\\keras\\engine\\training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\n-- Docs: http://doc.pytest.org/en/latest/warnings.html\r\n==================== 7 passed, 7 warnings in 11.44 seconds ====================\r\n2017-12-02 08:50:53.632443: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2017-12-02 08:50:54.016767: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1030] Found device 0 with properties:\r\nname: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\r\npciBusID: 0000:03:00.0\r\ntotalMemory: 12.00GiB freeMemory: 10.06GiB\r\n2017-12-02 08:50:54.016804: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2017-12-02 08:50:57.848682: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2017-12-02 08:50:59.634973: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2017-12-02 08:51:00.172749: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2017-12-02 08:51:01.090078: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2017-12-02 08:51:01.358376: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n2017-12-02 08:51:01.480222: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows-gpu\\PY\\36\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)\r\n```\r\n\r\n*Steps to recreate test environment*\r\n\r\n```\r\n$ conda create --yes -n dlwin36 numpy scipy mkl-service matplotlib pandas pillow scikit-learn jupyter pytest\r\n$ conda create --name dlwin36tf140kerasmaster --clone dlwin36\r\n$ activate dlwin36tf140kerasmaster \r\n$ pip install tensorflow-gpu==1.4.0 \r\n$ cd \"%CONDA_PREFIX%\\Lib\\site-packages\"\r\n$ git clone git://github.com/fchollet/keras.git\r\n$ cd keras\r\n$ python setup.py install\r\n```\r\n\r\n## `dlwin27cntk23kerasmaster` (Python 2.7 on Windows 10 with CNTK 2.3)\r\n\r\n*Execution without the fix*\r\n\r\n```\r\n(dlwin27cntk23kerasmaster) Phil@SERVERP e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\Lib\\site-packages\\keras\\tests\r\n$ py.test test_multiprocessing.py\r\n============================= test session starts =============================\r\nplatform win32 -- Python 2.7.13, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 -- e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\python.exe\r\ncachedir: ..\\.cache\r\nrootdir: e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\Lib\\site-packages\\keras, inifile: pytest.ini\r\ncollected 7 items\r\n\r\ntest_multiprocessing.py::test_multiprocessing_training FAILED\r\ntest_multiprocessing.py::test_multiprocessing_training_fromfile FAILED\r\ntest_multiprocessing.py::test_multiprocessing_training_fromfile ERROR\r\ntest_multiprocessing.py::test_multiprocessing_predicting FAILED\r\ntest_multiprocessing.py::test_multiprocessing_evaluating FAILED\r\ntest_multiprocessing.py::test_multiprocessing_fit_error FAILED\r\ntest_multiprocessing.py::test_multiprocessing_evaluate_error FAILED\r\ntest_multiprocessing.py::test_multiprocessing_predict_error FAILED\r\n\r\n========================== slowest 10 test durations ==========================\r\n0.63s call     tests/test_multiprocessing.py::test_multiprocessing_training\r\n0.18s call     tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.15s call     tests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n0.14s call     tests/test_multiprocessing.py::test_multiprocessing_predicting\r\n0.14s call     tests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n0.14s call     tests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n0.14s call     tests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n0.01s setup    tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_predicting\r\n=================================== ERRORS ====================================\r\n_________ ERROR at teardown of test_multiprocessing_training_fromfile _________\r\n\r\ntmpdir = local('c:\\\\users\\\\phil\\\\appdata\\\\local\\\\temp\\\\pytest-of-Phil\\\\pytest-103\\\\test_multiprocessing_training_0')\r\n\r\n    @pytest.fixture\r\n    def in_tmpdir(tmpdir):\r\n        \"\"\"Runs a function in a temporary directory.\r\n\r\n        Checks that the directory is empty afterwards.\r\n        \"\"\"\r\n        with tmpdir.as_cwd():\r\n            yield None\r\n>       assert not tmpdir.listdir()\r\nE       AssertionError: assert not [local('c:\\\\users\\\\phil\\\\appdata\\\\local\\\\temp\\\\pytest-of-Phil\\\\pytest-103\\\\test_multiprocessing_training_0\\\\data.npz')]\r\nE        +  where [local('c:\\\\users\\\\phil\\\\appdata\\\\local\\\\temp\\\\pytest-of-Phil\\\\pytest-103\\\\test_multiprocessing_training_0\\\\data.npz')] = <bound method LocalPath.listdir of local('c:\\\\users\\\\phil\\\\appdata\\\\local\\\\temp\\\\pytest-of-Phil\\\\pytest-103\\\\test_multiprocessing_training_0')>()\r\nE        +    where <bound method LocalPath.listdir of local('c:\\\\users\\\\phil\\\\appdata\\\\local\\\\temp\\\\pytest-of-Phil\\\\pytest-103\\\\test_multiprocessing_training_0')> = local('c:\\\\users\\\\phil\\\\appdata\\\\local\\\\temp\\\\pytest-of-Phil\\\\pytest-103\\\\test_multiprocessing_training_0').listdir\r\n\r\ntest_multiprocessing.py:18: AssertionError\r\n-------------------------- Captured stderr teardown ---------------------------\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\lib\\multiprocessing\\forking.py\", line 381, in main\r\n    self = load(from_parent)\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\lib\\pickle.py\", line 1384, in load\r\n    return Unpickler(file).load()\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\lib\\pickle.py\", line 864, in load\r\n    dispatch[key](self)\r\n  File \"e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\lib\\pickle.py\", line 886, in load_eof\r\n    raise EOFError\r\nEOFError\r\n================================== FAILURES ===================================\r\n________________________ test_multiprocessing_training ________________________\r\n\r\n    @keras_test\r\n    def test_multiprocessing_training():\r\n        arr_data = np.random.randint(0, 256, (50, 2))\r\n        arr_labels = np.random.randint(0, 2, 50)\r\n        arr_weights = np.random.random(50)\r\n\r\n        def custom_generator(use_weights=False):\r\n            batch_size = 10\r\n            n_samples = 50\r\n\r\n            while True:\r\n                batch_index = np.random.randint(0, n_samples - batch_size)\r\n                start = batch_index\r\n                end = start + batch_size\r\n                X = arr_data[start: end]\r\n                y = arr_labels[start: end]\r\n                if use_weights:\r\n                    w = arr_weights[start: end]\r\n                    yield X, y, w\r\n                else:\r\n                    yield X, y\r\n\r\n        # Build a NN\r\n        model = Sequential()\r\n        model.add(Dense(1, input_shape=(2, )))\r\n        model.compile(loss='mse', optimizer='adadelta')\r\n\r\n        model.fit_generator(custom_generator(),\r\n                            steps_per_epoch=5,\r\n                            epochs=1,\r\n                            verbose=1,\r\n                            max_queue_size=10,\r\n                            workers=4,\r\n>                           use_multiprocessing=True)\r\n\r\ntest_multiprocessing.py:54:\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\nbuild\\bdist.win-amd64\\egg\\keras\\legacy\\interfaces.py:87: in wrapper\r\n    ???\r\nbuild\\bdist.win-amd64\\egg\\keras\\models.py:1227: in fit_generator\r\n    ???\r\nbuild\\bdist.win-amd64\\egg\\keras\\legacy\\interfaces.py:87: in wrapper\r\n    ???\r\nbuild\\bdist.win-amd64\\egg\\keras\\engine\\training.py:2104: in fit_generator\r\n    ???\r\nbuild\\bdist.win-amd64\\egg\\keras\\utils\\data_utils.py:674: in start\r\n    ???\r\n..\\..\\..\\multiprocessing\\process.py:130: in start\r\n    self._popen = Popen(self)\r\n..\\..\\..\\multiprocessing\\forking.py:277: in __init__\r\n    dump(process_obj, to_child, HIGHEST_PROTOCOL)\r\n..\\..\\..\\multiprocessing\\forking.py:199: in dump\r\n    ForkingPickler(file, protocol).dump(obj)\r\n..\\..\\..\\pickle.py:224: in dump\r\n    self.save(obj)\r\n..\\..\\..\\pickle.py:331: in save\r\n    self.save_reduce(obj=obj, *rv)\r\n..\\..\\..\\pickle.py:425: in save_reduce\r\n    save(state)\r\n..\\..\\..\\pickle.py:286: in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n..\\..\\..\\pickle.py:655: in save_dict\r\n    self._batch_setitems(obj.iteritems())\r\n..\\..\\..\\pickle.py:687: in _batch_setitems\r\n    save(v)\r\n..\\..\\..\\pickle.py:286: in save\r\n    f(self, obj) # Call unbound method with explicit self\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nself = <multiprocessing.forking.ForkingPickler instance at 0x0000000008817608>\r\nobj = <function data_generator_task at 0x00000000087FE978>\r\nname = 'data_generator_task', pack = <built-in function pack>\r\n\r\n    def save_global(self, obj, name=None, pack=struct.pack):\r\n        write = self.write\r\n        memo = self.memo\r\n\r\n        if name is None:\r\n            name = obj.__name__\r\n\r\n        module = getattr(obj, \"__module__\", None)\r\n        if module is None:\r\n            module = whichmodule(obj, name)\r\n\r\n        try:\r\n            __import__(module)\r\n            mod = sys.modules[module]\r\n            klass = getattr(mod, name)\r\n        except (ImportError, KeyError, AttributeError):\r\n            raise PicklingError(\r\n                \"Can't pickle %r: it's not found as %s.%s\" %\r\n>               (obj, module, name))\r\nE           PicklingError: Can't pickle <function data_generator_task at 0x00000000087FE978>: it's not found as keras.utils.data_utils.data_generator_task\r\n\r\n..\\..\\..\\pickle.py:754: PicklingError\r\n...\r\n```\r\n\r\n*Execution with the fix*\r\n\r\n```\r\n(dlwin27cntk23kerasmaster) Phil@SERVERP e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\Lib\\site-packages\\keras\\tests\r\n$ py.test test_multiprocessing.py\r\n============================= test session starts =============================\r\nplatform win32 -- Python 2.7.13, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 -- e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\python.exe\r\ncachedir: ..\\.cache\r\nrootdir: e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\Lib\\site-packages\\keras, inifile: pytest.ini\r\ncollected 7 items\r\n\r\ntest_multiprocessing.py::test_multiprocessing_training PASSED\r\ntest_multiprocessing.py::test_multiprocessing_training_from_file PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predicting PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluating PASSED\r\ntest_multiprocessing.py::test_multiprocessing_fit_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluate_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predict_error PASSED\r\n\r\n========================== slowest 10 test durations ==========================\r\n2.40s call     tests/test_multiprocessing.py::test_multiprocessing_training\r\n1.54s call     tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n0.80s call     tests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n0.51s call     tests/test_multiprocessing.py::test_multiprocessing_predicting\r\n0.06s call     tests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n0.03s call     tests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n0.03s call     tests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n0.01s setup    tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n0.00s setup    tests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n============================== warnings summary ===============================\r\ntests/test_multiprocessing.py::test_multiprocessing_training\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\lib\\site-packages\\keras-2.1.2-py2.7.egg\\keras\\engine\\training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\lib\\site-packages\\cntk\\core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input23\") expects \"<type 'numpy.float32'>\". Please convert your data beforehand to speed up training.\r\n    (sample.dtype, var.uid, str(var.dtype)))\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\lib\\site-packages\\_pytest\\warnings.py:88: UnicodeWarning: Warning is using unicode non convertible to ascii, converting to a safe representation:\r\n    e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\lib\\site-packages\\cntk\\core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input23\") expects \"<type 'numpy.float32'>\". Please convert your data beforehand to speed up training.\r\n    (sample.dtype, var.uid, str(var.dtype)))\r\n\r\n    UnicodeWarning)\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_predicting\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\lib\\site-packages\\keras-2.1.2-py2.7.egg\\keras\\engine\\training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n  e:\\toolkits.win\\anaconda3-4.4.0\\envs\\dlwin27cntk23kerasmaster\\lib\\site-packages\\keras-2.1.2-py2.7.egg\\keras\\engine\\training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\n-- Docs: http://doc.pytest.org/en/latest/warnings.html\r\n==================== 7 passed, 5 warnings in 6.69 seconds =====================\r\n```\r\n\r\n*Steps to recreate test environment*\r\n\r\n```\r\n$ conda create --yes -n dlwin27 python=2.7\r\n$ activate dlwin27\r\n$ conda install --yes numpy scipy mkl-service matplotlib pandas pillow scikit-learn jupyter pytest\r\n$ deactivate\r\n$ conda create --name dlwin27cntk23kerasmaster --clone dlwin27\r\n$ activate dlwin27cntk23kerasmaster \r\n$ pip install https://cntk.ai/PythonWheel/GPU/cntk-2.3-cp27-cp27m-win_amd64.whl\r\n$ cd \"%CONDA_PREFIX%\\Lib\\site-packages\"\r\n$ git clone git://github.com/fchollet/keras.git\r\n$ cd keras\r\n$ python setup.py install\r\n$ set KERAS_BACKEND=cntk\r\n```\r\n\r\n\r\n## `dlubu36tf140kerasmaster` (Python 3.6 on Ubuntu 16.04 with Tensorflow 1.4)\r\n\r\n*Execution without the fix*\r\n\r\n```\r\n(dlubu36tf140kerasmaster) phil@DESKTOPP:/media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/keras/tests$ py.test test_multiprocessing.py\r\n======================================================= test session starts ========================================================\r\nplatform linux -- Python 3.6.2, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 -- /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/bin/python\r\ncachedir: ../.cache\r\nrootdir: /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/keras, inifile: pytest.ini\r\ncollected 7 items                                                                                                                   \r\n\r\ntest_multiprocessing.py::test_multiprocessing_training PASSED\r\ntest_multiprocessing.py::test_multiprocessing_training_fromfile PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predicting PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluating PASSED\r\ntest_multiprocessing.py::test_multiprocessing_fit_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluate_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predict_error PASSED\r\n\r\n==================================================== slowest 10 test durations =====================================================\r\n1.58s call     tests/test_multiprocessing.py::test_multiprocessing_training\r\n0.60s call     tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.37s call     tests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n0.25s call     tests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n0.24s call     tests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n0.20s call     tests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n0.18s call     tests/test_multiprocessing.py::test_multiprocessing_predicting\r\n0.01s setup    tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n========================================================= warnings summary =========================================================\r\ntests/test_multiprocessing.py::test_multiprocessing_training\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_predicting\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\n-- Docs: http://doc.pytest.org/en/latest/warnings.html\r\n=============================================== 7 passed, 7 warnings in 8.70 seconds ===============================================\r\n```\r\n\r\n*Execution with the fix*\r\n\r\n```\r\n(dlubu36tf140kerasmaster) phil@DESKTOPP:/media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/keras/tests$ py.test /media/EDrive/repos/toolkits/keras_mpc_bug/tests/test_multiprocessing.py\r\n======================================================= test session starts ========================================================\r\nplatform linux -- Python 3.6.2, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 -- /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/bin/python\r\ncachedir: ../.cache\r\nrootdir: /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/keras, inifile: pytest.ini\r\ncollected 7 items                                                                                                                   \r\n\r\ntest_multiprocessing.py::test_multiprocessing_training PASSED\r\ntest_multiprocessing.py::test_multiprocessing_training_from_file PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predicting PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluating PASSED\r\ntest_multiprocessing.py::test_multiprocessing_fit_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluate_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predict_error PASSED\r\n\r\n==================================================== slowest 10 test durations =====================================================\r\n5.51s call     tests/test_multiprocessing.py::test_multiprocessing_training\r\n3.75s call     tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n1.46s call     tests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n1.15s call     tests/test_multiprocessing.py::test_multiprocessing_predicting\r\n0.57s call     tests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n0.28s call     tests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n0.26s call     tests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n0.01s setup    tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n0.00s setup    tests/test_multiprocessing.py::test_multiprocessing_training\r\n========================================================= warnings summary =========================================================\r\ntests/test_multiprocessing.py::test_multiprocessing_training\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_predicting\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\n-- Docs: http://doc.pytest.org/en/latest/warnings.html\r\n============================================== 7 passed, 7 warnings in 18.28 seconds ===============================================\r\n```\r\n\r\n## `dlubu27cntk23kerasmaster` (Python 2.7 on Ubuntu 16.04 with CNTK 2.3)\r\n\r\n*Execution without the fix*\r\n\r\n```\r\n(dlubu27cntk23kerasmaster) phil@DESKTOPP:/media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/keras/tests$ py.test test_multiprocessing.py\r\n======================================================= test session starts ========================================================\r\nplatform linux2 -- Python 2.7.13, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 -- /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/bin/python\r\ncachedir: ../.cache\r\nrootdir: /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/keras, inifile: pytest.ini\r\ncollected 7 items                                                                                                                   \r\n\r\ntest_multiprocessing.py::test_multiprocessing_training PASSED\r\ntest_multiprocessing.py::test_multiprocessing_training_fromfile PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predicting PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluating PASSED\r\ntest_multiprocessing.py::test_multiprocessing_fit_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluate_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predict_error PASSED\r\n\r\n==================================================== slowest 10 test durations =====================================================\r\n0.97s call     tests/test_multiprocessing.py::test_multiprocessing_training\r\n0.19s call     tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.17s call     tests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n0.14s call     tests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n0.12s call     tests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n0.12s call     tests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n0.10s call     tests/test_multiprocessing.py::test_multiprocessing_predicting\r\n0.00s setup    tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_training_fromfile\r\n0.00s setup    tests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n========================================================= warnings summary =========================================================\r\ntests/test_multiprocessing.py::test_multiprocessing_training\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input23\") expects \"<type 'numpy.float32'>\". Please convert your data beforehand to speed up training.\r\n    (sample.dtype, var.uid, str(var.dtype)))\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/_pytest/warnings.py:88: UnicodeWarning: Warning is using unicode non convertible to ascii, converting to a safe representation:\r\n    /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input23\") expects \"<type 'numpy.float32'>\". Please convert your data beforehand to speed up training.\r\n    (sample.dtype, var.uid, str(var.dtype)))\r\n  \r\n    UnicodeWarning)\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_predicting\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/engine/training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\n-- Docs: http://doc.pytest.org/en/latest/warnings.html\r\n=============================================== 7 passed, 5 warnings in 3.74 seconds ===============================================\r\n```\r\n\r\n*Execution with the fix*\r\n\r\n```\r\n(dlubu27cntk23kerasmaster) phil@DESKTOPP:/media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/keras$ py.test /media/EDrive/repos/toolkits/keras_mpc_bug/tests/test_multiprocessing.py\r\n======================================================= test session starts ========================================================\r\nplatform linux2 -- Python 2.7.13, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 -- /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/bin/python\r\ncachedir: ../.cache\r\nrootdir: /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/keras, inifile: pytest.ini\r\ncollected 7 items                                                                                                                   \r\n\r\ntest_multiprocessing.py::test_multiprocessing_training PASSED\r\ntest_multiprocessing.py::test_multiprocessing_training_from_file PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predicting PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluating PASSED\r\ntest_multiprocessing.py::test_multiprocessing_fit_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_evaluate_error PASSED\r\ntest_multiprocessing.py::test_multiprocessing_predict_error PASSED\r\n\r\n==================================================== slowest 10 test durations =====================================================\r\n4.53s call     tests/test_multiprocessing.py::test_multiprocessing_training\r\n2.85s call     tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n1.61s call     tests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n0.95s call     tests/test_multiprocessing.py::test_multiprocessing_predicting\r\n0.23s call     tests/test_multiprocessing.py::test_multiprocessing_fit_error\r\n0.18s call     tests/test_multiprocessing.py::test_multiprocessing_evaluate_error\r\n0.17s call     tests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n0.00s setup    tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n0.00s teardown tests/test_multiprocessing.py::test_multiprocessing_training_from_file\r\n0.00s setup    tests/test_multiprocessing.py::test_multiprocessing_predict_error\r\n========================================================= warnings summary =========================================================\r\ntests/test_multiprocessing.py::test_multiprocessing_training\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input23\") expects \"<type 'numpy.float32'>\". Please convert your data beforehand to speed up training.\r\n    (sample.dtype, var.uid, str(var.dtype)))\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/_pytest/warnings.py:88: UnicodeWarning: Warning is using unicode non convertible to ascii, converting to a safe representation:\r\n    /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input23\") expects \"<type 'numpy.float32'>\". Please convert your data beforehand to speed up training.\r\n    (sample.dtype, var.uid, str(var.dtype)))\r\n  \r\n    UnicodeWarning)\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_predicting\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/engine/training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\ntests/test_multiprocessing.py::test_multiprocessing_evaluating\r\n  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\r\n\r\n-- Docs: http://doc.pytest.org/en/latest/warnings.html\r\n============================================== 7 passed, 5 warnings in 12.50 seconds ===============================================\r\n```\r\n\r\n*Steps to recreate test environment*\r\n\r\n```\r\n$ conda create --yes -n dlubu27 python=2.7\r\n$ source activate dlubu27\r\n$ conda install --yes numpy scipy mkl-service matplotlib pandas pillow scikit-learn jupyter pytest\r\n$ source deactivate\r\n$ conda create --name dlubu27cntk23kerasmaster --clone dlubu27\r\n$ source activate dlubu27cntk23kerasmaster \r\n$ pip install https://cntk.ai/PythonWheel/GPU/cntk-2.3-cp27-cp27mu-linux_x86_64.whl\r\n$ cd $CONDA_PREFIX/lib/python2.7/site-packages\r\n$ git clone git://github.com/fchollet/keras.git\r\n$ cd keras\r\n$ python setup.py install\r\n```\r\n",
        "changed_files": [
            {
                "filename": "keras/utils/data_utils.py",
                "patch": "@@ -612,64 +612,97 @@ def __init__(self, generator,\n                  seed=None):\n         self.wait_time = wait_time\n         self._generator = generator\n-        self._use_multiprocessing = use_multiprocessing\n+        if os.name is 'nt' and use_multiprocessing is True:\n+            # On Windows, avoid **SYSTEMATIC** error in `multiprocessing`:\n+            # `TypeError: can't pickle generator objects`\n+            # => Suggest multithreading instead of multiprocessing on Windows\n+            raise ValueError('Using a generator with `use_multiprocessing=True`'\n+                             ' is not supported on Windows (no marshalling of'\n+                             ' generators across process boundaries). Instead,'\n+                             ' use single thread/process or multithreading.')\n+        else:\n+            self._use_multiprocessing = use_multiprocessing\n         self._threads = []\n         self._stop_event = None\n         self._manager = None\n         self.queue = None\n         self.seed = seed\n \n-    def start(self, workers=1, max_queue_size=10):\n-        \"\"\"Kicks off threads which add data from the generator into the queue.\n-\n-        # Arguments\n-            workers: number of worker threads\n-            max_queue_size: queue size\n-                (when full, threads could block on `put()`)\n-        \"\"\"\n-\n-        def data_generator_task():\n+    def _data_generator_task(self):\n+        if self._use_multiprocessing is False:\n+            while not self._stop_event.is_set():\n+                with self.genlock:\n+                    try:\n+                        if self.queue is not None and self.queue.qsize() < self.max_queue_size:\n+                            # On all OSes, avoid **SYSTEMATIC** error in multithreading mode:\n+                            # `ValueError: generator already executing`\n+                            # => Serialize calls to infinite iterator/generator's next() function\n+                            generator_output = next(self._generator)\n+                            self.queue.put((True, generator_output))\n+                        else:\n+                            time.sleep(self.wait_time)\n+                    except StopIteration:\n+                        break\n+                    except Exception as e:\n+                        # Can't pickle tracebacks.\n+                        # As a compromise, print the traceback and pickle None instead.\n+                        if not hasattr(e, '__traceback__'):\n+                            setattr(e, '__traceback__', sys.exc_info()[2])\n+                        self.queue.put((False, e))\n+                        self._stop_event.set()\n+                        break\n+        else:\n             while not self._stop_event.is_set():\n                 try:\n-                    if self._use_multiprocessing or self.queue.qsize() < max_queue_size:\n+                    if self.queue is not None and self.queue.qsize() < self.max_queue_size:\n                         generator_output = next(self._generator)\n                         self.queue.put((True, generator_output))\n                     else:\n                         time.sleep(self.wait_time)\n                 except StopIteration:\n                     break\n                 except Exception as e:\n-                    # Can't pick tracebacks.\n+                    # Can't pickle tracebacks.\n                     # As a compromise, print the traceback and pickle None instead.\n-                    if self._use_multiprocessing:\n-                        traceback.print_exc()\n-                        setattr(e, '__traceback__', None)\n-                    elif not hasattr(e, '__traceback__'):\n-                        setattr(e, '__traceback__', sys.exc_info()[2])\n+                    traceback.print_exc()\n+                    setattr(e, '__traceback__', None)\n                     self.queue.put((False, e))\n                     self._stop_event.set()\n                     break\n \n+    def start(self, workers=1, max_queue_size=10):\n+        \"\"\"Kicks off threads which add data from the generator into the queue.\n+\n+        # Arguments\n+            workers: number of worker threads\n+            max_queue_size: queue size\n+                (when full, threads could block on `put()`)\n+        \"\"\"\n         try:\n+            self.max_queue_size = max_queue_size\n             if self._use_multiprocessing:\n                 self._manager = multiprocessing.Manager()\n                 self.queue = self._manager.Queue(maxsize=max_queue_size)\n                 self._stop_event = multiprocessing.Event()\n             else:\n-                self.queue = queue.Queue()\n+                # On all OSes, avoid **SYSTEMATIC** error in multithreading mode:\n+                # `ValueError: generator already executing`\n+                # => Serialize calls to infinite iterator/generator's next() function\n+                self.genlock = threading.Lock()\n+                self.queue = queue.Queue(maxsize=max_queue_size)\n                 self._stop_event = threading.Event()\n \n             for _ in range(workers):\n                 if self._use_multiprocessing:\n                     # Reset random seed else all children processes\n                     # share the same seed\n                     np.random.seed(self.seed)\n-                    thread = multiprocessing.Process(target=data_generator_task)\n+                    thread = multiprocessing.Process(target=self._data_generator_task)\n                     thread.daemon = True\n                     if self.seed is not None:\n                         self.seed += 1\n                 else:\n-                    thread = threading.Thread(target=data_generator_task)\n+                    thread = threading.Thread(target=self._data_generator_task)\n                 self._threads.append(thread)\n                 thread.start()\n         except:\n@@ -691,11 +724,15 @@ def stop(self, timeout=None):\n             self._stop_event.set()\n \n         for thread in self._threads:\n-            if thread.is_alive():\n-                if self._use_multiprocessing:\n+            if self._use_multiprocessing:\n+                if thread.is_alive():\n                     thread.terminate()\n-                else:\n-                    thread.join(timeout)\n+            else:\n+                # The thread.is_alive() test is subject to a race condition:\n+                # the thread could terminate right after the test and before the\n+                # join, rendering this test meaningless -> Call thread.join()\n+                # always, which is ok no matter what the status of the thread.\n+                thread.join(timeout)\n \n         if self._manager:\n             self._manager.shutdown()"
            },
            {
                "filename": "tests/test_multiprocessing.py",
                "patch": "@@ -1,11 +1,16 @@\n from __future__ import print_function\n import os\n+import threading\n import pytest\n import numpy as np\n from keras.models import Sequential\n from keras.layers.core import Dense\n from keras.utils.test_utils import keras_test\n \n+STEPS_PER_EPOCH = 100\n+STEPS = 100\n+WORKERS = 4\n+\n \n @pytest.fixture\n def in_tmpdir(tmpdir):\n@@ -45,38 +50,130 @@ def custom_generator(use_weights=False):\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n-    model.fit_generator(custom_generator(),\n-                        steps_per_epoch=5,\n-                        epochs=1,\n-                        verbose=1,\n-                        max_queue_size=10,\n-                        workers=4,\n-                        use_multiprocessing=True)\n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=STEPS_PER_EPOCH,\n+                                epochs=1,\n+                                verbose=1,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=True)\n+    else:\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            epochs=1,\n+                            verbose=1,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=WORKERS,\n+                            use_multiprocessing=True)\n \n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n     model.fit_generator(custom_generator(),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         epochs=1,\n                         verbose=1,\n+                        validation_steps=None,\n                         max_queue_size=10,\n+                        workers=WORKERS,\n                         use_multiprocessing=False)\n \n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(True),\n+                                steps_per_epoch=STEPS_PER_EPOCH,\n+                                validation_data=(arr_data[:10],\n+                                                 arr_labels[:10],\n+                                                 arr_weights[:10]),\n+                                validation_steps=1,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+    else:\n+        model.fit_generator(custom_generator(True),\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            validation_data=(arr_data[:10],\n+                                             arr_labels[:10],\n+                                             arr_weights[:10]),\n+                            validation_steps=1,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n     model.fit_generator(custom_generator(True),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         validation_data=(arr_data[:10],\n                                          arr_labels[:10],\n                                          arr_weights[:10]),\n-                        validation_steps=1)\n+                        validation_steps=1,\n+                        max_queue_size=10,\n+                        workers=1,\n+                        use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(True),\n+                                steps_per_epoch=STEPS_PER_EPOCH,\n+                                validation_data=custom_generator(True),\n+                                validation_steps=1,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+    else:\n+        model.fit_generator(custom_generator(True),\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            validation_data=custom_generator(True),\n+                            validation_steps=1,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=True)\n \n+    # - Produce data on 1 worker thread AT A TIME, consume on main thread:\n+    #   - Worker threads for training and validation run generator SEQUENTIALLY\n     model.fit_generator(custom_generator(True),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         validation_data=custom_generator(True),\n-                        validation_steps=1)\n+                        validation_steps=1,\n+                        max_queue_size=10,\n+                        workers=1,\n+                        use_multiprocessing=False)\n \n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n     model.fit_generator(custom_generator(True),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         validation_data=custom_generator(True),\n                         validation_steps=1,\n-                        workers=0)\n+                        max_queue_size=10,\n+                        workers=0,\n+                        use_multiprocessing=True)\n+    model.fit_generator(custom_generator(True),\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n+                        validation_data=custom_generator(True),\n+                        validation_steps=1,\n+                        max_queue_size=10,\n+                        workers=0,\n+                        use_multiprocessing=False)\n \n     # Test invalid use cases\n     def invalid_generator():\n@@ -86,29 +183,39 @@ def invalid_generator():\n     # not specified `validation_steps`\n     with pytest.raises(ValueError):\n         model.fit_generator(custom_generator(),\n-                            steps_per_epoch=5,\n-                            validation_data=custom_generator())\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            validation_data=custom_generator(),\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=False)\n \n     # validation data is neither a tuple nor a triple.\n     with pytest.raises(ValueError):\n         model.fit_generator(custom_generator(),\n-                            steps_per_epoch=5,\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n                             validation_data=(arr_data[:10],\n                                              arr_data[:10],\n                                              arr_labels[:10],\n                                              arr_weights[:10]),\n-                            validation_steps=1)\n+                            validation_steps=1,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=False)\n \n     # validation generator is neither a tuple nor a triple.\n     with pytest.raises(ValueError):\n         model.fit_generator(custom_generator(),\n-                            steps_per_epoch=5,\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n                             validation_data=invalid_generator(),\n-                            validation_steps=1)\n+                            validation_steps=1,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=False)\n \n \n @keras_test\n-def test_multiprocessing_training_fromfile(in_tmpdir):\n+def test_multiprocessing_training_from_file(in_tmpdir):\n     arr_data = np.random.randint(0, 256, (50, 2))\n     arr_labels = np.random.randint(0, 2, 50)\n     np.savez('data.npz', **{'data': arr_data, 'labels': arr_labels})\n@@ -133,19 +240,95 @@ def custom_generator():\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=STEPS_PER_EPOCH,\n+                                epochs=1,\n+                                verbose=1,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=True)\n+    else:\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            epochs=1,\n+                            verbose=1,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=WORKERS,\n+                            use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n     model.fit_generator(custom_generator(),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         epochs=1,\n                         verbose=1,\n+                        validation_steps=None,\n                         max_queue_size=10,\n-                        workers=2,\n-                        use_multiprocessing=True)\n+                        workers=WORKERS,\n+                        use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=STEPS_PER_EPOCH,\n+                                epochs=1,\n+                                verbose=1,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+    else:\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            epochs=1,\n+                            verbose=1,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=True)\n \n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n     model.fit_generator(custom_generator(),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         epochs=1,\n                         verbose=1,\n+                        validation_steps=None,\n                         max_queue_size=10,\n+                        workers=1,\n+                        use_multiprocessing=False)\n+\n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n+    model.fit_generator(custom_generator(),\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n+                        epochs=1,\n+                        verbose=1,\n+                        validation_steps=None,\n+                        max_queue_size=10,\n+                        workers=0,\n+                        use_multiprocessing=True)\n+    model.fit_generator(custom_generator(),\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n+                        epochs=1,\n+                        verbose=1,\n+                        validation_steps=None,\n+                        max_queue_size=10,\n+                        workers=0,\n                         use_multiprocessing=False)\n \n     os.remove('data.npz')\n@@ -170,19 +353,73 @@ def custom_generator():\n     model = Sequential()\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n+\n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `predict_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=STEPS,\n+                                    max_queue_size=10,\n+                                    workers=WORKERS,\n+                                    use_multiprocessing=True)\n+    else:\n+        model.predict_generator(custom_generator(),\n+                                steps=STEPS,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n     model.predict_generator(custom_generator(),\n-                            steps=5,\n+                            steps=STEPS,\n                             max_queue_size=10,\n-                            workers=2,\n-                            use_multiprocessing=True)\n+                            workers=WORKERS,\n+                            use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `predict_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=STEPS,\n+                                    max_queue_size=10,\n+                                    workers=1,\n+                                    use_multiprocessing=True)\n+    else:\n+        model.predict_generator(custom_generator(),\n+                                steps=STEPS,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n     model.predict_generator(custom_generator(),\n-                            steps=5,\n+                            steps=STEPS,\n                             max_queue_size=10,\n+                            workers=1,\n                             use_multiprocessing=False)\n+\n+    # - Main thread runs the generator without a queue\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n     model.predict_generator(custom_generator(),\n-                            steps=5,\n+                            steps=STEPS,\n                             max_queue_size=10,\n-                            workers=0)\n+                            workers=0,\n+                            use_multiprocessing=True)\n+    model.predict_generator(custom_generator(),\n+                            steps=STEPS,\n+                            max_queue_size=10,\n+                            workers=0,\n+                            use_multiprocessing=False)\n \n \n @keras_test\n@@ -207,32 +444,92 @@ def custom_generator():\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries\n+    #       -> make sure `evaluate_generator()` raises raises ValueError\n+    #          exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=STEPS,\n+                                     max_queue_size=10,\n+                                     workers=WORKERS,\n+                                     use_multiprocessing=True)\n+    else:\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=STEPS,\n+                                 max_queue_size=10,\n+                                 workers=WORKERS,\n+                                 use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n     model.evaluate_generator(custom_generator(),\n-                             steps=5,\n+                             steps=STEPS,\n                              max_queue_size=10,\n-                             workers=2,\n-                             use_multiprocessing=True)\n+                             workers=WORKERS,\n+                             use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=STEPS,\n+                                     max_queue_size=10,\n+                                     workers=1,\n+                                     use_multiprocessing=True)\n+    else:\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=STEPS,\n+                                 max_queue_size=10,\n+                                 workers=1,\n+                                 use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n     model.evaluate_generator(custom_generator(),\n-                             steps=5,\n+                             steps=STEPS,\n                              max_queue_size=10,\n+                             workers=1,\n                              use_multiprocessing=False)\n+\n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n     model.evaluate_generator(custom_generator(),\n-                             steps=5,\n+                             steps=STEPS,\n                              max_queue_size=10,\n-                             use_multiprocessing=False,\n-                             workers=0)\n+                             workers=0,\n+                             use_multiprocessing=True)\n+    model.evaluate_generator(custom_generator(),\n+                             steps=STEPS,\n+                             max_queue_size=10,\n+                             workers=0,\n+                             use_multiprocessing=False)\n \n \n @keras_test\n def test_multiprocessing_fit_error():\n+    arr_data = np.random.randint(0, 256, (50, 2))\n+    arr_labels = np.random.randint(0, 2, 50)\n     batch_size = 10\n+    n_samples = 50\n     good_batches = 3\n \n-    def custom_generator():\n+    def custom_generator(use_weights=False):\n         \"\"\"Raises an exception after a few good batches\"\"\"\n         for i in range(good_batches):\n-            yield (np.random.randint(batch_size, 256, (50, 2)),\n-                   np.random.randint(batch_size, 12, 50))\n+            batch_index = np.random.randint(0, n_samples - batch_size)\n+            start = batch_index\n+            end = start + batch_size\n+            X = arr_data[start: end]\n+            y = arr_labels[start: end]\n+            yield X, y\n         raise RuntimeError\n \n     model = Sequential()\n@@ -241,77 +538,294 @@ def custom_generator():\n \n     samples = batch_size * (good_batches + 1)\n \n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=samples,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=samples,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n     with pytest.raises(RuntimeError):\n-        model.fit_generator(\n-            custom_generator(), samples, 1,\n-            workers=4, use_multiprocessing=True,\n-        )\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=samples,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=WORKERS,\n+                            use_multiprocessing=False)\n \n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=samples,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=samples,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n+    with pytest.raises(RuntimeError):\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=samples,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=False)\n+\n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n+    #   - Make sure `RuntimeError` exception bubbles up\n+    with pytest.raises(RuntimeError):\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=samples,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=0,\n+                            use_multiprocessing=True)\n     with pytest.raises(RuntimeError):\n-        model.fit_generator(\n-            custom_generator(), samples, 1,\n-            use_multiprocessing=False,\n-        )\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=samples,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=0,\n+                            use_multiprocessing=False)\n \n \n @keras_test\n def test_multiprocessing_evaluate_error():\n+    arr_data = np.random.randint(0, 256, (50, 2))\n+    arr_labels = np.random.randint(0, 2, 50)\n     batch_size = 10\n+    n_samples = 50\n     good_batches = 3\n-    workers = 4\n \n     def custom_generator():\n         \"\"\"Raises an exception after a few good batches\"\"\"\n         for i in range(good_batches):\n-            yield (np.random.randint(batch_size, 256, (50, 2)),\n-                   np.random.randint(batch_size, 12, 50))\n+            batch_index = np.random.randint(0, n_samples - batch_size)\n+            start = batch_index\n+            end = start + batch_size\n+            X = arr_data[start: end]\n+            y = arr_labels[start: end]\n+            yield X, y\n         raise RuntimeError\n \n     model = Sequential()\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=good_batches * WORKERS + 1,\n+                                     max_queue_size=10,\n+                                     workers=WORKERS,\n+                                     use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=good_batches * WORKERS + 1,\n+                                     max_queue_size=10,\n+                                     workers=WORKERS,\n+                                     use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n     with pytest.raises(RuntimeError):\n-        model.evaluate_generator(\n-            custom_generator(), good_batches * workers + 1, 1,\n-            workers=workers, use_multiprocessing=True,\n-        )\n-\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=good_batches * WORKERS + 1,\n+                                 max_queue_size=10,\n+                                 workers=WORKERS,\n+                                 use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=good_batches + 1,\n+                                     max_queue_size=10,\n+                                     workers=1,\n+                                     use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=good_batches + 1,\n+                                     max_queue_size=10,\n+                                     workers=1,\n+                                     use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n+    with pytest.raises(RuntimeError):\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=good_batches + 1,\n+                                 max_queue_size=10,\n+                                 workers=1,\n+                                 use_multiprocessing=False)\n+\n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n+    #   - Make sure `RuntimeError` exception bubbles up\n     with pytest.raises(RuntimeError):\n-        model.evaluate_generator(\n-            custom_generator(), good_batches + 1, 1,\n-            use_multiprocessing=False,\n-        )\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=good_batches + 1,\n+                                 max_queue_size=10,\n+                                 workers=0,\n+                                 use_multiprocessing=True)\n+    with pytest.raises(RuntimeError):\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=good_batches + 1,\n+                                 max_queue_size=10,\n+                                 workers=0,\n+                                 use_multiprocessing=False)\n \n \n @keras_test\n def test_multiprocessing_predict_error():\n+    arr_data = np.random.randint(0, 256, (50, 2))\n     good_batches = 3\n-    workers = 4\n \n     def custom_generator():\n         \"\"\"Raises an exception after a few good batches\"\"\"\n+        batch_size = 10\n+        n_samples = 50\n+\n         for i in range(good_batches):\n-            yield (np.random.randint(1, 256, size=(2, 5)),\n-                   np.random.randint(1, 256, size=(2, 5)))\n+            batch_index = np.random.randint(0, n_samples - batch_size)\n+            start = batch_index\n+            end = start + batch_size\n+            X = arr_data[start: end]\n+            yield X\n         raise RuntimeError\n \n     model = Sequential()\n-    model.add(Dense(1, input_shape=(5,)))\n+    model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `predict_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=good_batches * WORKERS + 1,\n+                                    max_queue_size=10,\n+                                    workers=WORKERS,\n+                                    use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=good_batches * WORKERS + 1,\n+                                    max_queue_size=10,\n+                                    workers=WORKERS,\n+                                    use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n     with pytest.raises(RuntimeError):\n-        model.predict_generator(\n-            custom_generator(), good_batches * workers + 1, 1,\n-            workers=workers, use_multiprocessing=True,\n-        )\n-\n+        model.predict_generator(custom_generator(),\n+                                steps=good_batches * WORKERS + 1,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `predict_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=good_batches + 1,\n+                                    max_queue_size=10,\n+                                    workers=1,\n+                                    use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=good_batches + 1,\n+                                    max_queue_size=10,\n+                                    workers=1,\n+                                    use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n     with pytest.raises(RuntimeError):\n-        model.predict_generator(\n-            custom_generator(), good_batches + 1, 1,\n-            use_multiprocessing=False,\n-        )\n-\n+        model.predict_generator(custom_generator(),\n+                                steps=good_batches + 1,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=False)\n+\n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n+    #   - Make sure `RuntimeError` exception bubbles up\n+    with pytest.raises(RuntimeError):\n+        model.predict_generator(custom_generator(),\n+                                steps=good_batches + 1,\n+                                max_queue_size=10,\n+                                workers=0,\n+                                use_multiprocessing=True)\n+    with pytest.raises(RuntimeError):\n+        model.predict_generator(custom_generator(),\n+                                steps=good_batches + 1,\n+                                max_queue_size=10,\n+                                workers=0,\n+                                use_multiprocessing=False)\n \n if __name__ == '__main__':\n     pytest.main([__file__])"
            }
        ],
        "diff": "diff --git a/keras/utils/data_utils.py b/keras/utils/data_utils.py\nindex bc0d87ce061..2b6ab69f1f2 100644\n--- a/keras/utils/data_utils.py\n+++ b/keras/utils/data_utils.py\n@@ -612,26 +612,49 @@ def __init__(self, generator,\n                  seed=None):\n         self.wait_time = wait_time\n         self._generator = generator\n-        self._use_multiprocessing = use_multiprocessing\n+        if os.name is 'nt' and use_multiprocessing is True:\n+            # On Windows, avoid **SYSTEMATIC** error in `multiprocessing`:\n+            # `TypeError: can't pickle generator objects`\n+            # => Suggest multithreading instead of multiprocessing on Windows\n+            raise ValueError('Using a generator with `use_multiprocessing=True`'\n+                             ' is not supported on Windows (no marshalling of'\n+                             ' generators across process boundaries). Instead,'\n+                             ' use single thread/process or multithreading.')\n+        else:\n+            self._use_multiprocessing = use_multiprocessing\n         self._threads = []\n         self._stop_event = None\n         self._manager = None\n         self.queue = None\n         self.seed = seed\n \n-    def start(self, workers=1, max_queue_size=10):\n-        \"\"\"Kicks off threads which add data from the generator into the queue.\n-\n-        # Arguments\n-            workers: number of worker threads\n-            max_queue_size: queue size\n-                (when full, threads could block on `put()`)\n-        \"\"\"\n-\n-        def data_generator_task():\n+    def _data_generator_task(self):\n+        if self._use_multiprocessing is False:\n+            while not self._stop_event.is_set():\n+                with self.genlock:\n+                    try:\n+                        if self.queue is not None and self.queue.qsize() < self.max_queue_size:\n+                            # On all OSes, avoid **SYSTEMATIC** error in multithreading mode:\n+                            # `ValueError: generator already executing`\n+                            # => Serialize calls to infinite iterator/generator's next() function\n+                            generator_output = next(self._generator)\n+                            self.queue.put((True, generator_output))\n+                        else:\n+                            time.sleep(self.wait_time)\n+                    except StopIteration:\n+                        break\n+                    except Exception as e:\n+                        # Can't pickle tracebacks.\n+                        # As a compromise, print the traceback and pickle None instead.\n+                        if not hasattr(e, '__traceback__'):\n+                            setattr(e, '__traceback__', sys.exc_info()[2])\n+                        self.queue.put((False, e))\n+                        self._stop_event.set()\n+                        break\n+        else:\n             while not self._stop_event.is_set():\n                 try:\n-                    if self._use_multiprocessing or self.queue.qsize() < max_queue_size:\n+                    if self.queue is not None and self.queue.qsize() < self.max_queue_size:\n                         generator_output = next(self._generator)\n                         self.queue.put((True, generator_output))\n                     else:\n@@ -639,24 +662,34 @@ def data_generator_task():\n                 except StopIteration:\n                     break\n                 except Exception as e:\n-                    # Can't pick tracebacks.\n+                    # Can't pickle tracebacks.\n                     # As a compromise, print the traceback and pickle None instead.\n-                    if self._use_multiprocessing:\n-                        traceback.print_exc()\n-                        setattr(e, '__traceback__', None)\n-                    elif not hasattr(e, '__traceback__'):\n-                        setattr(e, '__traceback__', sys.exc_info()[2])\n+                    traceback.print_exc()\n+                    setattr(e, '__traceback__', None)\n                     self.queue.put((False, e))\n                     self._stop_event.set()\n                     break\n \n+    def start(self, workers=1, max_queue_size=10):\n+        \"\"\"Kicks off threads which add data from the generator into the queue.\n+\n+        # Arguments\n+            workers: number of worker threads\n+            max_queue_size: queue size\n+                (when full, threads could block on `put()`)\n+        \"\"\"\n         try:\n+            self.max_queue_size = max_queue_size\n             if self._use_multiprocessing:\n                 self._manager = multiprocessing.Manager()\n                 self.queue = self._manager.Queue(maxsize=max_queue_size)\n                 self._stop_event = multiprocessing.Event()\n             else:\n-                self.queue = queue.Queue()\n+                # On all OSes, avoid **SYSTEMATIC** error in multithreading mode:\n+                # `ValueError: generator already executing`\n+                # => Serialize calls to infinite iterator/generator's next() function\n+                self.genlock = threading.Lock()\n+                self.queue = queue.Queue(maxsize=max_queue_size)\n                 self._stop_event = threading.Event()\n \n             for _ in range(workers):\n@@ -664,12 +697,12 @@ def data_generator_task():\n                     # Reset random seed else all children processes\n                     # share the same seed\n                     np.random.seed(self.seed)\n-                    thread = multiprocessing.Process(target=data_generator_task)\n+                    thread = multiprocessing.Process(target=self._data_generator_task)\n                     thread.daemon = True\n                     if self.seed is not None:\n                         self.seed += 1\n                 else:\n-                    thread = threading.Thread(target=data_generator_task)\n+                    thread = threading.Thread(target=self._data_generator_task)\n                 self._threads.append(thread)\n                 thread.start()\n         except:\n@@ -691,11 +724,15 @@ def stop(self, timeout=None):\n             self._stop_event.set()\n \n         for thread in self._threads:\n-            if thread.is_alive():\n-                if self._use_multiprocessing:\n+            if self._use_multiprocessing:\n+                if thread.is_alive():\n                     thread.terminate()\n-                else:\n-                    thread.join(timeout)\n+            else:\n+                # The thread.is_alive() test is subject to a race condition:\n+                # the thread could terminate right after the test and before the\n+                # join, rendering this test meaningless -> Call thread.join()\n+                # always, which is ok no matter what the status of the thread.\n+                thread.join(timeout)\n \n         if self._manager:\n             self._manager.shutdown()\ndiff --git a/tests/test_multiprocessing.py b/tests/test_multiprocessing.py\nindex 9b7a1632ea0..be7a59ac1e0 100644\n--- a/tests/test_multiprocessing.py\n+++ b/tests/test_multiprocessing.py\n@@ -1,11 +1,16 @@\n from __future__ import print_function\n import os\n+import threading\n import pytest\n import numpy as np\n from keras.models import Sequential\n from keras.layers.core import Dense\n from keras.utils.test_utils import keras_test\n \n+STEPS_PER_EPOCH = 100\n+STEPS = 100\n+WORKERS = 4\n+\n \n @pytest.fixture\n def in_tmpdir(tmpdir):\n@@ -45,38 +50,130 @@ def custom_generator(use_weights=False):\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n-    model.fit_generator(custom_generator(),\n-                        steps_per_epoch=5,\n-                        epochs=1,\n-                        verbose=1,\n-                        max_queue_size=10,\n-                        workers=4,\n-                        use_multiprocessing=True)\n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=STEPS_PER_EPOCH,\n+                                epochs=1,\n+                                verbose=1,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=True)\n+    else:\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            epochs=1,\n+                            verbose=1,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=WORKERS,\n+                            use_multiprocessing=True)\n \n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n     model.fit_generator(custom_generator(),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         epochs=1,\n                         verbose=1,\n+                        validation_steps=None,\n                         max_queue_size=10,\n+                        workers=WORKERS,\n                         use_multiprocessing=False)\n \n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(True),\n+                                steps_per_epoch=STEPS_PER_EPOCH,\n+                                validation_data=(arr_data[:10],\n+                                                 arr_labels[:10],\n+                                                 arr_weights[:10]),\n+                                validation_steps=1,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+    else:\n+        model.fit_generator(custom_generator(True),\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            validation_data=(arr_data[:10],\n+                                             arr_labels[:10],\n+                                             arr_weights[:10]),\n+                            validation_steps=1,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n     model.fit_generator(custom_generator(True),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         validation_data=(arr_data[:10],\n                                          arr_labels[:10],\n                                          arr_weights[:10]),\n-                        validation_steps=1)\n+                        validation_steps=1,\n+                        max_queue_size=10,\n+                        workers=1,\n+                        use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(True),\n+                                steps_per_epoch=STEPS_PER_EPOCH,\n+                                validation_data=custom_generator(True),\n+                                validation_steps=1,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+    else:\n+        model.fit_generator(custom_generator(True),\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            validation_data=custom_generator(True),\n+                            validation_steps=1,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=True)\n \n+    # - Produce data on 1 worker thread AT A TIME, consume on main thread:\n+    #   - Worker threads for training and validation run generator SEQUENTIALLY\n     model.fit_generator(custom_generator(True),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         validation_data=custom_generator(True),\n-                        validation_steps=1)\n+                        validation_steps=1,\n+                        max_queue_size=10,\n+                        workers=1,\n+                        use_multiprocessing=False)\n \n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n     model.fit_generator(custom_generator(True),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         validation_data=custom_generator(True),\n                         validation_steps=1,\n-                        workers=0)\n+                        max_queue_size=10,\n+                        workers=0,\n+                        use_multiprocessing=True)\n+    model.fit_generator(custom_generator(True),\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n+                        validation_data=custom_generator(True),\n+                        validation_steps=1,\n+                        max_queue_size=10,\n+                        workers=0,\n+                        use_multiprocessing=False)\n \n     # Test invalid use cases\n     def invalid_generator():\n@@ -86,29 +183,39 @@ def invalid_generator():\n     # not specified `validation_steps`\n     with pytest.raises(ValueError):\n         model.fit_generator(custom_generator(),\n-                            steps_per_epoch=5,\n-                            validation_data=custom_generator())\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            validation_data=custom_generator(),\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=False)\n \n     # validation data is neither a tuple nor a triple.\n     with pytest.raises(ValueError):\n         model.fit_generator(custom_generator(),\n-                            steps_per_epoch=5,\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n                             validation_data=(arr_data[:10],\n                                              arr_data[:10],\n                                              arr_labels[:10],\n                                              arr_weights[:10]),\n-                            validation_steps=1)\n+                            validation_steps=1,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=False)\n \n     # validation generator is neither a tuple nor a triple.\n     with pytest.raises(ValueError):\n         model.fit_generator(custom_generator(),\n-                            steps_per_epoch=5,\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n                             validation_data=invalid_generator(),\n-                            validation_steps=1)\n+                            validation_steps=1,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=False)\n \n \n @keras_test\n-def test_multiprocessing_training_fromfile(in_tmpdir):\n+def test_multiprocessing_training_from_file(in_tmpdir):\n     arr_data = np.random.randint(0, 256, (50, 2))\n     arr_labels = np.random.randint(0, 2, 50)\n     np.savez('data.npz', **{'data': arr_data, 'labels': arr_labels})\n@@ -133,19 +240,95 @@ def custom_generator():\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=STEPS_PER_EPOCH,\n+                                epochs=1,\n+                                verbose=1,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=True)\n+    else:\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            epochs=1,\n+                            verbose=1,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=WORKERS,\n+                            use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n     model.fit_generator(custom_generator(),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         epochs=1,\n                         verbose=1,\n+                        validation_steps=None,\n                         max_queue_size=10,\n-                        workers=2,\n-                        use_multiprocessing=True)\n+                        workers=WORKERS,\n+                        use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=STEPS_PER_EPOCH,\n+                                epochs=1,\n+                                verbose=1,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+    else:\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=STEPS_PER_EPOCH,\n+                            epochs=1,\n+                            verbose=1,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=True)\n \n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n     model.fit_generator(custom_generator(),\n-                        steps_per_epoch=5,\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n                         epochs=1,\n                         verbose=1,\n+                        validation_steps=None,\n                         max_queue_size=10,\n+                        workers=1,\n+                        use_multiprocessing=False)\n+\n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n+    model.fit_generator(custom_generator(),\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n+                        epochs=1,\n+                        verbose=1,\n+                        validation_steps=None,\n+                        max_queue_size=10,\n+                        workers=0,\n+                        use_multiprocessing=True)\n+    model.fit_generator(custom_generator(),\n+                        steps_per_epoch=STEPS_PER_EPOCH,\n+                        epochs=1,\n+                        verbose=1,\n+                        validation_steps=None,\n+                        max_queue_size=10,\n+                        workers=0,\n                         use_multiprocessing=False)\n \n     os.remove('data.npz')\n@@ -170,19 +353,73 @@ def custom_generator():\n     model = Sequential()\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n+\n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `predict_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=STEPS,\n+                                    max_queue_size=10,\n+                                    workers=WORKERS,\n+                                    use_multiprocessing=True)\n+    else:\n+        model.predict_generator(custom_generator(),\n+                                steps=STEPS,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n     model.predict_generator(custom_generator(),\n-                            steps=5,\n+                            steps=STEPS,\n                             max_queue_size=10,\n-                            workers=2,\n-                            use_multiprocessing=True)\n+                            workers=WORKERS,\n+                            use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `predict_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=STEPS,\n+                                    max_queue_size=10,\n+                                    workers=1,\n+                                    use_multiprocessing=True)\n+    else:\n+        model.predict_generator(custom_generator(),\n+                                steps=STEPS,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n     model.predict_generator(custom_generator(),\n-                            steps=5,\n+                            steps=STEPS,\n                             max_queue_size=10,\n+                            workers=1,\n                             use_multiprocessing=False)\n+\n+    # - Main thread runs the generator without a queue\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n     model.predict_generator(custom_generator(),\n-                            steps=5,\n+                            steps=STEPS,\n                             max_queue_size=10,\n-                            workers=0)\n+                            workers=0,\n+                            use_multiprocessing=True)\n+    model.predict_generator(custom_generator(),\n+                            steps=STEPS,\n+                            max_queue_size=10,\n+                            workers=0,\n+                            use_multiprocessing=False)\n \n \n @keras_test\n@@ -207,32 +444,92 @@ def custom_generator():\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries\n+    #       -> make sure `evaluate_generator()` raises raises ValueError\n+    #          exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=STEPS,\n+                                     max_queue_size=10,\n+                                     workers=WORKERS,\n+                                     use_multiprocessing=True)\n+    else:\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=STEPS,\n+                                 max_queue_size=10,\n+                                 workers=WORKERS,\n+                                 use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n     model.evaluate_generator(custom_generator(),\n-                             steps=5,\n+                             steps=STEPS,\n                              max_queue_size=10,\n-                             workers=2,\n-                             use_multiprocessing=True)\n+                             workers=WORKERS,\n+                             use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=STEPS,\n+                                     max_queue_size=10,\n+                                     workers=1,\n+                                     use_multiprocessing=True)\n+    else:\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=STEPS,\n+                                 max_queue_size=10,\n+                                 workers=1,\n+                                 use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n     model.evaluate_generator(custom_generator(),\n-                             steps=5,\n+                             steps=STEPS,\n                              max_queue_size=10,\n+                             workers=1,\n                              use_multiprocessing=False)\n+\n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n     model.evaluate_generator(custom_generator(),\n-                             steps=5,\n+                             steps=STEPS,\n                              max_queue_size=10,\n-                             use_multiprocessing=False,\n-                             workers=0)\n+                             workers=0,\n+                             use_multiprocessing=True)\n+    model.evaluate_generator(custom_generator(),\n+                             steps=STEPS,\n+                             max_queue_size=10,\n+                             workers=0,\n+                             use_multiprocessing=False)\n \n \n @keras_test\n def test_multiprocessing_fit_error():\n+    arr_data = np.random.randint(0, 256, (50, 2))\n+    arr_labels = np.random.randint(0, 2, 50)\n     batch_size = 10\n+    n_samples = 50\n     good_batches = 3\n \n-    def custom_generator():\n+    def custom_generator(use_weights=False):\n         \"\"\"Raises an exception after a few good batches\"\"\"\n         for i in range(good_batches):\n-            yield (np.random.randint(batch_size, 256, (50, 2)),\n-                   np.random.randint(batch_size, 12, 50))\n+            batch_index = np.random.randint(0, n_samples - batch_size)\n+            start = batch_index\n+            end = start + batch_size\n+            X = arr_data[start: end]\n+            y = arr_labels[start: end]\n+            yield X, y\n         raise RuntimeError\n \n     model = Sequential()\n@@ -241,77 +538,294 @@ def custom_generator():\n \n     samples = batch_size * (good_batches + 1)\n \n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=samples,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=samples,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n     with pytest.raises(RuntimeError):\n-        model.fit_generator(\n-            custom_generator(), samples, 1,\n-            workers=4, use_multiprocessing=True,\n-        )\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=samples,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=WORKERS,\n+                            use_multiprocessing=False)\n \n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `fit_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=samples,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.fit_generator(custom_generator(),\n+                                steps_per_epoch=samples,\n+                                validation_steps=None,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n+    with pytest.raises(RuntimeError):\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=samples,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=1,\n+                            use_multiprocessing=False)\n+\n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n+    #   - Make sure `RuntimeError` exception bubbles up\n+    with pytest.raises(RuntimeError):\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=samples,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=0,\n+                            use_multiprocessing=True)\n     with pytest.raises(RuntimeError):\n-        model.fit_generator(\n-            custom_generator(), samples, 1,\n-            use_multiprocessing=False,\n-        )\n+        model.fit_generator(custom_generator(),\n+                            steps_per_epoch=samples,\n+                            validation_steps=None,\n+                            max_queue_size=10,\n+                            workers=0,\n+                            use_multiprocessing=False)\n \n \n @keras_test\n def test_multiprocessing_evaluate_error():\n+    arr_data = np.random.randint(0, 256, (50, 2))\n+    arr_labels = np.random.randint(0, 2, 50)\n     batch_size = 10\n+    n_samples = 50\n     good_batches = 3\n-    workers = 4\n \n     def custom_generator():\n         \"\"\"Raises an exception after a few good batches\"\"\"\n         for i in range(good_batches):\n-            yield (np.random.randint(batch_size, 256, (50, 2)),\n-                   np.random.randint(batch_size, 12, 50))\n+            batch_index = np.random.randint(0, n_samples - batch_size)\n+            start = batch_index\n+            end = start + batch_size\n+            X = arr_data[start: end]\n+            y = arr_labels[start: end]\n+            yield X, y\n         raise RuntimeError\n \n     model = Sequential()\n     model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=good_batches * WORKERS + 1,\n+                                     max_queue_size=10,\n+                                     workers=WORKERS,\n+                                     use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=good_batches * WORKERS + 1,\n+                                     max_queue_size=10,\n+                                     workers=WORKERS,\n+                                     use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n     with pytest.raises(RuntimeError):\n-        model.evaluate_generator(\n-            custom_generator(), good_batches * workers + 1, 1,\n-            workers=workers, use_multiprocessing=True,\n-        )\n-\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=good_batches * WORKERS + 1,\n+                                 max_queue_size=10,\n+                                 workers=WORKERS,\n+                                 use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `evaluate_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=good_batches + 1,\n+                                     max_queue_size=10,\n+                                     workers=1,\n+                                     use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.evaluate_generator(custom_generator(),\n+                                     steps=good_batches + 1,\n+                                     max_queue_size=10,\n+                                     workers=1,\n+                                     use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n+    with pytest.raises(RuntimeError):\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=good_batches + 1,\n+                                 max_queue_size=10,\n+                                 workers=1,\n+                                 use_multiprocessing=False)\n+\n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n+    #   - Make sure `RuntimeError` exception bubbles up\n     with pytest.raises(RuntimeError):\n-        model.evaluate_generator(\n-            custom_generator(), good_batches + 1, 1,\n-            use_multiprocessing=False,\n-        )\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=good_batches + 1,\n+                                 max_queue_size=10,\n+                                 workers=0,\n+                                 use_multiprocessing=True)\n+    with pytest.raises(RuntimeError):\n+        model.evaluate_generator(custom_generator(),\n+                                 steps=good_batches + 1,\n+                                 max_queue_size=10,\n+                                 workers=0,\n+                                 use_multiprocessing=False)\n \n \n @keras_test\n def test_multiprocessing_predict_error():\n+    arr_data = np.random.randint(0, 256, (50, 2))\n     good_batches = 3\n-    workers = 4\n \n     def custom_generator():\n         \"\"\"Raises an exception after a few good batches\"\"\"\n+        batch_size = 10\n+        n_samples = 50\n+\n         for i in range(good_batches):\n-            yield (np.random.randint(1, 256, size=(2, 5)),\n-                   np.random.randint(1, 256, size=(2, 5)))\n+            batch_index = np.random.randint(0, n_samples - batch_size)\n+            start = batch_index\n+            end = start + batch_size\n+            X = arr_data[start: end]\n+            yield X\n         raise RuntimeError\n \n     model = Sequential()\n-    model.add(Dense(1, input_shape=(5,)))\n+    model.add(Dense(1, input_shape=(2, )))\n     model.compile(loss='mse', optimizer='adadelta')\n \n+    # - Produce data on 4 worker processes, consume on main process:\n+    #   - Each worker process runs OWN copy of generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `predict_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=good_batches * WORKERS + 1,\n+                                    max_queue_size=10,\n+                                    workers=WORKERS,\n+                                    use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=good_batches * WORKERS + 1,\n+                                    max_queue_size=10,\n+                                    workers=WORKERS,\n+                                    use_multiprocessing=True)\n+\n+    # - Produce data on 4 worker threads, consume on main thread:\n+    #   - All worker threads share the SAME generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n     with pytest.raises(RuntimeError):\n-        model.predict_generator(\n-            custom_generator(), good_batches * workers + 1, 1,\n-            workers=workers, use_multiprocessing=True,\n-        )\n-\n+        model.predict_generator(custom_generator(),\n+                                steps=good_batches * WORKERS + 1,\n+                                max_queue_size=10,\n+                                workers=WORKERS,\n+                                use_multiprocessing=False)\n+\n+    # - Produce data on 1 worker process, consume on main process:\n+    #   - Worker process runs generator\n+    #   - BUT on Windows, `multiprocessing` won't marshall generators across\n+    #     process boundaries -> make sure `predict_generator()` raises ValueError\n+    #     exception and does not attempt to run the generator.\n+    #   - On other platforms, make sure `RuntimeError` exception bubbles up\n+    if os.name is 'nt':\n+        with pytest.raises(ValueError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=good_batches + 1,\n+                                    max_queue_size=10,\n+                                    workers=1,\n+                                    use_multiprocessing=True)\n+    else:\n+        with pytest.raises(RuntimeError):\n+            model.predict_generator(custom_generator(),\n+                                    steps=good_batches + 1,\n+                                    max_queue_size=10,\n+                                    workers=1,\n+                                    use_multiprocessing=True)\n+\n+    # - Produce data on 1 worker thread, consume on main thread:\n+    #   - Worker thread is the only thread running the generator\n+    #   - Make sure `RuntimeError` exception bubbles up\n     with pytest.raises(RuntimeError):\n-        model.predict_generator(\n-            custom_generator(), good_batches + 1, 1,\n-            use_multiprocessing=False,\n-        )\n-\n+        model.predict_generator(custom_generator(),\n+                                steps=good_batches + 1,\n+                                max_queue_size=10,\n+                                workers=1,\n+                                use_multiprocessing=False)\n+\n+    # - Produce and consume data without a queue on main thread\n+    #   - Make sure the value of `use_multiprocessing` is ignored\n+    #   - Make sure `RuntimeError` exception bubbles up\n+    with pytest.raises(RuntimeError):\n+        model.predict_generator(custom_generator(),\n+                                steps=good_batches + 1,\n+                                max_queue_size=10,\n+                                workers=0,\n+                                use_multiprocessing=True)\n+    with pytest.raises(RuntimeError):\n+        model.predict_generator(custom_generator(),\n+                                steps=good_batches + 1,\n+                                max_queue_size=10,\n+                                workers=0,\n+                                use_multiprocessing=False)\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n",
        "reviews": [
            {
                "reviewer": "Dref360",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "Dref360",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "Dref360",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "philferriere",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "philferriere",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "philferriere",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "de-vri-es",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "de-vri-es",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "de-vri-es",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "philferriere",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "de-vri-es",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "de-vri-es",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "de-vri-es",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "philferriere",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "de-vri-es",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "fchollet",
                "state": "DISMISSED",
                "body": "Thanks for the PR!"
            },
            {
                "reviewer": "philferriere",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "philferriere",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "fchollet",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "philferriere",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "fchollet",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "fchollet",
                "state": "APPROVED",
                "body": "LGTM, thank you!"
            },
            {
                "reviewer": "datumbox",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "Dref360",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "Dref360",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "datumbox",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "Dref360",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "datumbox",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "Dref360",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "datumbox",
                "state": "COMMENTED",
                "body": "No comment"
            },
            {
                "reviewer": "de-vri-es",
                "state": "COMMENTED",
                "body": "No comment"
            }
        ],
        "comments": [
            {
                "commenter": "Dref360",
                "body": "At this point, what's the use case of using multiple threads for a generator? \r\n\r\nIs there any speedup doing multithreading, since the GIL would kill any concurrency anyway?  Shouldn't we just limit the `use_multiprocessing=False` to just one worker?\r\n\r\nI cannot speak for the Windows case since I do not own one. "
            },
            {
                "commenter": "philferriere",
                "body": "Good questions, Fr\u00e9d\u00e9ric.\r\n\r\nThis is really just a bug fix and is mostly about feature parity (not performance improvements) between Linux and Windows. I don't aim to support new use cases/scenarios either. If you need to know what my specific use case is, I have a personal interest in getting [this project](https://github.com/matterport/Mask_RCNN) to work on Windows.\r\n\r\nPerhaps your questions point to a larger interface design issue. I agree with you on the limitations imposed by the GIL. It seems to me that your valid concerns really apply to all platforms and I wasn't attempting to address them with this fix.\r\n\r\nAs of today, multi-process and multi-threaded generators are simply broken on Windows. And, by broken, I do mean code execution crashes (you'll see there are several bugs that have been reported over time). Being a huge fan of Keras, I don't want to forced to move to a different high-level deep learning library (Gluon?) because crashes on Windows are simply tolerated and bugs don't get fixed on the platform I have to support.\r\n\r\nI will leave it to you to come up with what I'm sure will be good answers to the larger Keras API issue. "
            },
            {
                "commenter": "Dref360",
                "body": "Your PR is fine, if multiprocessing doesn't work on Windows, we shouldn't try to support it."
            },
            {
                "commenter": "philferriere",
                "body": "Thanks, Fr\u00e9d\u00e9ric."
            },
            {
                "commenter": "de-vri-es",
                "body": "The real underlying issue here seems to be that python generators simply aren't suitable for multi-threading or multiprocessing. In the case of multiprocessing you'll always get each worker generating the same sequence, and in the case of multi-threading there can't really be any parallelism.\r\n\r\nAn interface which implies to do something impossible without actually doing it does more harm than good, I think. How about adding deprecation warnings to using generators with more than 1 worker and eventually remove support all together?\r\n\r\nIf there is a valid use case we should come up with an interface which does actually work. Sadly that probably means no Python generators, nice as they are."
            },
            {
                "commenter": "Dref360",
                "body": "There is a warning : [here](https://github.com/fchollet/keras/blob/master/keras/engine/training.py#L2023)"
            },
            {
                "commenter": "de-vri-es",
                "body": "> There is a warning : here\r\n\r\nYeah, but only in the `multiprocessing=True` case. Turns out the other case also doesn't really do what you would expect."
            },
            {
                "commenter": "philferriere",
                "body": "@Dref360 @de-vri-es, please let me know if you need anything else from me.\r\n\r\nIf you approve this PR, may I suggest adding a small note to [Docs \u00bb Models \u00bb Model (functional API)](https://keras.io/models/model/#methods) for the three generator methods (fit_generator, evaluate_generator, predict_generator)? Something along the lines of:\r\n\r\n*Using a generator with `use_multiprocessing=True` and `workers>0` is not supported on Windows (no marshalling of generators across process boundaries) and will result in a `ValueError` exception. Instead, use single thread/process or multithreading.*\r\n\r\nThank you both for your help with this!"
            },
            {
                "commenter": "de-vri-es",
                "body": "Looks good to me. I do think it makes sense to update the API of `GeneratorEnqueuer` to reflect the fact that parallelism isn't really possible at all, but that is probably out of scope for this PR. Removing race conditions is a good first step."
            },
            {
                "commenter": "adam-grant-hendry",
                "body": "> since the GIL would kill any concurrency anyway\r\n\r\nThe GIL kills _parallelism_, not concurrency:\r\n\r\n- `multitasking (parallelism)` = tasks literally run at the same time\r\n- `multithreading (concurrency)` = tasks can start, run, and complete in overlapping time so there is no down time, but only one task runs at a time\r\n\r\nJust adding this so people aren't confused."
            },
            {
                "commenter": "de-vri-es",
                "body": "That's a little nitpicky, but also, the distinction between multitasking and multithreading as you describe it is quite arbitrary.\r\n\r\nNowadays, a \"task\" tends to refer to a concept from either your languague runtime or a library, and doesn't necessarily map to parallel execution. Multi-threading on the other hand is an execution model, possibly for \"tasks\", that actually runs parallel in practically any languague other than python since the days of multi-core CPUs (~2005)."
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 17052,
        "body": "Adaptation of the temporary fix by @kyamagu from #16173.",
        "changed_files": [
            {
                "filename": "keras/callbacks.py",
                "patch": "@@ -2767,6 +2767,18 @@ def on_train_batch_end(self, batch, logs=None):\n                 1.0 / batch_run_time,\n                 step=self._train_step,\n             )\n+\n+        should_record = False\n+        if type(self.update_freq) == int:\n+            should_record = tf.equal(self._train_step % self.update_freq, 0)\n+        with tf.summary.record_if(should_record):\n+            if logs:\n+                with self._train_writer.as_default():\n+                    for name, value in logs.items():\n+                        tf.summary.scalar(\n+                            \"batch_\" + name, value, step=self._train_step\n+                        )\n+\n         if not self._should_trace:\n             return\n "
            },
            {
                "filename": "keras/callbacks_test.py",
                "patch": "@@ -2991,6 +2991,7 @@ def test_TensorBoard_batch_metrics(self):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(logdir=self.validation_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(\n@@ -3053,6 +3054,7 @@ def test_TensorBoard_global_step(self):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(\n                     logdir=self.train_dir, tag=\"epoch_learning_rate\"\n@@ -3238,6 +3240,7 @@ def call(self, x):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(logdir=self.validation_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary("
            }
        ],
        "diff": "diff --git a/keras/callbacks.py b/keras/callbacks.py\nindex e596f3de538..f678f2d37c3 100644\n--- a/keras/callbacks.py\n+++ b/keras/callbacks.py\n@@ -2767,6 +2767,18 @@ def on_train_batch_end(self, batch, logs=None):\n                 1.0 / batch_run_time,\n                 step=self._train_step,\n             )\n+\n+        should_record = False\n+        if type(self.update_freq) == int:\n+            should_record = tf.equal(self._train_step % self.update_freq, 0)\n+        with tf.summary.record_if(should_record):\n+            if logs:\n+                with self._train_writer.as_default():\n+                    for name, value in logs.items():\n+                        tf.summary.scalar(\n+                            \"batch_\" + name, value, step=self._train_step\n+                        )\n+\n         if not self._should_trace:\n             return\n \ndiff --git a/keras/callbacks_test.py b/keras/callbacks_test.py\nindex 0b8438eb72d..ff10c777944 100644\n--- a/keras/callbacks_test.py\n+++ b/keras/callbacks_test.py\n@@ -2991,6 +2991,7 @@ def test_TensorBoard_batch_metrics(self):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(logdir=self.validation_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(\n@@ -3053,6 +3054,7 @@ def test_TensorBoard_global_step(self):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(\n                     logdir=self.train_dir, tag=\"epoch_learning_rate\"\n@@ -3238,6 +3240,7 @@ def call(self, x):\n         self.assertEqual(\n             summary_file.scalars,\n             {\n+                _ObservedSummary(logdir=self.train_dir, tag=\"batch_loss\"),\n                 _ObservedSummary(logdir=self.train_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(logdir=self.validation_dir, tag=\"epoch_loss\"),\n                 _ObservedSummary(\n",
        "reviews": [
            {
                "reviewer": "rchao",
                "state": "COMMENTED",
                "body": "No comment"
            }
        ],
        "comments": [
            {
                "commenter": "google-cla[bot]",
                "body": "Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/keras-team/keras/pull/17052/checks?check_run_id=8440270071) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."
            },
            {
                "commenter": "myaaaaaaaaa",
                "body": "@rchao I just realized that all the logging checks were unnecessary since they're already done in `_push_writer()`, so this patch can be reduced to:\r\n\r\n```diff\r\ndiff --git a/keras/callbacks.py b/keras/callbacks.py\r\nindex 07852e86..86316f66 100644\r\n--- a/keras/callbacks.py\r\n+++ b/keras/callbacks.py\r\n@@ -2707,24 +2707,29 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\r\n \r\n     def on_train_batch_end(self, batch, logs=None):\r\n         if self._should_write_train_graph:\r\n             self._write_keras_model_train_graph()\r\n             self._should_write_train_graph = False\r\n         if self.write_steps_per_second:\r\n             batch_run_time = time.time() - self._batch_start_time\r\n             tf.summary.scalar(\r\n                 \"batch_steps_per_second\",\r\n                 1.0 / batch_run_time,\r\n                 step=self._train_step,\r\n             )\r\n+\r\n+        if logs:\r\n+            for name, value in logs.items():\r\n+                tf.summary.scalar(\"batch_\" + name, value, step=self._train_step)\r\n+\r\n         if not self._should_trace:\r\n             return\r\n \r\n         if self._is_tracing and self._global_train_batch >= self._stop_batch:\r\n             self._stop_trace()\r\n```\r\n\r\nDoes this version have similar performance problems with asynchronous strategies? If not, I'll open a new pull request since I seem to have accidentally broken this one with all of my force pushing."
            }
        ]
    },
    {
        "repo": "keras-team/keras",
        "pr_number": 16363,
        "body": "This should solve this issue : https://github.com/keras-team/keras-applications/issues/151\r\n\r\nWhich has duplicates here:\r\n- https://github.com/keras-team/keras/issues/15269\r\n- https://github.com/keras-team/keras/issues/15494\r\n\r\nI don't know how to test this, this is why I am making it a draft PR.\r\nI haven't implemented the V2, to make this easy to review, and I haven't trained the networks to get the weights.\r\n\r\nNote: this is a reopening of https://github.com/keras-team/keras/pull/16358, which I messed up with wrong emails in the commits.",
        "changed_files": [
            {
                "filename": "keras/applications/applications_test.py",
                "patch": "@@ -38,6 +38,8 @@\n from keras.applications import xception\n \n MODEL_LIST_NO_NASNET = [\n+    (resnet.ResNet18, 512),\n+    (resnet.ResNet34, 512),\n     (resnet.ResNet50, 2048),\n     (resnet.ResNet101, 2048),\n     (resnet.ResNet152, 2048),"
            },
            {
                "filename": "keras/applications/resnet.py",
                "patch": "@@ -12,7 +12,6 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\n \"\"\"ResNet models for Keras.\n \n Reference:\n@@ -242,8 +241,92 @@ def ResNet(\n     return model\n \n \n-def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n-    \"\"\"A residual block.\n+def basic_block(\n+    x,\n+    filters,\n+    stride=1,\n+    use_bias=True,\n+    conv_shortcut=True,\n+    manual_padding=True,\n+    name=None,\n+):\n+    \"\"\"A basic residual block for ResNet18 and 34.\n+\n+    Args:\n+      x: input tensor.\n+      filters: integer, filters of the bottleneck layer.\n+      use_bias: default True, whether to use biases in convolution\n+          layers.\n+      stride: default 1, stride of the first layer.\n+      conv_shortcut: default True, use convolution shortcut if True,\n+          otherwise identity shortcut.\n+      manual_padding: default True, whether to use manual padding for\n+          strided convolutions in order to use ported PyTorch weights.\n+      name: string, block label.\n+\n+    Returns:\n+      Output tensor for the basic residual block.\n+    \"\"\"\n+    bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n+    kernel_size = 3\n+\n+    if conv_shortcut:\n+        shortcut = layers.Conv2D(\n+            filters, 1, strides=stride, use_bias=use_bias, name=name + \"_0_conv\"\n+        )(x)\n+        shortcut = layers.BatchNormalization(\n+            axis=bn_axis, epsilon=1.001e-5, name=name + \"_0_bn\"\n+        )(shortcut)\n+    else:\n+        shortcut = x\n+\n+    if stride > 1 and manual_padding:\n+        x = layers.ZeroPadding2D(\n+            padding=((1, 0), (1, 0)), name=name + \"_1_pad\"\n+        )(x)\n+        padding_mode = \"valid\"\n+    else:\n+        padding_mode = \"same\"\n+    x = layers.Conv2D(\n+        filters,\n+        kernel_size,\n+        padding=padding_mode,\n+        strides=stride,\n+        use_bias=use_bias,\n+        name=name + \"_1_conv\",\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_1_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=name + \"_1_relu\")(x)\n+\n+    x = layers.Conv2D(\n+        filters,\n+        kernel_size,\n+        padding=\"SAME\",\n+        use_bias=use_bias,\n+        name=name + \"_2_conv\",\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_2_bn\"\n+    )(x)\n+\n+    x = layers.Add(name=name + \"_add\")([shortcut, x])\n+    x = layers.Activation(\"relu\", name=name + \"_out\")(x)\n+    return x\n+\n+\n+def bottleneck_block(\n+    x,\n+    filters,\n+    kernel_size=3,\n+    stride=1,\n+    conv_shortcut=True,\n+    use_bias=True,\n+    manual_padding=False,\n+    name=None,\n+):\n+    \"\"\"A residual block with a bottle neck used in ResNet 50, 101, 152.\n \n     Args:\n       x: input tensor.\n@@ -252,6 +335,9 @@ def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n       stride: default 1, stride of the first layer.\n       conv_shortcut: default True, use convolution shortcut if True,\n           otherwise identity shortcut.\n+      use_bias: default True, whether to use biases in convolution\n+          layers.\n+      manual_padding: default False, mock arg.\n       name: string, block label.\n \n     Returns:\n@@ -261,29 +347,41 @@ def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n \n     if conv_shortcut:\n         shortcut = layers.Conv2D(\n-            4 * filters, 1, strides=stride, name=name + \"_0_conv\"\n+            4 * filters,\n+            1,\n+            strides=stride,\n+            use_bias=use_bias,\n+            name=name + \"_0_conv\",\n         )(x)\n         shortcut = layers.BatchNormalization(\n             axis=bn_axis, epsilon=1.001e-5, name=name + \"_0_bn\"\n         )(shortcut)\n     else:\n         shortcut = x\n \n-    x = layers.Conv2D(filters, 1, strides=stride, name=name + \"_1_conv\")(x)\n+    x = layers.Conv2D(\n+        filters, 1, strides=stride, use_bias=use_bias, name=name + \"_1_conv\"\n+    )(x)\n     x = layers.BatchNormalization(\n         axis=bn_axis, epsilon=1.001e-5, name=name + \"_1_bn\"\n     )(x)\n     x = layers.Activation(\"relu\", name=name + \"_1_relu\")(x)\n \n     x = layers.Conv2D(\n-        filters, kernel_size, padding=\"SAME\", name=name + \"_2_conv\"\n+        filters,\n+        kernel_size,\n+        padding=\"SAME\",\n+        use_bias=use_bias,\n+        name=name + \"_2_conv\",\n     )(x)\n     x = layers.BatchNormalization(\n         axis=bn_axis, epsilon=1.001e-5, name=name + \"_2_bn\"\n     )(x)\n     x = layers.Activation(\"relu\", name=name + \"_2_relu\")(x)\n \n-    x = layers.Conv2D(4 * filters, 1, name=name + \"_3_conv\")(x)\n+    x = layers.Conv2D(4 * filters, 1, use_bias=use_bias, name=name + \"_3_conv\")(\n+        x\n+    )\n     x = layers.BatchNormalization(\n         axis=bn_axis, epsilon=1.001e-5, name=name + \"_3_bn\"\n     )(x)\n@@ -293,23 +391,54 @@ def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n     return x\n \n \n-def stack1(x, filters, blocks, stride1=2, name=None):\n+def stack_block(\n+    x,\n+    filters,\n+    n_blocks,\n+    block_fn,\n+    stride1=2,\n+    use_bias=True,\n+    first_shortcut=True,\n+    manual_padding=True,\n+    name=None,\n+):\n     \"\"\"A set of stacked residual blocks.\n \n     Args:\n       x: input tensor.\n       filters: integer, filters of the bottleneck layer in a block.\n-      blocks: integer, blocks in the stacked blocks.\n+      n_blocks: integer, blocks in the stacked blocks.\n+      block_fn: callable, function defining one block.\n       stride1: default 2, stride of the first layer in the first block.\n+      use_bias: default True, whether to use biases in convolution\n+          layers.\n+      first_shortcut: default True, whether to use the convolution shortcut\n+          of the first layer in the first block.\n+      manual_padding: default True, whether to use manual padding for\n+          strided convolutions in order to use ported PyTorch weights.\n+          Used only for basic blocks.\n       name: string, stack label.\n \n     Returns:\n-      Output tensor for the stacked blocks.\n+      Output tensor for the stacked basic blocks.\n     \"\"\"\n-    x = block1(x, filters, stride=stride1, name=name + \"_block1\")\n-    for i in range(2, blocks + 1):\n-        x = block1(\n-            x, filters, conv_shortcut=False, name=name + \"_block\" + str(i)\n+    x = block_fn(\n+        x,\n+        filters,\n+        stride=stride1,\n+        conv_shortcut=first_shortcut,\n+        use_bias=use_bias,\n+        manual_padding=manual_padding,\n+        name=name + \"_block1\",\n+    )\n+    for i in range(2, n_blocks + 1):\n+        x = block_fn(\n+            x,\n+            filters,\n+            conv_shortcut=False,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=name + \"_block\" + str(i),\n         )\n     return x\n \n@@ -496,6 +625,148 @@ def stack3(x, filters, blocks, stride1=2, groups=32, name=None):\n     return x\n \n \n+@keras_export(\n+    \"keras.applications.resnet.ResNet18\", \"keras.applications.ResNet18\"\n+)\n+def ResNet18(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    use_bias=True,\n+    manual_padding=True,\n+    **kwargs\n+):\n+    \"\"\"Instantiates the ResNet18 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = stack_block(\n+            x,\n+            64,\n+            2,\n+            basic_block,\n+            use_bias=use_bias,\n+            first_shortcut=False,\n+            stride1=1,\n+            manual_padding=manual_padding,\n+            name=\"conv2\",\n+        )\n+        x = stack_block(\n+            x,\n+            128,\n+            2,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv3\",\n+        )\n+        x = stack_block(\n+            x,\n+            256,\n+            2,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv4\",\n+        )\n+        return stack_block(\n+            x,\n+            512,\n+            2,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv5\",\n+        )\n+\n+    return ResNet(\n+        stack_fn,\n+        False,\n+        use_bias,\n+        \"resnet18\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        **kwargs\n+    )\n+\n+\n+@keras_export(\n+    \"keras.applications.resnet.ResNet34\", \"keras.applications.ResNet34\"\n+)\n+def ResNet34(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    use_bias=True,\n+    manual_padding=True,\n+    **kwargs\n+):\n+    \"\"\"Instantiates the ResNet34 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = stack_block(\n+            x,\n+            64,\n+            3,\n+            basic_block,\n+            use_bias=use_bias,\n+            first_shortcut=False,\n+            stride1=1,\n+            manual_padding=manual_padding,\n+            name=\"conv2\",\n+        )\n+        x = stack_block(\n+            x,\n+            128,\n+            4,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv3\",\n+        )\n+        x = stack_block(\n+            x,\n+            256,\n+            6,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv4\",\n+        )\n+        return stack_block(\n+            x,\n+            512,\n+            3,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv5\",\n+        )\n+\n+    return ResNet(\n+        stack_fn,\n+        False,\n+        use_bias,\n+        \"resnet34\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        **kwargs\n+    )\n+\n+\n @keras_export(\n     \"keras.applications.resnet50.ResNet50\",\n     \"keras.applications.resnet.ResNet50\",\n@@ -508,20 +779,40 @@ def ResNet50(\n     input_shape=None,\n     pooling=None,\n     classes=1000,\n+    use_bias=True,\n     **kwargs\n ):\n     \"\"\"Instantiates the ResNet50 architecture.\"\"\"\n \n     def stack_fn(x):\n-        x = stack1(x, 64, 3, stride1=1, name=\"conv2\")\n-        x = stack1(x, 128, 4, name=\"conv3\")\n-        x = stack1(x, 256, 6, name=\"conv4\")\n-        return stack1(x, 512, 3, name=\"conv5\")\n+        x = stack_block(\n+            x,\n+            64,\n+            3,\n+            bottleneck_block,\n+            use_bias=use_bias,\n+            stride1=1,\n+            name=\"conv2\",\n+        )\n+        x = stack_block(\n+            x, 128, 4, bottleneck_block, use_bias=use_bias, name=\"conv3\"\n+        )\n+        x = stack_block(\n+            x, 256, 6, bottleneck_block, use_bias=use_bias, name=\"conv4\"\n+        )\n+        return stack_block(\n+            x,\n+            512,\n+            3,\n+            bottleneck_block,\n+            use_bias=use_bias,\n+            name=\"conv5\",\n+        )\n \n     return ResNet(\n         stack_fn,\n         False,\n-        True,\n+        use_bias,\n         \"resnet50\",\n         include_top,\n         weights,\n@@ -543,20 +834,40 @@ def ResNet101(\n     input_shape=None,\n     pooling=None,\n     classes=1000,\n+    use_bias=True,\n     **kwargs\n ):\n     \"\"\"Instantiates the ResNet101 architecture.\"\"\"\n \n     def stack_fn(x):\n-        x = stack1(x, 64, 3, stride1=1, name=\"conv2\")\n-        x = stack1(x, 128, 4, name=\"conv3\")\n-        x = stack1(x, 256, 23, name=\"conv4\")\n-        return stack1(x, 512, 3, name=\"conv5\")\n+        x = stack_block(\n+            x,\n+            64,\n+            3,\n+            bottleneck_block,\n+            use_bias=use_bias,\n+            stride1=1,\n+            name=\"conv2\",\n+        )\n+        x = stack_block(\n+            x, 128, 4, bottleneck_block, use_bias=use_bias, name=\"conv3\"\n+        )\n+        x = stack_block(\n+            x, 256, 23, bottleneck_block, use_bias=use_bias, name=\"conv4\"\n+        )\n+        return stack_block(\n+            x,\n+            512,\n+            3,\n+            bottleneck_block,\n+            use_bias=use_bias,\n+            name=\"conv5\",\n+        )\n \n     return ResNet(\n         stack_fn,\n         False,\n-        True,\n+        use_bias,\n         \"resnet101\",\n         include_top,\n         weights,\n@@ -578,20 +889,35 @@ def ResNet152(\n     input_shape=None,\n     pooling=None,\n     classes=1000,\n+    use_bias=True,\n     **kwargs\n ):\n     \"\"\"Instantiates the ResNet152 architecture.\"\"\"\n \n     def stack_fn(x):\n-        x = stack1(x, 64, 3, stride1=1, name=\"conv2\")\n-        x = stack1(x, 128, 8, name=\"conv3\")\n-        x = stack1(x, 256, 36, name=\"conv4\")\n-        return stack1(x, 512, 3, name=\"conv5\")\n+        x = stack_block(\n+            x,\n+            64,\n+            3,\n+            bottleneck_block,\n+            use_bias=use_bias,\n+            stride1=1,\n+            name=\"conv2\",\n+        )\n+        x = stack_block(\n+            x, 128, 8, bottleneck_block, use_bias=use_bias, name=\"conv3\"\n+        )\n+        x = stack_block(\n+            x, 256, 36, bottleneck_block, use_bias=use_bias, name=\"conv4\"\n+        )\n+        return stack_block(\n+            x, 512, 3, bottleneck_block, use_bias=use_bias, name=\"conv5\"\n+        )\n \n     return ResNet(\n         stack_fn,\n         False,\n-        True,\n+        use_bias,\n         \"resnet152\",\n         include_top,\n         weights,\n@@ -678,6 +1004,9 @@ def decode_predictions(preds, top=5):\n     classes: optional number of classes to classify images\n       into, only to be specified if `include_top` is True, and\n       if no `weights` argument is specified.\n+    use_bias: optional boolean, to specify whether to have a bias in\n+    the convolutions. Note that biases are not needed since the batch\n+    normalization layers are affine.\n     classifier_activation: A `str` or callable. The activation function to use\n       on the \"top\" layer. Ignored unless `include_top=True`. Set\n       `classifier_activation=None` to return the logits of the \"top\" layer.\n@@ -688,6 +1017,8 @@ def decode_predictions(preds, top=5):\n     A Keras model instance.\n \"\"\"\n \n+setattr(ResNet18, \"__doc__\", ResNet18.__doc__ + DOC)\n+setattr(ResNet34, \"__doc__\", ResNet34.__doc__ + DOC)\n setattr(ResNet50, \"__doc__\", ResNet50.__doc__ + DOC)\n setattr(ResNet101, \"__doc__\", ResNet101.__doc__ + DOC)\n setattr(ResNet152, \"__doc__\", ResNet152.__doc__ + DOC)"
            }
        ],
        "diff": "diff --git a/keras/applications/applications_test.py b/keras/applications/applications_test.py\nindex 0f99cf07f3b..66e345c9d4a 100644\n--- a/keras/applications/applications_test.py\n+++ b/keras/applications/applications_test.py\n@@ -38,6 +38,8 @@\n from keras.applications import xception\n \n MODEL_LIST_NO_NASNET = [\n+    (resnet.ResNet18, 512),\n+    (resnet.ResNet34, 512),\n     (resnet.ResNet50, 2048),\n     (resnet.ResNet101, 2048),\n     (resnet.ResNet152, 2048),\ndiff --git a/keras/applications/resnet.py b/keras/applications/resnet.py\nindex 700b2ea1774..fff09dde4e2 100644\n--- a/keras/applications/resnet.py\n+++ b/keras/applications/resnet.py\n@@ -12,7 +12,6 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n # ==============================================================================\n-\n \"\"\"ResNet models for Keras.\n \n Reference:\n@@ -242,8 +241,92 @@ def ResNet(\n     return model\n \n \n-def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n-    \"\"\"A residual block.\n+def basic_block(\n+    x,\n+    filters,\n+    stride=1,\n+    use_bias=True,\n+    conv_shortcut=True,\n+    manual_padding=True,\n+    name=None,\n+):\n+    \"\"\"A basic residual block for ResNet18 and 34.\n+\n+    Args:\n+      x: input tensor.\n+      filters: integer, filters of the bottleneck layer.\n+      use_bias: default True, whether to use biases in convolution\n+          layers.\n+      stride: default 1, stride of the first layer.\n+      conv_shortcut: default True, use convolution shortcut if True,\n+          otherwise identity shortcut.\n+      manual_padding: default True, whether to use manual padding for\n+          strided convolutions in order to use ported PyTorch weights.\n+      name: string, block label.\n+\n+    Returns:\n+      Output tensor for the basic residual block.\n+    \"\"\"\n+    bn_axis = 3 if backend.image_data_format() == \"channels_last\" else 1\n+    kernel_size = 3\n+\n+    if conv_shortcut:\n+        shortcut = layers.Conv2D(\n+            filters, 1, strides=stride, use_bias=use_bias, name=name + \"_0_conv\"\n+        )(x)\n+        shortcut = layers.BatchNormalization(\n+            axis=bn_axis, epsilon=1.001e-5, name=name + \"_0_bn\"\n+        )(shortcut)\n+    else:\n+        shortcut = x\n+\n+    if stride > 1 and manual_padding:\n+        x = layers.ZeroPadding2D(\n+            padding=((1, 0), (1, 0)), name=name + \"_1_pad\"\n+        )(x)\n+        padding_mode = \"valid\"\n+    else:\n+        padding_mode = \"same\"\n+    x = layers.Conv2D(\n+        filters,\n+        kernel_size,\n+        padding=padding_mode,\n+        strides=stride,\n+        use_bias=use_bias,\n+        name=name + \"_1_conv\",\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_1_bn\"\n+    )(x)\n+    x = layers.Activation(\"relu\", name=name + \"_1_relu\")(x)\n+\n+    x = layers.Conv2D(\n+        filters,\n+        kernel_size,\n+        padding=\"SAME\",\n+        use_bias=use_bias,\n+        name=name + \"_2_conv\",\n+    )(x)\n+    x = layers.BatchNormalization(\n+        axis=bn_axis, epsilon=1.001e-5, name=name + \"_2_bn\"\n+    )(x)\n+\n+    x = layers.Add(name=name + \"_add\")([shortcut, x])\n+    x = layers.Activation(\"relu\", name=name + \"_out\")(x)\n+    return x\n+\n+\n+def bottleneck_block(\n+    x,\n+    filters,\n+    kernel_size=3,\n+    stride=1,\n+    conv_shortcut=True,\n+    use_bias=True,\n+    manual_padding=False,\n+    name=None,\n+):\n+    \"\"\"A residual block with a bottle neck used in ResNet 50, 101, 152.\n \n     Args:\n       x: input tensor.\n@@ -252,6 +335,9 @@ def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n       stride: default 1, stride of the first layer.\n       conv_shortcut: default True, use convolution shortcut if True,\n           otherwise identity shortcut.\n+      use_bias: default True, whether to use biases in convolution\n+          layers.\n+      manual_padding: default False, mock arg.\n       name: string, block label.\n \n     Returns:\n@@ -261,7 +347,11 @@ def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n \n     if conv_shortcut:\n         shortcut = layers.Conv2D(\n-            4 * filters, 1, strides=stride, name=name + \"_0_conv\"\n+            4 * filters,\n+            1,\n+            strides=stride,\n+            use_bias=use_bias,\n+            name=name + \"_0_conv\",\n         )(x)\n         shortcut = layers.BatchNormalization(\n             axis=bn_axis, epsilon=1.001e-5, name=name + \"_0_bn\"\n@@ -269,21 +359,29 @@ def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n     else:\n         shortcut = x\n \n-    x = layers.Conv2D(filters, 1, strides=stride, name=name + \"_1_conv\")(x)\n+    x = layers.Conv2D(\n+        filters, 1, strides=stride, use_bias=use_bias, name=name + \"_1_conv\"\n+    )(x)\n     x = layers.BatchNormalization(\n         axis=bn_axis, epsilon=1.001e-5, name=name + \"_1_bn\"\n     )(x)\n     x = layers.Activation(\"relu\", name=name + \"_1_relu\")(x)\n \n     x = layers.Conv2D(\n-        filters, kernel_size, padding=\"SAME\", name=name + \"_2_conv\"\n+        filters,\n+        kernel_size,\n+        padding=\"SAME\",\n+        use_bias=use_bias,\n+        name=name + \"_2_conv\",\n     )(x)\n     x = layers.BatchNormalization(\n         axis=bn_axis, epsilon=1.001e-5, name=name + \"_2_bn\"\n     )(x)\n     x = layers.Activation(\"relu\", name=name + \"_2_relu\")(x)\n \n-    x = layers.Conv2D(4 * filters, 1, name=name + \"_3_conv\")(x)\n+    x = layers.Conv2D(4 * filters, 1, use_bias=use_bias, name=name + \"_3_conv\")(\n+        x\n+    )\n     x = layers.BatchNormalization(\n         axis=bn_axis, epsilon=1.001e-5, name=name + \"_3_bn\"\n     )(x)\n@@ -293,23 +391,54 @@ def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n     return x\n \n \n-def stack1(x, filters, blocks, stride1=2, name=None):\n+def stack_block(\n+    x,\n+    filters,\n+    n_blocks,\n+    block_fn,\n+    stride1=2,\n+    use_bias=True,\n+    first_shortcut=True,\n+    manual_padding=True,\n+    name=None,\n+):\n     \"\"\"A set of stacked residual blocks.\n \n     Args:\n       x: input tensor.\n       filters: integer, filters of the bottleneck layer in a block.\n-      blocks: integer, blocks in the stacked blocks.\n+      n_blocks: integer, blocks in the stacked blocks.\n+      block_fn: callable, function defining one block.\n       stride1: default 2, stride of the first layer in the first block.\n+      use_bias: default True, whether to use biases in convolution\n+          layers.\n+      first_shortcut: default True, whether to use the convolution shortcut\n+          of the first layer in the first block.\n+      manual_padding: default True, whether to use manual padding for\n+          strided convolutions in order to use ported PyTorch weights.\n+          Used only for basic blocks.\n       name: string, stack label.\n \n     Returns:\n-      Output tensor for the stacked blocks.\n+      Output tensor for the stacked basic blocks.\n     \"\"\"\n-    x = block1(x, filters, stride=stride1, name=name + \"_block1\")\n-    for i in range(2, blocks + 1):\n-        x = block1(\n-            x, filters, conv_shortcut=False, name=name + \"_block\" + str(i)\n+    x = block_fn(\n+        x,\n+        filters,\n+        stride=stride1,\n+        conv_shortcut=first_shortcut,\n+        use_bias=use_bias,\n+        manual_padding=manual_padding,\n+        name=name + \"_block1\",\n+    )\n+    for i in range(2, n_blocks + 1):\n+        x = block_fn(\n+            x,\n+            filters,\n+            conv_shortcut=False,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=name + \"_block\" + str(i),\n         )\n     return x\n \n@@ -496,6 +625,148 @@ def stack3(x, filters, blocks, stride1=2, groups=32, name=None):\n     return x\n \n \n+@keras_export(\n+    \"keras.applications.resnet.ResNet18\", \"keras.applications.ResNet18\"\n+)\n+def ResNet18(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    use_bias=True,\n+    manual_padding=True,\n+    **kwargs\n+):\n+    \"\"\"Instantiates the ResNet18 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = stack_block(\n+            x,\n+            64,\n+            2,\n+            basic_block,\n+            use_bias=use_bias,\n+            first_shortcut=False,\n+            stride1=1,\n+            manual_padding=manual_padding,\n+            name=\"conv2\",\n+        )\n+        x = stack_block(\n+            x,\n+            128,\n+            2,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv3\",\n+        )\n+        x = stack_block(\n+            x,\n+            256,\n+            2,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv4\",\n+        )\n+        return stack_block(\n+            x,\n+            512,\n+            2,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv5\",\n+        )\n+\n+    return ResNet(\n+        stack_fn,\n+        False,\n+        use_bias,\n+        \"resnet18\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        **kwargs\n+    )\n+\n+\n+@keras_export(\n+    \"keras.applications.resnet.ResNet34\", \"keras.applications.ResNet34\"\n+)\n+def ResNet34(\n+    include_top=True,\n+    weights=\"imagenet\",\n+    input_tensor=None,\n+    input_shape=None,\n+    pooling=None,\n+    classes=1000,\n+    use_bias=True,\n+    manual_padding=True,\n+    **kwargs\n+):\n+    \"\"\"Instantiates the ResNet34 architecture.\"\"\"\n+\n+    def stack_fn(x):\n+        x = stack_block(\n+            x,\n+            64,\n+            3,\n+            basic_block,\n+            use_bias=use_bias,\n+            first_shortcut=False,\n+            stride1=1,\n+            manual_padding=manual_padding,\n+            name=\"conv2\",\n+        )\n+        x = stack_block(\n+            x,\n+            128,\n+            4,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv3\",\n+        )\n+        x = stack_block(\n+            x,\n+            256,\n+            6,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv4\",\n+        )\n+        return stack_block(\n+            x,\n+            512,\n+            3,\n+            basic_block,\n+            use_bias=use_bias,\n+            manual_padding=manual_padding,\n+            name=\"conv5\",\n+        )\n+\n+    return ResNet(\n+        stack_fn,\n+        False,\n+        use_bias,\n+        \"resnet34\",\n+        include_top,\n+        weights,\n+        input_tensor,\n+        input_shape,\n+        pooling,\n+        classes,\n+        **kwargs\n+    )\n+\n+\n @keras_export(\n     \"keras.applications.resnet50.ResNet50\",\n     \"keras.applications.resnet.ResNet50\",\n@@ -508,20 +779,40 @@ def ResNet50(\n     input_shape=None,\n     pooling=None,\n     classes=1000,\n+    use_bias=True,\n     **kwargs\n ):\n     \"\"\"Instantiates the ResNet50 architecture.\"\"\"\n \n     def stack_fn(x):\n-        x = stack1(x, 64, 3, stride1=1, name=\"conv2\")\n-        x = stack1(x, 128, 4, name=\"conv3\")\n-        x = stack1(x, 256, 6, name=\"conv4\")\n-        return stack1(x, 512, 3, name=\"conv5\")\n+        x = stack_block(\n+            x,\n+            64,\n+            3,\n+            bottleneck_block,\n+            use_bias=use_bias,\n+            stride1=1,\n+            name=\"conv2\",\n+        )\n+        x = stack_block(\n+            x, 128, 4, bottleneck_block, use_bias=use_bias, name=\"conv3\"\n+        )\n+        x = stack_block(\n+            x, 256, 6, bottleneck_block, use_bias=use_bias, name=\"conv4\"\n+        )\n+        return stack_block(\n+            x,\n+            512,\n+            3,\n+            bottleneck_block,\n+            use_bias=use_bias,\n+            name=\"conv5\",\n+        )\n \n     return ResNet(\n         stack_fn,\n         False,\n-        True,\n+        use_bias,\n         \"resnet50\",\n         include_top,\n         weights,\n@@ -543,20 +834,40 @@ def ResNet101(\n     input_shape=None,\n     pooling=None,\n     classes=1000,\n+    use_bias=True,\n     **kwargs\n ):\n     \"\"\"Instantiates the ResNet101 architecture.\"\"\"\n \n     def stack_fn(x):\n-        x = stack1(x, 64, 3, stride1=1, name=\"conv2\")\n-        x = stack1(x, 128, 4, name=\"conv3\")\n-        x = stack1(x, 256, 23, name=\"conv4\")\n-        return stack1(x, 512, 3, name=\"conv5\")\n+        x = stack_block(\n+            x,\n+            64,\n+            3,\n+            bottleneck_block,\n+            use_bias=use_bias,\n+            stride1=1,\n+            name=\"conv2\",\n+        )\n+        x = stack_block(\n+            x, 128, 4, bottleneck_block, use_bias=use_bias, name=\"conv3\"\n+        )\n+        x = stack_block(\n+            x, 256, 23, bottleneck_block, use_bias=use_bias, name=\"conv4\"\n+        )\n+        return stack_block(\n+            x,\n+            512,\n+            3,\n+            bottleneck_block,\n+            use_bias=use_bias,\n+            name=\"conv5\",\n+        )\n \n     return ResNet(\n         stack_fn,\n         False,\n-        True,\n+        use_bias,\n         \"resnet101\",\n         include_top,\n         weights,\n@@ -578,20 +889,35 @@ def ResNet152(\n     input_shape=None,\n     pooling=None,\n     classes=1000,\n+    use_bias=True,\n     **kwargs\n ):\n     \"\"\"Instantiates the ResNet152 architecture.\"\"\"\n \n     def stack_fn(x):\n-        x = stack1(x, 64, 3, stride1=1, name=\"conv2\")\n-        x = stack1(x, 128, 8, name=\"conv3\")\n-        x = stack1(x, 256, 36, name=\"conv4\")\n-        return stack1(x, 512, 3, name=\"conv5\")\n+        x = stack_block(\n+            x,\n+            64,\n+            3,\n+            bottleneck_block,\n+            use_bias=use_bias,\n+            stride1=1,\n+            name=\"conv2\",\n+        )\n+        x = stack_block(\n+            x, 128, 8, bottleneck_block, use_bias=use_bias, name=\"conv3\"\n+        )\n+        x = stack_block(\n+            x, 256, 36, bottleneck_block, use_bias=use_bias, name=\"conv4\"\n+        )\n+        return stack_block(\n+            x, 512, 3, bottleneck_block, use_bias=use_bias, name=\"conv5\"\n+        )\n \n     return ResNet(\n         stack_fn,\n         False,\n-        True,\n+        use_bias,\n         \"resnet152\",\n         include_top,\n         weights,\n@@ -678,6 +1004,9 @@ def decode_predictions(preds, top=5):\n     classes: optional number of classes to classify images\n       into, only to be specified if `include_top` is True, and\n       if no `weights` argument is specified.\n+    use_bias: optional boolean, to specify whether to have a bias in\n+    the convolutions. Note that biases are not needed since the batch\n+    normalization layers are affine.\n     classifier_activation: A `str` or callable. The activation function to use\n       on the \"top\" layer. Ignored unless `include_top=True`. Set\n       `classifier_activation=None` to return the logits of the \"top\" layer.\n@@ -688,6 +1017,8 @@ def decode_predictions(preds, top=5):\n     A Keras model instance.\n \"\"\"\n \n+setattr(ResNet18, \"__doc__\", ResNet18.__doc__ + DOC)\n+setattr(ResNet34, \"__doc__\", ResNet34.__doc__ + DOC)\n setattr(ResNet50, \"__doc__\", ResNet50.__doc__ + DOC)\n setattr(ResNet101, \"__doc__\", ResNet101.__doc__ + DOC)\n setattr(ResNet152, \"__doc__\", ResNet152.__doc__ + DOC)\n",
        "reviews": [],
        "comments": [
            {
                "commenter": "zaccharieramzi",
                "body": "Adding the model summaries here for info:\r\n\r\nResnet18:\r\n```\r\nModel: \"resnet18\"\r\n__________________________________________________________________________________________________\r\n Layer (type)                   Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\n input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \r\n                                )]                                                                \r\n                                                                                                  \r\n conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \r\n                                                                                                  \r\n conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \r\n                                )                                                                 \r\n                                                                                                  \r\n conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \r\n                                )                                                                 \r\n                                                                                                  \r\n conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \r\n                                )                                                                 \r\n                                                                                                  \r\n pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \r\n                                )                                                                 \r\n                                                                                                  \r\n pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \r\n                                                                                                  \r\n conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   36928       ['pool1_pool[0][0]']             \r\n                                                                                                  \r\n conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv2_block1_0_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \r\n                                                                                                  \r\n conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \r\n                                                                                                  \r\n conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_0_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block1_add (Add)         (None, 56, 56, 64)   0           ['conv2_block1_0_bn[0][0]',      \r\n                                                                  'conv2_block1_2_bn[0][0]']      \r\n                                                                                                  \r\n conv2_block1_out (Activation)  (None, 56, 56, 64)   0           ['conv2_block1_add[0][0]']       \r\n                                                                                                  \r\n conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_out[0][0]']       \r\n                                                                                                  \r\n conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \r\n                                                                                                  \r\n conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block2_add (Add)         (None, 56, 56, 64)   0           ['conv2_block1_out[0][0]',       \r\n                                                                  'conv2_block2_2_bn[0][0]']      \r\n                                                                                                  \r\n conv2_block2_out (Activation)  (None, 56, 56, 64)   0           ['conv2_block2_add[0][0]']       \r\n                                                                                                  \r\n conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  73856       ['conv2_block2_out[0][0]']       \r\n                                                                                                  \r\n conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv3_block1_0_conv (Conv2D)   (None, 28, 28, 128)  8320        ['conv2_block2_out[0][0]']       \r\n                                                                                                  \r\n conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \r\n                                                                                                  \r\n conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_0_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block1_add (Add)         (None, 28, 28, 128)  0           ['conv3_block1_0_bn[0][0]',      \r\n                                                                  'conv3_block1_2_bn[0][0]']      \r\n                                                                                                  \r\n conv3_block1_out (Activation)  (None, 28, 28, 128)  0           ['conv3_block1_add[0][0]']       \r\n                                                                                                  \r\n conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_out[0][0]']       \r\n                                                                                                  \r\n conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \r\n                                                                                                  \r\n conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block2_add (Add)         (None, 28, 28, 128)  0           ['conv3_block1_out[0][0]',       \r\n                                                                  'conv3_block2_2_bn[0][0]']      \r\n                                                                                                  \r\n conv3_block2_out (Activation)  (None, 28, 28, 128)  0           ['conv3_block2_add[0][0]']       \r\n                                                                                                  \r\n conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  295168      ['conv3_block2_out[0][0]']       \r\n                                                                                                  \r\n conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv4_block1_0_conv (Conv2D)   (None, 14, 14, 256)  33024       ['conv3_block2_out[0][0]']       \r\n                                                                                                  \r\n conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \r\n                                                                                                  \r\n conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_0_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block1_add (Add)         (None, 14, 14, 256)  0           ['conv4_block1_0_bn[0][0]',      \r\n                                                                  'conv4_block1_2_bn[0][0]']      \r\n                                                                                                  \r\n conv4_block1_out (Activation)  (None, 14, 14, 256)  0           ['conv4_block1_add[0][0]']       \r\n                                                                                                  \r\n conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_out[0][0]']       \r\n                                                                                                  \r\n conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \r\n                                                                                                  \r\n conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block2_add (Add)         (None, 14, 14, 256)  0           ['conv4_block1_out[0][0]',       \r\n                                                                  'conv4_block2_2_bn[0][0]']      \r\n                                                                                                  \r\n conv4_block2_out (Activation)  (None, 14, 14, 256)  0           ['conv4_block2_add[0][0]']       \r\n                                                                                                  \r\n conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    1180160     ['conv4_block2_out[0][0]']       \r\n                                                                                                  \r\n conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv5_block1_0_conv (Conv2D)   (None, 7, 7, 512)    131584      ['conv4_block2_out[0][0]']       \r\n                                                                                                  \r\n conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \r\n                                                                                                  \r\n conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_0_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block1_add (Add)         (None, 7, 7, 512)    0           ['conv5_block1_0_bn[0][0]',      \r\n                                                                  'conv5_block1_2_bn[0][0]']      \r\n                                                                                                  \r\n conv5_block1_out (Activation)  (None, 7, 7, 512)    0           ['conv5_block1_add[0][0]']       \r\n                                                                                                  \r\n conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_out[0][0]']       \r\n                                                                                                  \r\n conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \r\n                                                                                                  \r\n conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block2_add (Add)         (None, 7, 7, 512)    0           ['conv5_block1_out[0][0]',       \r\n                                                                  'conv5_block2_2_bn[0][0]']      \r\n                                                                                                  \r\n conv5_block2_out (Activation)  (None, 7, 7, 512)    0           ['conv5_block2_add[0][0]']       \r\n                                                                                                  \r\n avg_pool (GlobalAveragePooling  (None, 512)         0           ['conv5_block2_out[0][0]']       \r\n 2D)                                                                                              \r\n                                                                                                  \r\n predictions (Dense)            (None, 1000)         513000      ['avg_pool[0][0]']               \r\n                                                                                                  \r\n==================================================================================================\r\nTotal params: 11,708,328\r\nTrainable params: 11,698,600\r\nNon-trainable params: 9,728\r\n__________________________________________________________________________________________________\r\n\r\n```\r\n\r\nResnet34:\r\n\r\n```\r\nModel: \"resnet34\"\r\n__________________________________________________________________________________________________\r\n Layer (type)                   Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\n input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \r\n                                )]                                                                \r\n                                                                                                  \r\n conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \r\n                                                                                                  \r\n conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \r\n                                )                                                                 \r\n                                                                                                  \r\n conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \r\n                                )                                                                 \r\n                                                                                                  \r\n conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \r\n                                )                                                                 \r\n                                                                                                  \r\n pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \r\n                                )                                                                 \r\n                                                                                                  \r\n pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \r\n                                                                                                  \r\n conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   36928       ['pool1_pool[0][0]']             \r\n                                                                                                  \r\n conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv2_block1_0_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \r\n                                                                                                  \r\n conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \r\n                                                                                                  \r\n conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_0_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block1_add (Add)         (None, 56, 56, 64)   0           ['conv2_block1_0_bn[0][0]',      \r\n                                                                  'conv2_block1_2_bn[0][0]']      \r\n                                                                                                  \r\n conv2_block1_out (Activation)  (None, 56, 56, 64)   0           ['conv2_block1_add[0][0]']       \r\n                                                                                                  \r\n conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_out[0][0]']       \r\n                                                                                                  \r\n conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \r\n                                                                                                  \r\n conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block2_add (Add)         (None, 56, 56, 64)   0           ['conv2_block1_out[0][0]',       \r\n                                                                  'conv2_block2_2_bn[0][0]']      \r\n                                                                                                  \r\n conv2_block2_out (Activation)  (None, 56, 56, 64)   0           ['conv2_block2_add[0][0]']       \r\n                                                                                                  \r\n conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_out[0][0]']       \r\n                                                                                                  \r\n conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \r\n                                                                                                  \r\n conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv2_block3_add (Add)         (None, 56, 56, 64)   0           ['conv2_block2_out[0][0]',       \r\n                                                                  'conv2_block3_2_bn[0][0]']      \r\n                                                                                                  \r\n conv2_block3_out (Activation)  (None, 56, 56, 64)   0           ['conv2_block3_add[0][0]']       \r\n                                                                                                  \r\n conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  73856       ['conv2_block3_out[0][0]']       \r\n                                                                                                  \r\n conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv3_block1_0_conv (Conv2D)   (None, 28, 28, 128)  8320        ['conv2_block3_out[0][0]']       \r\n                                                                                                  \r\n conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \r\n                                                                                                  \r\n conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_0_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block1_add (Add)         (None, 28, 28, 128)  0           ['conv3_block1_0_bn[0][0]',      \r\n                                                                  'conv3_block1_2_bn[0][0]']      \r\n                                                                                                  \r\n conv3_block1_out (Activation)  (None, 28, 28, 128)  0           ['conv3_block1_add[0][0]']       \r\n                                                                                                  \r\n conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_out[0][0]']       \r\n                                                                                                  \r\n conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \r\n                                                                                                  \r\n conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block2_add (Add)         (None, 28, 28, 128)  0           ['conv3_block1_out[0][0]',       \r\n                                                                  'conv3_block2_2_bn[0][0]']      \r\n                                                                                                  \r\n conv3_block2_out (Activation)  (None, 28, 28, 128)  0           ['conv3_block2_add[0][0]']       \r\n                                                                                                  \r\n conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_out[0][0]']       \r\n                                                                                                  \r\n conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \r\n                                                                                                  \r\n conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block3_add (Add)         (None, 28, 28, 128)  0           ['conv3_block2_out[0][0]',       \r\n                                                                  'conv3_block3_2_bn[0][0]']      \r\n                                                                                                  \r\n conv3_block3_out (Activation)  (None, 28, 28, 128)  0           ['conv3_block3_add[0][0]']       \r\n                                                                                                  \r\n conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_out[0][0]']       \r\n                                                                                                  \r\n conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \r\n                                                                                                  \r\n conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv3_block4_add (Add)         (None, 28, 28, 128)  0           ['conv3_block3_out[0][0]',       \r\n                                                                  'conv3_block4_2_bn[0][0]']      \r\n                                                                                                  \r\n conv3_block4_out (Activation)  (None, 28, 28, 128)  0           ['conv3_block4_add[0][0]']       \r\n                                                                                                  \r\n conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  295168      ['conv3_block4_out[0][0]']       \r\n                                                                                                  \r\n conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv4_block1_0_conv (Conv2D)   (None, 14, 14, 256)  33024       ['conv3_block4_out[0][0]']       \r\n                                                                                                  \r\n conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \r\n                                                                                                  \r\n conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_0_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block1_add (Add)         (None, 14, 14, 256)  0           ['conv4_block1_0_bn[0][0]',      \r\n                                                                  'conv4_block1_2_bn[0][0]']      \r\n                                                                                                  \r\n conv4_block1_out (Activation)  (None, 14, 14, 256)  0           ['conv4_block1_add[0][0]']       \r\n                                                                                                  \r\n conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_out[0][0]']       \r\n                                                                                                  \r\n conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \r\n                                                                                                  \r\n conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block2_add (Add)         (None, 14, 14, 256)  0           ['conv4_block1_out[0][0]',       \r\n                                                                  'conv4_block2_2_bn[0][0]']      \r\n                                                                                                  \r\n conv4_block2_out (Activation)  (None, 14, 14, 256)  0           ['conv4_block2_add[0][0]']       \r\n                                                                                                  \r\n conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_out[0][0]']       \r\n                                                                                                  \r\n conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \r\n                                                                                                  \r\n conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block3_add (Add)         (None, 14, 14, 256)  0           ['conv4_block2_out[0][0]',       \r\n                                                                  'conv4_block3_2_bn[0][0]']      \r\n                                                                                                  \r\n conv4_block3_out (Activation)  (None, 14, 14, 256)  0           ['conv4_block3_add[0][0]']       \r\n                                                                                                  \r\n conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_out[0][0]']       \r\n                                                                                                  \r\n conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \r\n                                                                                                  \r\n conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block4_add (Add)         (None, 14, 14, 256)  0           ['conv4_block3_out[0][0]',       \r\n                                                                  'conv4_block4_2_bn[0][0]']      \r\n                                                                                                  \r\n conv4_block4_out (Activation)  (None, 14, 14, 256)  0           ['conv4_block4_add[0][0]']       \r\n                                                                                                  \r\n conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_out[0][0]']       \r\n                                                                                                  \r\n conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \r\n                                                                                                  \r\n conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block5_add (Add)         (None, 14, 14, 256)  0           ['conv4_block4_out[0][0]',       \r\n                                                                  'conv4_block5_2_bn[0][0]']      \r\n                                                                                                  \r\n conv4_block5_out (Activation)  (None, 14, 14, 256)  0           ['conv4_block5_add[0][0]']       \r\n                                                                                                  \r\n conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_out[0][0]']       \r\n                                                                                                  \r\n conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \r\n                                                                                                  \r\n conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv4_block6_add (Add)         (None, 14, 14, 256)  0           ['conv4_block5_out[0][0]',       \r\n                                                                  'conv4_block6_2_bn[0][0]']      \r\n                                                                                                  \r\n conv4_block6_out (Activation)  (None, 14, 14, 256)  0           ['conv4_block6_add[0][0]']       \r\n                                                                                                  \r\n conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    1180160     ['conv4_block6_out[0][0]']       \r\n                                                                                                  \r\n conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv5_block1_0_conv (Conv2D)   (None, 7, 7, 512)    131584      ['conv4_block6_out[0][0]']       \r\n                                                                                                  \r\n conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \r\n                                                                                                  \r\n conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_0_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block1_add (Add)         (None, 7, 7, 512)    0           ['conv5_block1_0_bn[0][0]',      \r\n                                                                  'conv5_block1_2_bn[0][0]']      \r\n                                                                                                  \r\n conv5_block1_out (Activation)  (None, 7, 7, 512)    0           ['conv5_block1_add[0][0]']       \r\n                                                                                                  \r\n conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_out[0][0]']       \r\n                                                                                                  \r\n conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \r\n                                                                                                  \r\n conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block2_add (Add)         (None, 7, 7, 512)    0           ['conv5_block1_out[0][0]',       \r\n                                                                  'conv5_block2_2_bn[0][0]']      \r\n                                                                                                  \r\n conv5_block2_out (Activation)  (None, 7, 7, 512)    0           ['conv5_block2_add[0][0]']       \r\n                                                                                                  \r\n conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_out[0][0]']       \r\n                                                                                                  \r\n conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \r\n n)                                                                                               \r\n                                                                                                  \r\n conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \r\n                                                                                                  \r\n conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \r\n ization)                                                                                         \r\n                                                                                                  \r\n conv5_block3_add (Add)         (None, 7, 7, 512)    0           ['conv5_block2_out[0][0]',       \r\n                                                                  'conv5_block3_2_bn[0][0]']      \r\n                                                                                                  \r\n conv5_block3_out (Activation)  (None, 7, 7, 512)    0           ['conv5_block3_add[0][0]']       \r\n                                                                                                  \r\n avg_pool (GlobalAveragePooling  (None, 512)         0           ['conv5_block3_out[0][0]']       \r\n 2D)                                                                                              \r\n                                                                                                  \r\n predictions (Dense)            (None, 1000)         513000      ['avg_pool[0][0]']               \r\n                                                                                                  \r\n==================================================================================================\r\nTotal params: 21,827,624\r\nTrainable params: 21,810,472\r\nNon-trainable params: 17,152\r\n__________________________________________________________________________________________________\r\n```\r\n\r\nIt turns out that they do not match PyTorch's numbers which is something I do not understand.\r\nFor info, the same happens for ResNet50 (already implemented), and you can see that in the following colab: https://colab.research.google.com/drive/1RCmWkpwuKFapzzPacbqodxz0mqt9Igft?usp=sharing\r\n\r\nThis appears to be due to the fact that there are bias in TF's convs, and not in PyTorch's ones, and also due to how PyTorch counts BN's params.\r\n\r\nHowever, the last dimension before the dense layer matches, and the size (WH) of the feature maps matches as well."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "So 2 things w.r.t. to the comparison with PyTorch:\r\n- indeed the only difference in the trainable parameter count is the use of bias in Keras. Imo, there shouldn't be any bias in the convolutions given we have affine BatchNorm just afterwards. Maybe having an option allowing to use it or not would be nice, I am going to implement it.\r\n- the batch norm in PyTorch indeed doesn't count the running stats as parameters but as buffers.\r\n\r\nSide note: the default momentum values for the batch norm in Keras and PyTorch are not the same: 0.9 for PyTorch and 0.99 in Keras. This, coupled with the use of bias in TF will mean that the training will be different between the 2 frameworks.\r\n\r\nI think it would be nice to implement the possibility to change the batch norm momentum to fit PyTorch's one, I am going to open a new issue and a new PR about this."
            },
            {
                "commenter": "qlzh727",
                "body": "Thanks for the PR. Could u make the sure the weights for imagenet also available? Also please make sure to run the evaluation with imagenet eval set, and report the acc number in the PR."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@qlzh727 should I train the models also for the no bias case?\n\nAlso, could you point me to the script that were used to train the bigger models? I couldn't find them but maybe didn't look well enough"
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@qlzh727 I was looking for an official script to train a classification model on imagenet, and stumbled upon this: https://github.com/tensorflow/models\r\n\r\nThere is a typical example allowing to train classification models, but I also noticed that there is already an implementation of ResNet without the bias and with the basic blocks [here](https://github.com/tensorflow/models/blob/master/official/vision/modeling/backbones/resnet.py). I don't think the weights are available, but now my question is more: should we re-implement it here given it's already present in this other repo?\r\n\r\nBasically, is there a difference in concern between keras applications and tensorflow models?"
            },
            {
                "commenter": "zaccharieramzi",
                "body": "I just noticed that one additional difference with the PyTorch implementation (in both keras applications and tensorflow models) is the initialization strategy for the convolution weights.\r\n\r\n| **Framework**  | **Init strategy**                                                                                                                                                     |\r\n|----------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\r\n| **PyTorch**    | [He normal](https://pytorch.org/vision/main/_modules/torchvision/models/resnet.html#ResNet), `nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")` |\r\n| **Keras**      | [Glorot uniform](https://github.com/keras-team/keras/blob/master/keras/applications/resnet.py#L238), default of `Conv2D`                                              |\r\n| **TensorFlow** | [Variance Scaling](https://github.com/tensorflow/models/blob/master/official/vision/modeling/backbones/resnet.py#L128), at least by default                           |"
            },
            {
                "commenter": "qlzh727",
                "body": "> @qlzh727 should I train the models also for the no bias case?\r\n> \r\n> Also, could you point me to the script that were used to train the bigger models? I couldn't find them but maybe didn't look well enough\r\n\r\nWe currently don't have any script for retrain the model. Keras application was used for fine tuning and we usually reuse weights/checkpoints from original paper (if it was published)."
            },
            {
                "commenter": "qlzh727",
                "body": "> @qlzh727 I was looking for an official script to train a classification model on imagenet, and stumbled upon this: https://github.com/tensorflow/models\r\n> \r\n> There is a typical example allowing to train classification models, but I also noticed that there is already an implementation of ResNet without the bias and with the basic blocks [here](https://github.com/tensorflow/models/blob/master/official/vision/modeling/backbones/resnet.py). I don't think the weights are available, but now my question is more: should we re-implement it here given it's already present in this other repo?\r\n> \r\n> Basically, is there a difference in concern between keras applications and tensorflow models?\r\n\r\ntensorflow-models is more focused on end to end solutions, and if that's already available in tf-models, we probably can skip it here in keras.application (given that you can't get any existing weigths)."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "Well the original paper did train both resnet 18 and 34, but not sure in which framework or even whether the weights are available. \r\nDo you know where you obtained the resnet 50 weights ? \r\n\r\nAnother solution would be to translate the ones from PyTorch, potentially forcing the bias to 0 for the original implementations with bias. Wdyt? \r\n\r\nEDIT\r\n--------\r\n\r\nOne last thing is that if we do not include the resnet 18 and 34 here, it might still be nice to have a pointer to tensorflow/models, in order for people looking for an implementation to find it easily (this is not the case rn, see https://github.com/keras-team/keras-applications/issues/151)"
            },
            {
                "commenter": "fchollet",
                "body": "> Do you know where you obtained the resnet 50 weights\r\n\r\nI ported them from the original Caffe implementation IIRC.\r\n\r\n> Another solution would be to translate the ones from PyTorch, potentially forcing the bias to 0 for the original implementations with bias. Wdyt?\r\n\r\nSure, if you can produce an ImageNet weights checkpoint (under proper licensing), that works.\r\n\r\n> We currently don't have any script for retrain the model\r\n\r\nHopefully we'll have such a script in KerasCV soon.\r\n"
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@fchollet thanks for your answer.\r\n\r\nDo you know how I can check the license for the PyTorch weights? In their repo they have [a vague statement regarding this](https://github.com/pytorch/vision#pre-trained-model-license). \r\n> The pre-trained models provided in this library may have their own licenses or terms and conditions derived from the dataset used for training. It is your responsibility to determine whether you have permission to use the models for your use case.\r\n\r\nDoes it mean that the license is \"only\" the ImageNet license, and therefore I can use these weights and port them here?\r\nOr do you think I need to ask for extra specifications?"
            },
            {
                "commenter": "fchollet",
                "body": "This just refers to the dataset as far as I can tell. Seems fine to port them."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@fchollet @qlzh727 Ok great!\r\n\r\nI am currently in the process of porting PyTorch weights to Keras, and I am running into a bit of an issue regarding strided convolutions.\r\nI have create a colab notebook illustrating the issue: https://colab.research.google.com/drive/1iOriG0i2tGtQENVnsXrGiQ9VZlAgeOEM?usp=sharing\r\n\r\nBasically for the same weights and the same inputs, PyTorch and TensorFlow do not give the same outputs...\r\nThis is only the case for stride = 2, and not stride = 1, where the outputs are the same.\r\n\r\nI am going to investigate, but if you happen to know anything about this potential issue, let me know.\r\n\r\nIt seems that I am doing something wrong with TF, given how weirdly huge the output values are for stride = 2."
            },
            {
                "commenter": "fchollet",
                "body": "> Basically for the same weights and the same inputs, PyTorch and TensorFlow do not give the same outputs...\r\n\r\nThis may be related to padding defaults. See if you can change the padding mode."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@fchollet indeed it somehow had to do with the padding, but more precisely with which side you begin the striding on. Therefore, to compensate the difference between the 2 frameworks, we need to do an anti-symmetric padding before strided convolutions in the basic blocks, in order to be able to port PyTorch weights.\r\n\r\nI know (with a test) have the same output for the same inputs for PyTorch ResNet 18 and 34, and for the implementations in this branch.\r\n\r\n@qlzh727 Could it be possible for me to give you the weights so that you store them on GCP? I can give you a WeTransfer link of the h5 files.\r\n\r\nI will also try to run the evaluations on ImageNet, but I am quite confident since the output is the same as for PyTorch. Do you have an evaluation script I could use by any chance? Otherwise, I'll just craft my own.\r\n\r\nAlso is it the evaluation on the test set or some other set?\r\nActually I guess the validation set given this quote in [the doc](https://keras.io/api/applications/):\r\n> The top-1 and top-5 accuracy refers to the model's performance on the ImageNet validation dataset.\r\n\r\n\r\nSide note:\r\nI have a script for porting PyTorch weights into a Keras model now (architecture specific ofc but it could be interesting for some folks I guess in some situations). Is this something you would like to see cleaned up in the repo somewhere? Otherwise I'll just make a gist out of it."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@qlzh727  These are the results I obtain with my port of the PyTorch weights on the ImageNet validation set:\r\n\r\n| **ResNet size** | **Top-1 acc** | **Top-5 acc** |\r\n|-----------------|---------------|---------------|\r\n| **18**          | 0.67804       | 0.88187       |\r\n| **34**          | 0.71855       | 0.90719       |\r\n\r\nI used the following data pipeline inspired by [the PyTorch docs](https://pytorch.org/hub/pytorch_vision_resnet/) (I removed the `num_parallel_calls` to make it more readable):\r\n```python\r\nds = tfds.load(\r\n    'imagenet2012',\r\n    split='validation',\r\n    as_supervised=True,\r\n).map(\r\n    lambda x, y: (\r\n        tf.image.resize_with_crop_or_pad(tf.image.resize(x, (256, 256)), 224, 224),\r\n        y,\r\n    ),\r\n).batch(\r\n\t64,\r\n).map(\r\n    lambda x, y: (\r\n        tf.keras.applications.imagenet_utils.preprocess_input(\r\n            x, \r\n\t\t\tmode='torch',\r\n        ),\r\n        tf.one_hot(y, 1000),\r\n    ),\r\n)\r\n```\r\n\r\nTo be honest, these numbers are slightly lower than the ones reported in the PyTorch docs:\r\n\r\n| **ResNet size** | **Top-1 acc** | **Top-5 acc** |\r\n|-----------------|---------------|---------------|\r\n| **18**          | 0.6976        | 0.8908        |\r\n| **34**          | 0.733         | 0.9142        |\r\n\r\n\r\nI have verified that the network performs the same function using random inputs though. I don't know if this is satisfying enough."
            },
            {
                "commenter": "fchollet",
                "body": "I am slightly concerned that the need for manual insertion of padding operations is making the model slower, while not being necessary (it's only needed in order to be able to use the PyTorch weights checkpoint). Can you check if there is added overhead due to it on GPU or CPU? If there is, then it would seem preferable to train our own checkpoint."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "Do you mean overhead compared to PyTorch or compared to a padding within the convolution op?\r\nAnyway I can test both, but  for GPU I'll have to check if it fits on colab's ones, bc I just arrived in my new institution and I don't have access to a GPU yet (although it should be the case rather soon).\r\n\r\nI'll let you know soon enough."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@fchollet here are the overhead results on just comparing with and without padding in Keras:\r\n\r\n| **ResNet size / hardware** | **No padding** | **With padding** |\r\n|----------------------------|----------------|------------------|\r\n| **18-CPU**                 | 0.71841        | 0.7608           |\r\n| **18-GPU**                 | 0.03884        | 0.03953          |\r\n| **34-CPU**                 | 1.3042         | 1.3201           |\r\n| **34-GPU**                 | 0.06858        | 0.06718          |\r\n\r\nThese are the results when running on a `32x224x224x3` batch with a warm-up.\r\nThe CPU tests were done on my laptop. The GPU tests were done on [Colab](https://colab.research.google.com/drive/1LjFlpnDsH1zAzmQO-su39F70D1cyzkDu?usp=sharing).\r\n\r\nI don't know how much of an overhead it sounds like.\r\nIt's true that in my case I would like to have the option to not use this padding when training from scratch, but I guess a lot of folks would be happy just to have the baseline even if it's not that fast.\r\n\r\nMaybe since I cannot train the model straight away (and I would need to validate the training procedure with someone), it's okay to integrate the models as is and already have the flag, and in a second PR remove the flag with the trained weights?"
            },
            {
                "commenter": "fchollet",
                "body": "> Maybe since I cannot train the model straight away (and I would need to validate the training procedure with someone), it's okay to integrate the models as is and already have the flag, and in a second PR remove the flag with the trained weights?\r\n\r\nYes, we could do that. Thanks for checking the step timing -- the padding overhead doesn't look so bad. \r\n\r\nWe can merge this PR and then train the model and replace the weights.\r\n\r\nWould you need help with training the model? The main difficulty is finding the augmentation configuration, regularization configuration, and the learning rate schedule. If you have these (e.g. from another implementation) it's fairly straightforward to train the model on the Colab TPU runtime."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "Ok I'll just add the flag before merging.\n\nI have to say I hadn't thought about the possibility to use TPUs on Colab. It's true that it might be enough.\n\nBut you are right that the reason I was asking for help was to know how I could figure out all the training hyperparameters. Maybe going through the original paper will give me all the info I need although I doubt that but I can always check."
            },
            {
                "commenter": "fchollet",
                "body": "> I have to say I hadn't thought about the possibility to use TPUs on Colab. It's true that it might be enough.\r\n\r\nI believe it is. Happy to help you set it up, if you're interested!"
            },
            {
                "commenter": "zaccharieramzi",
                "body": "Thanks so much for the offer. I am going to try to get my hands dirty by myself a bit first, then I might come back asking for your help if I need anything re GCS or the data pipeline optimization."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@qlzh727 you can find the weights ported from PyTorch [in this WeTransfer link](https://we.tl/t-Fo1N1nGEqe). And the evaluation is [in this comment](https://github.com/keras-team/keras/pull/16363#issuecomment-1099193041).\r\n\r\n@fchollet I added the manual padding flag, so after this PR is merged I can open an issue asking to retrain the model weights without using the manual padding.\r\nMaybe you can help me there to set up the TPU training, because I am struggling with the data pipeline (see [here](https://colab.research.google.com/drive/15TtiY2Vah4-z-pmNO8riBxUG50MHv8R7?usp=sharing))."
            },
            {
                "commenter": "qlzh727",
                "body": "@zaccharieramzi, could u try to attach the weights to PR? or push it your github fork? What's the size of the weight file? "
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@qlzh727 I am not sure what you mean by attaching the weights to the PR.\r\nI cannot for example put them in a comment. I think it's because it's too heavy as a file for GitHub (the zip file for the 2 weights file is 119M).\r\nWhat's the problem with WeTransfer?\r\n\r\nI am not sure also where I should push them in the fork... I see that the other weights are all in GCS."
            },
            {
                "commenter": "qlzh727",
                "body": "> @qlzh727 I am not sure what you mean by attaching the weights to the PR. I cannot for example put them in a comment. I think it's because it's too heavy as a file for GitHub (the zip file for the 2 weights file is 119M). What's the problem with WeTransfer?\r\n> \r\n> I am not sure also where I should push them in the fork... I see that the other weights are all in GCS.\r\n\r\nI see. I guess 100M is probably too big here (for small files, eg less than 25M, you can drag/drop it in the comment, and it will be added as an attachment).\r\n\r\nI would like the file to be properly tracked, so we can have a stable place to refer it. Could u try to add the weight file to your github repo, so that we can retrieve it from a commit?"
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@qlzh727 Ok I think I did what you asked by creating 2 commits: [one that adds the weights](https://github.com/keras-team/keras/pull/16363/commits/fbeb86bc36337ba612a417e8f5c5b1a5909c9adc) and [one that removes them](https://github.com/keras-team/keras/pull/16363/commits/fb89c6b9af81b56c2bbf5702e063c8d81f79f179).\r\n\r\nTell me if it doesn't work for you."
            },
            {
                "commenter": "qlzh727",
                "body": "Thanks. Will take a look."
            },
            {
                "commenter": "fchollet",
                "body": "Note that placing files in git history can be expensive. It's often a good idea to upload files as \"release artifacts\" of a new GitHub release of the project."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "I felt that here it was not too much of a problem since we were going to squash eventually so the heavy commits would not be in the git history.\n\nBut happy to revise the git history and have the weights as release artifacts."
            },
            {
                "commenter": "KaleabTessera",
                "body": "Really looking forward to this getting in! :rocket: :fire: "
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@fchollet I finally got around to making a TPU-ImageNet-ResNet training work on Colab.\r\n\r\nWith a ResNet-50, each epoch takes ~ 20'. This will probably be much smaller for ResNet-18 and ResNet-34. So once this PR is merged, I can train them and provide the weights for a future PR.\r\n\r\nHowever, I think my script could be much faster: I am not using `steps_per_execution` in the `model.compile`, because if I do the loss becomes `nan`... If you are still down to helping me set this up, I am interested."
            },
            {
                "commenter": "qlzh727",
                "body": "Thanks for the change. I was able to verify the weights with the model. There is one particular issue for preprocessing. In your sample code, it was using \r\n\r\n```\r\ntf.keras.applications.imagenet_utils.preprocess_input(\r\n            image,  mode='torch')\r\n```\r\n\r\nwhich is different from `tf.keras.applications.resnet.preprocess_input(image)`. If we use this, the acc reduced to less than 1%. \r\n\r\nI think this will be a big issue since the preprocessing logic lives outside of model, and we can't easily warn user about what's the range of value we are expecting. I think we should consolidate all the weights into one format (and seems that all the resnet v1 weights are converted from caffe.)\r\n"
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@qlzh727 Indeed since I am porting from PyTorch I needed to use their preprocessing.\r\nI was not able to find the weights of the resnet34 in caffe, and the resnet18 weights appear to be only available [here](https://github.com/HolmesShuan/ResNet-18-Caffemodel-on-ImageNet).\r\n\r\nHere are my tentative answers:\r\n- Since anyway we wanted to retrain the models (cf this [comment](https://github.com/keras-team/keras/pull/16363#issuecomment-1100793061)), it's only going to be a temporary issue. We can simply document it well, in particular in the model and preprocessing docs. There could by the way be a `tf.keras.applications.resnet18.preprocess_input` similarly [to what exists for resnet50](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/preprocess_input).\r\n- In the current state we could do the correction of preprocessing in the model, before retraining.\r\n\r\nIf however, you have at your disposal the caffe weights for both models (and by any chance the script to port them), I can definitely do the porting, and checks."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "I just found out something about the way torch applies batch norm at eval time that might explain the difference in accuracy I noticed [here](https://github.com/keras-team/keras/pull/16363#issuecomment-1099193041).\r\n\r\nYou can read about it [here](https://github.com/pytorch/pytorch/issues/77427)."
            },
            {
                "commenter": "KaleabTessera",
                "body": "Any progress on this? This would be really great to have! "
            },
            {
                "commenter": "gbaned",
                "body": "@zaccharieramzi Can you please resolve conflicts? Thank you!"
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@gbaned should be done"
            },
            {
                "commenter": "qlzh727",
                "body": "Sorry for the long wait, since end user could easily miss the preprocess API with pytorch format, how about we include the preprocess as part of the model, and control it via a `include_preprocessing ` flag on the model. We have take this approach for several other models in the applications. "
            },
            {
                "commenter": "LukeWood",
                "body": "> Sorry for the long wait, since end user could easily miss the preprocess API with pytorch format, how about we include the preprocess as part of the model, and control it via a `include_preprocessing ` flag on the model. We have take this approach for several other models in the applications.\r\n\r\nDue to the fact that the model requires a different preprocessing for inputs in the inputs between the ResNet18/34 and the other ResNets, we would probably need to re-train these weights.  Let's migrate this to a PR on keras-cv.  Please send a pull request to KerasCV, and place the model in the models package: \r\n\r\nhttps://github.com/keras-team/keras-cv/tree/master/keras_cv/models\r\n\r\nfrom there, we can retrain the models"
            },
            {
                "commenter": "zaccharieramzi",
                "body": "@LukeWood sure, opening this PR https://github.com/keras-team/keras-cv/pull/805"
            },
            {
                "commenter": "fchollet",
                "body": "> @LukeWood sure, opening this PR https://github.com/keras-team/keras-cv/pull/805\r\n\r\nThank you. Let's move to the discussion to the KerasCV PR."
            },
            {
                "commenter": "zaccharieramzi",
                "body": "Just mentioning for those following the conversation that the [corresponding PR in keras-cv](https://github.com/keras-team/keras-cv/pull/805#event-7441560537) has been merged."
            }
        ]
    }
]