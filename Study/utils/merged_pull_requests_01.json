[
    {
        "repo": "numpy/numpy",
        "pr_number": 24560,
        "body": "The changed jobs are:\r\n- The `basic` job was de-matrixed (the basic Python 3.9 job served no purpose, duplicate with other jobs) and rename to be specifically for PyPy\r\n- The `debug` job (this was straightforward)\r\n- The `benchmark` job (this one was broken in many ways, and the benchmarks weren't even running before despite the job being green)\r\n\r\nMaking the `benchmark` job run uncovered a ton of warnings and bugs in both our benchmark suite and in `asv`. Everything should work after this PR with `asv` 0.6 (a recent release), some open issues in `asv` are worked around. The fixes were mostly in these categories:\r\n- Avoid using deprecated or removed APIs\r\n- Avoid raising `NotImplementedError` where possible - this is extremely noisy, because `spin bench` will show stderr output (that is a good idea, because it should run cleanly) - and instead split up benchmarks to avoid trying unsupported dtypes/values,\r\n- Remove long double types from the default list of types in `common.py`. They caused a lot of problems, and they're not very interesting dtypes to test that extensively. For the few performance-critical ops, whoever cares can write a dedicated benchmark,\r\n- Reduce the level of parametrization of a number of tests. This is a good idea for at least two reasons: reduce runtime, and keep the CI log output reasonable (it went from >50,000 lines with all the warnings and heavy parametrization to ~8.000 lines) \r\n- `spin bench` improvements:\r\n  - ensure the exit code is always propagated so that when benchmarks fail the CI job fails, and\r\n  - add a `--quick` option to `spin bench` - necessary to make the CI job run in a reasonable amount of time.\r\n\r\n",
        "changed_files": [
            {
                "filename": ".github/workflows/linux.yml",
                "patch": "@@ -64,41 +64,50 @@ jobs:\n         python-version: '3.9'\n     - uses: ./.github/meson_actions\n \n-  basic:\n+  pypy:\n     needs: [smoke_test]\n     runs-on: ubuntu-latest\n     if: github.event_name != 'push'\n-    strategy:\n-      matrix:\n-        python-version: [\"3.9\", \"pypy3.9-v7.3.12\"]\n-    env:\n-      EXPECT_CPU_FEATURES: \"SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_KNL AVX512_KNM AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL\"\n     steps:\n     - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3.6.0\n       with:\n         submodules: recursive\n         fetch-depth: 0\n     - uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1 # v4.7.0\n       with:\n-        python-version: ${{ matrix.python-version }}\n-    - uses: ./.github/actions\n+        python-version: 'pypy3.9-v7.3.12'\n+    - name: Install system dependencies\n+      run: |\n+        sudo apt-get install libopenblas-dev ninja-build\n+    - uses: ./.github/meson_actions\n \n   debug:\n     needs: [smoke_test]\n     runs-on: ubuntu-latest\n     if: github.event_name != 'push'\n-    env:\n-      USE_DEBUG: 1\n     steps:\n     - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3.6.0\n       with:\n         submodules: recursive\n         fetch-depth: 0\n-    - uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1 # v4.7.0\n-      with:\n-        python-version: '3.11'\n-\n-    - uses: ./.github/actions\n+    - name: Install debug Python\n+      run: |\n+        sudo apt-get install python3-dbg ninja-build\n+    - name: Build NumPy and install into venv\n+      run: |\n+        python3-dbg -m venv venv\n+        source venv/bin/activate\n+        pip install -U pip\n+        pip install . -v -Csetup-args=-Dbuildtype=debug -Csetup-args=-Dallow-noblas=true\n+    - name: Install test dependencies\n+      run: |\n+        source venv/bin/activate\n+        pip install -r test_requirements.txt\n+    - name: Run test suite\n+      run: |\n+        source venv/bin/activate\n+        cd tools\n+        pytest --pyargs numpy -m \"not slow\"\n \n   full:\n     # Build a wheel, install it, then run the full test suite with code coverage\n@@ -137,14 +146,6 @@ jobs:\n     needs: [smoke_test]\n     runs-on: ubuntu-latest\n     if: github.event_name != 'push'\n-    env:\n-      PYTHONOPTIMIZE: 2\n-      BLAS: None\n-      LAPACK: None\n-      ATLAS: None\n-      NPY_BLAS_ORDER: mkl,blis,openblas,atlas,blas\n-      NPY_LAPACK_ORDER: MKL,OPENBLAS,ATLAS,LAPACK\n-      USE_ASV: 1\n     steps:\n     - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3.6.0\n       with:\n@@ -153,7 +154,23 @@ jobs:\n     - uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1 # v4.7.0\n       with:\n         python-version: '3.9'\n-    - uses: ./.github/actions\n+    - name: Install build and benchmarking dependencies\n+      run: |\n+        sudo apt-get install libopenblas-dev ninja-build\n+        pip install spin cython asv virtualenv packaging\n+    - name: Install NumPy\n+      run: |\n+        spin build -- -Dcpu-dispatch=none\n+    # Ensure to keep the below steps as single-line bash commands (it's a\n+    # workaround for asv#1333, and it may have side-effects on multi-line commands)\n+    - name: Appease asv's need for machine info\n+      shell: 'script -q -e -c \"bash --noprofile --norc -eo pipefail {0}\"'\n+      run: |\n+        asv machine --yes --config benchmarks/asv.conf.json\n+    - name: Run benchmarks\n+      shell: 'script -q -e -c \"bash --noprofile --norc -eo pipefail {0}\"'\n+      run: |\n+        spin bench --quick\n \n   relaxed_strides_debug:\n     needs: [smoke_test]"
            },
            {
                "filename": ".spin/cmds.py",
                "patch": "@@ -303,19 +303,7 @@ def _run_asv(cmd):\n     except (ImportError, RuntimeError):\n         pass\n \n-    try:\n-        util.run(cmd, cwd='benchmarks', env=env, sys_exit=False)\n-    except FileNotFoundError:\n-        click.secho((\n-            \"Cannot find `asv`. \"\n-            \"Please install Airspeed Velocity:\\n\\n\"\n-            \"  https://asv.readthedocs.io/en/latest/installing.html\\n\"\n-            \"\\n\"\n-            \"Depending on your system, one of the following should work:\\n\\n\"\n-            \"  pip install asv\\n\"\n-            \"  conda install asv\\n\"\n-        ), fg=\"red\")\n-        sys.exit(1)\n+    util.run(cmd, cwd='benchmarks', env=env)\n \n \n @click.command()\n@@ -336,13 +324,17 @@ def _run_asv(cmd):\n @click.option(\n     '--verbose', '-v', is_flag=True, default=False\n )\n+@click.option(\n+    '--quick', '-q', is_flag=True, default=False,\n+    help=\"Run each benchmark only once (timings won't be accurate)\"\n+)\n @click.argument(\n     'commits', metavar='',\n     required=False,\n     nargs=-1\n )\n @click.pass_context\n-def bench(ctx, tests, compare, verbose, commits):\n+def bench(ctx, tests, compare, verbose, quick, commits):\n     \"\"\"\ud83c\udfcb Run benchmarks.\n \n     \\b\n@@ -382,6 +374,9 @@ def bench(ctx, tests, compare, verbose, commits):\n     if verbose:\n         bench_args = ['-v'] + bench_args\n \n+    if quick:\n+        bench_args = ['--quick'] + bench_args\n+\n     if not compare:\n         # No comparison requested; we build and benchmark the current version\n \n@@ -409,27 +404,21 @@ def bench(ctx, tests, compare, verbose, commits):\n         cmd = [\n             'asv', 'run', '--dry-run', '--show-stderr', '--python=same'\n         ] + bench_args\n-\n         _run_asv(cmd)\n-\n     else:\n-        # Benchmark comparison\n-\n         # Ensure that we don't have uncommited changes\n         commit_a, commit_b = [_commit_to_sha(c) for c in commits]\n \n-        if commit_b == 'HEAD':\n-            if _dirty_git_working_dir():\n-                click.secho(\n-                    \"WARNING: you have uncommitted changes --- \"\n-                    \"these will NOT be benchmarked!\",\n-                    fg=\"red\"\n-                )\n+        if commit_b == 'HEAD' and _dirty_git_working_dir():\n+            click.secho(\n+                \"WARNING: you have uncommitted changes --- \"\n+                \"these will NOT be benchmarked!\",\n+                fg=\"red\"\n+            )\n \n         cmd_compare = [\n             'asv', 'continuous', '--factor', '1.05',\n         ] + bench_args + [commit_a, commit_b]\n-\n         _run_asv(cmd_compare)\n \n "
            },
            {
                "filename": "benchmarks/benchmarks/bench_core.py",
                "patch": "@@ -217,19 +217,13 @@ def time_indices(self):\n \n \n class StatsMethods(Benchmark):\n-    # Not testing, but in array_api (redundant)\n-    # 8, 16, 32 bit variants, and 128 complexes\n-    params = [['int64', 'uint64', 'float64', 'intp',\n-               'complex64', 'bool', 'float', 'int',\n-               'complex', 'complex256'],\n-              [100**n for n in range(0, 2)]]\n+    params = [['int64', 'uint64', 'float32', 'float64',\n+               'complex64', 'bool_'],\n+              [100, 10000]]\n     param_names = ['dtype', 'size']\n \n     def setup(self, dtype, size):\n-        try:\n-            self.data = np.ones(size, dtype=getattr(np, dtype))\n-        except AttributeError:  # builtins throw AttributeError after 1.20\n-            self.data = np.ones(size, dtype=dtype)\n+        self.data = np.ones(size, dtype=dtype)\n         if dtype.startswith('complex'):\n             self.data = np.random.randn(size) + 1j * np.random.randn(size)\n "
            },
            {
                "filename": "benchmarks/benchmarks/bench_creation.py",
                "patch": "@@ -1,4 +1,4 @@\n-from .common import Benchmark, TYPES1\n+from .common import Benchmark, TYPES1, get_squares_\n \n import numpy as np\n \n@@ -23,57 +23,49 @@ def time_meshgrid(self, size, ndims, ind, ndtype):\n class Create(Benchmark):\n     \"\"\" Benchmark for creation functions\n     \"\"\"\n-    # (64, 64), (128, 128), (256, 256)\n-    # , (512, 512), (1024, 1024)\n-    params = [[16, 32, 128, 256, 512,\n-               (16, 16), (32, 32)],\n-              ['C', 'F'],\n+    params = [[16, 512, (32, 32)],\n               TYPES1]\n-    param_names = ['shape', 'order', 'npdtypes']\n+    param_names = ['shape', 'npdtypes']\n     timeout = 10\n \n-    def setup(self, shape, order, npdtypes):\n+    def setup(self, shape, npdtypes):\n         values = get_squares_()\n         self.xarg = values.get(npdtypes)[0]\n \n-    def time_full(self, shape, order, npdtypes):\n-        np.full(shape, self.xarg[1], dtype=npdtypes, order=order)\n+    def time_full(self, shape, npdtypes):\n+        np.full(shape, self.xarg[1], dtype=npdtypes)\n \n-    def time_full_like(self, shape, order, npdtypes):\n-        np.full_like(self.xarg, self.xarg[0], order=order)\n+    def time_full_like(self, shape, npdtypes):\n+        np.full_like(self.xarg, self.xarg[0])\n \n-    def time_ones(self, shape, order, npdtypes):\n-        np.ones(shape, dtype=npdtypes, order=order)\n+    def time_ones(self, shape, npdtypes):\n+        np.ones(shape, dtype=npdtypes)\n \n-    def time_ones_like(self, shape, order, npdtypes):\n-        np.ones_like(self.xarg, order=order)\n+    def time_ones_like(self, shape, npdtypes):\n+        np.ones_like(self.xarg)\n \n-    def time_zeros(self, shape, order, npdtypes):\n-        np.zeros(shape, dtype=npdtypes, order=order)\n+    def time_zeros(self, shape, npdtypes):\n+        np.zeros(shape, dtype=npdtypes)\n \n-    def time_zeros_like(self, shape, order, npdtypes):\n-        np.zeros_like(self.xarg, order=order)\n+    def time_zeros_like(self, shape, npdtypes):\n+        np.zeros_like(self.xarg)\n \n-    def time_empty(self, shape, order, npdtypes):\n-        np.empty(shape, dtype=npdtypes, order=order)\n+    def time_empty(self, shape, npdtypes):\n+        np.empty(shape, dtype=npdtypes)\n \n-    def time_empty_like(self, shape, order, npdtypes):\n-        np.empty_like(self.xarg, order=order)\n+    def time_empty_like(self, shape, npdtypes):\n+        np.empty_like(self.xarg)\n \n \n class UfuncsFromDLP(Benchmark):\n     \"\"\" Benchmark for creation functions\n     \"\"\"\n-    params = [[16, 32, (16, 16),\n-               (32, 32), (64, 64)],\n+    params = [[16, 32, (16, 16), (64, 64)],\n               TYPES1]\n     param_names = ['shape', 'npdtypes']\n     timeout = 10\n \n     def setup(self, shape, npdtypes):\n-        if npdtypes in ['longdouble', 'clongdouble']:\n-            raise NotImplementedError(\n-                'Only IEEE dtypes are supported')\n         values = get_squares_()\n         self.xarg = values.get(npdtypes)[0]\n "
            },
            {
                "filename": "benchmarks/benchmarks/bench_itemselection.py",
                "patch": "@@ -5,7 +5,7 @@\n \n class Take(Benchmark):\n     params = [\n-        [(1000, 1), (1000, 2), (2, 1000, 1), (1000, 3)],\n+        [(1000, 1), (2, 1000, 1), (1000, 3)],\n         [\"raise\", \"wrap\", \"clip\"],\n         TYPES1 + [\"O\", \"i,O\"]]\n     param_names = [\"shape\", \"mode\", \"dtype\"]"
            },
            {
                "filename": "benchmarks/benchmarks/bench_linalg.py",
                "patch": "@@ -72,37 +72,39 @@ def time_tensordot_a_b_axes_1_0_0_1(self):\n \n \n class Linalg(Benchmark):\n-    params = [['svd', 'pinv', 'det', 'norm'],\n-              TYPES1]\n-    param_names = ['op', 'type']\n+    params = set(TYPES1) - set(['float16'])\n+    param_names = ['dtype']\n \n-    def setup(self, op, typename):\n+    def setup(self, typename):\n         np.seterr(all='ignore')\n+        self.a = get_squares_()[typename]\n+\n+    def time_svd(self, typename):\n+        np.linalg.svd(self.a)\n+\n+    def time_pinv(self, typename):\n+        np.linalg.pinv(self.a)\n \n-        self.func = getattr(np.linalg, op)\n+    def time_det(self, typename):\n+        np.linalg.det(self.a)\n \n-        if op == 'cholesky':\n-            # we need a positive definite\n-            self.a = np.dot(get_squares_()[typename],\n-                            get_squares_()[typename].T)\n-        else:\n-            self.a = get_squares_()[typename]\n \n-        # check that dtype is supported at all\n-        try:\n-            self.func(self.a[:2, :2])\n-        except TypeError as e:\n-            raise NotImplementedError() from e\n+class LinalgNorm(Benchmark):\n+    params = TYPES1\n+    param_names = ['dtype']\n+\n+    def setup(self, typename):\n+        self.a = get_squares_()[typename]\n \n-    def time_op(self, op, typename):\n-        self.func(self.a)\n+    def time_norm(self, typename):\n+        np.linalg.norm(self.a)\n \n \n class LinalgSmallArrays(Benchmark):\n     \"\"\" Test overhead of linalg methods for small arrays \"\"\"\n     def setup(self):\n         self.array_5 = np.arange(5.)\n-        self.array_5_5 = np.reshape(np.arange(25.), (5., 5.))\n+        self.array_5_5 = np.reshape(np.arange(25.), (5, 5))\n \n     def time_norm_small_array(self):\n         np.linalg.norm(self.array_5)"
            },
            {
                "filename": "benchmarks/benchmarks/bench_ma.py",
                "patch": "@@ -128,10 +128,10 @@ class MAFunctions1v(Benchmark):\n               ['small', 'big']]\n \n     def setup(self, mtype, func, msize):\n-        xs = np.random.uniform(-1, 1, 6).reshape(2, 3)\n+        xs = 2.0 + np.random.uniform(-1, 1, 6).reshape(2, 3)\n         m1 = [[True, False, False], [False, False, True]]\n-        xl = np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n-        maskx = xl > 0.8\n+        xl = 2.0 + np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n+        maskx = xl > 2.8\n         self.nmxs = np.ma.array(xs, mask=m1)\n         self.nmxl = np.ma.array(xl, mask=maskx)\n \n@@ -173,17 +173,17 @@ class MAFunctions2v(Benchmark):\n \n     def setup(self, mtype, func, msize):\n         # Small arrays\n-        xs = np.random.uniform(-1, 1, 6).reshape(2, 3)\n-        ys = np.random.uniform(-1, 1, 6).reshape(2, 3)\n+        xs = 2.0 + np.random.uniform(-1, 1, 6).reshape(2, 3)\n+        ys = 2.0 + np.random.uniform(-1, 1, 6).reshape(2, 3)\n         m1 = [[True, False, False], [False, False, True]]\n         m2 = [[True, False, True], [False, False, True]]\n         self.nmxs = np.ma.array(xs, mask=m1)\n         self.nmys = np.ma.array(ys, mask=m2)\n         # Big arrays\n-        xl = np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n-        yl = np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n-        maskx = xl > 0.8\n-        masky = yl < -0.8\n+        xl = 2.0 + np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n+        yl = 2.0 + np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n+        maskx = xl > 2.8\n+        masky = yl < 1.8\n         self.nmxl = np.ma.array(xl, mask=maskx)\n         self.nmyl = np.ma.array(yl, mask=masky)\n "
            },
            {
                "filename": "benchmarks/benchmarks/bench_manipulate.py",
                "patch": "@@ -4,9 +4,7 @@\n from collections import deque\n \n class BroadcastArrays(Benchmark):\n-    params = [[(16, 32), (32, 64),\n-               (64, 128), (128, 256),\n-               (256, 512), (512, 1024)],\n+    params = [[(16, 32), (128, 256), (512, 1024)],\n               TYPES1]\n     param_names = ['shape', 'ndtype']\n     timeout = 10\n@@ -22,7 +20,7 @@ def time_broadcast_arrays(self, shape, ndtype):\n \n \n class BroadcastArraysTo(Benchmark):\n-    params = [[16, 32, 64, 128, 256, 512],\n+    params = [[16, 64, 512],\n               TYPES1]\n     param_names = ['size', 'ndtype']\n     timeout = 10\n@@ -39,9 +37,8 @@ def time_broadcast_to(self, size, ndtype):\n \n \n class ConcatenateStackArrays(Benchmark):\n-    # (64, 128), (128, 256), (256, 512)\n     params = [[(16, 32), (32, 64)],\n-              [2, 3, 4, 5],\n+              [2, 5],\n               TYPES1]\n     param_names = ['shape', 'narrays', 'ndtype']\n     timeout = 10"
            },
            {
                "filename": "benchmarks/benchmarks/bench_reduce.py",
                "patch": "@@ -46,18 +46,11 @@ def time_any_slow(self):\n \n \n class StatsReductions(Benchmark):\n-    # Not testing, but in array_api (redundant)\n-    # 8, 16, 32 bit variants, and 128 complexes\n-    params = ['int64', 'uint64', 'float64', 'intp',\n-               'complex64', 'bool', 'float', 'int',\n-               'complex', 'complex256'],\n+    params = ['int64', 'uint64', 'float32', 'float64', 'complex64', 'bool_'],\n     param_names = ['dtype']\n \n     def setup(self, dtype):\n-        try:\n-            self.data = np.ones(200, dtype=getattr(np, dtype))\n-        except AttributeError:  # builtins throw AttributeError after 1.20\n-            self.data = np.ones(200, dtype=dtype)\n+        self.data = np.ones(200, dtype=dtype)\n         if dtype.startswith('complex'):\n             self.data = self.data * self.data.T*1j\n "
            },
            {
                "filename": "benchmarks/benchmarks/bench_shape_base.py",
                "patch": "@@ -68,7 +68,7 @@ def time_no_lists(self, n):\n \n \n class Block2D(Benchmark):\n-    params = [[(16, 16), (32, 32), (64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)],\n+    params = [[(16, 16), (64, 64), (256, 256), (1024, 1024)],\n               ['uint8', 'uint16', 'uint32', 'uint64'],\n               [(2, 2), (4, 4)]]\n     param_names = ['shape', 'dtype', 'n_chunks']"
            },
            {
                "filename": "benchmarks/benchmarks/bench_ufunc.py",
                "patch": "@@ -135,47 +135,98 @@ def time_ndarray_meth(self, methname, npdtypes):\n         getattr(operator, methname)(*[self.vals, 2])\n \n \n-class Methods0D(Benchmark):\n+class Methods0DBoolComplex(Benchmark):\n     \"\"\"Zero dimension array methods\n     \"\"\"\n-    params = [['__bool__', '__complex__', '__invert__',\n-               '__float__', '__int__'], TYPES1]\n+    params = [['__bool__', '__complex__'],\n+              TYPES1]\n+    param_names = ['methods', 'npdtypes']\n+    timeout = 10\n+\n+    def setup(self, methname, npdtypes):\n+        self.xarg = np.array(3, dtype=npdtypes)\n+\n+    def time_ndarray__0d__(self, methname, npdtypes):\n+        meth = getattr(self.xarg, methname)\n+        meth()\n+\n+\n+class Methods0DFloatInt(Benchmark):\n+    \"\"\"Zero dimension array methods\n+    \"\"\"\n+    params = [['__int__', '__float__'],\n+              [dt for dt in TYPES1 if not dt.startswith('complex')]]\n     param_names = ['methods', 'npdtypes']\n     timeout = 10\n \n     def setup(self, methname, npdtypes):\n         self.xarg = np.array(3, dtype=npdtypes)\n-        if (npdtypes.startswith('complex') and\n-           methname in ['__float__', '__int__']) or \\\n-           (npdtypes.startswith('int') and methname == '__invert__'):\n-            # Skip\n-            raise NotImplementedError\n \n     def time_ndarray__0d__(self, methname, npdtypes):\n         meth = getattr(self.xarg, methname)\n         meth()\n \n \n+class Methods0DInvert(Benchmark):\n+    \"\"\"Zero dimension array methods\n+    \"\"\"\n+    params = ['int16', 'int32', 'int64']\n+    param_names = ['npdtypes']\n+    timeout = 10\n+\n+    def setup(self, npdtypes):\n+        self.xarg = np.array(3, dtype=npdtypes)\n+\n+    def time_ndarray__0d__(self, npdtypes):\n+        self.xarg.__invert__()\n+\n+\n class MethodsV1(Benchmark):\n     \"\"\" Benchmark for the methods which take an argument\n     \"\"\"\n-    params = [['__and__', '__add__', '__eq__', '__floordiv__', '__ge__',\n-               '__gt__', '__le__', '__lt__', '__matmul__',\n-               '__mod__', '__mul__', '__ne__', '__or__',\n-               '__pow__', '__sub__', '__truediv__', '__xor__'],\n+    params = [['__add__', '__eq__', '__ge__', '__gt__', '__le__',\n+               '__lt__', '__matmul__', '__mul__', '__ne__',\n+               '__pow__', '__sub__', '__truediv__'],\n               TYPES1]\n     param_names = ['methods', 'npdtypes']\n     timeout = 10\n \n     def setup(self, methname, npdtypes):\n-        if (\n-            npdtypes.startswith(\"complex\")\n-                and methname in [\"__floordiv__\", \"__mod__\"]\n-        ) or (\n-            not npdtypes.startswith(\"int\")\n-            and methname in [\"__and__\", \"__or__\", \"__xor__\"]\n-        ):\n-            raise NotImplementedError  # skip\n+        values = get_squares_().get(npdtypes)\n+        self.xargs = [values[0], values[1]]\n+        if np.issubdtype(npdtypes, np.inexact):\n+            # avoid overflow in __pow__/__matmul__ for low-precision dtypes\n+            self.xargs[1] *= 0.01\n+\n+    def time_ndarray_meth(self, methname, npdtypes):\n+        getattr(operator, methname)(*self.xargs)\n+\n+\n+class MethodsV1IntOnly(Benchmark):\n+    \"\"\" Benchmark for the methods which take an argument\n+    \"\"\"\n+    params = [['__and__', '__or__', '__xor__'],\n+              ['int16', 'int32', 'int64']]\n+    param_names = ['methods', 'npdtypes']\n+    timeout = 10\n+\n+    def setup(self, methname, npdtypes):\n+        values = get_squares_().get(npdtypes)\n+        self.xargs = [values[0], values[1]]\n+\n+    def time_ndarray_meth(self, methname, npdtypes):\n+        getattr(operator, methname)(*self.xargs)\n+\n+\n+class MethodsV1NoComplex(Benchmark):\n+    \"\"\" Benchmark for the methods which take an argument\n+    \"\"\"\n+    params = [['__floordiv__', '__mod__'],\n+              [dt for dt in TYPES1 if not dt.startswith('complex')]]\n+    param_names = ['methods', 'npdtypes']\n+    timeout = 10\n+\n+    def setup(self, methname, npdtypes):\n         values = get_squares_().get(npdtypes)\n         self.xargs = [values[0], values[1]]\n \n@@ -391,25 +442,36 @@ def time_less_than_scalar2(self, dtype):\n \n \n class CustomScalarFloorDivideInt(Benchmark):\n-    params = (np.core.sctypes['int'] + \n-              np.core.sctypes['uint'], [8, -8, 43, -43])\n+    params = (np.core.sctypes['int'],\n+              [8, -8, 43, -43])\n     param_names = ['dtype', 'divisors']\n \n     def setup(self, dtype, divisor):\n-        if dtype in np.core.sctypes['uint'] and divisor < 0:\n-            raise NotImplementedError(\n-                    \"Skipping test for negative divisor with unsigned type\")\n-\n         iinfo = np.iinfo(dtype)\n         self.x = np.random.randint(\n                     iinfo.min, iinfo.max, size=10000, dtype=dtype)\n \n     def time_floor_divide_int(self, dtype, divisor):\n         self.x // divisor\n \n+\n+class CustomScalarFloorDivideUInt(Benchmark):\n+    params = (np.core.sctypes['uint'],\n+              [8, 43])\n+    param_names = ['dtype', 'divisors']\n+\n+    def setup(self, dtype, divisor):\n+        iinfo = np.iinfo(dtype)\n+        self.x = np.random.randint(\n+                    iinfo.min, iinfo.max, size=10000, dtype=dtype)\n+\n+    def time_floor_divide_uint(self, dtype, divisor):\n+        self.x // divisor\n+\n+\n class CustomArrayFloorDivideInt(Benchmark):\n-    params = (np.core.sctypes['int'] + \n-              np.core.sctypes['uint'], [100, 10000, 1000000])\n+    params = (np.core.sctypes['int'] + np.core.sctypes['uint'],\n+              [100, 10000, 1000000])\n     param_names = ['dtype', 'size']\n \n     def setup(self, dtype, size):"
            },
            {
                "filename": "benchmarks/benchmarks/bench_ufunc_strides.py",
                "patch": "@@ -100,7 +100,10 @@ def time_unary(self, ufunc, stride_in, stride_out, dtype):\n         ufunc(*self.ufunc_args)\n \n class UnaryFP(_AbstractUnary):\n-    params = [UFUNCS_UNARY, [1, 2, 4], [1, 2, 4], ['e', 'f', 'd']]\n+    params = [[uf for uf in UFUNCS_UNARY if uf != np.invert],\n+              [1, 4],\n+              [1, 2],\n+              ['e', 'f', 'd']]\n \n     def setup(self, ufunc, stride_in, stride_out, dtype):\n         _AbstractUnary.setup(self, ufunc, stride_in, stride_out, dtype)\n@@ -115,7 +118,7 @@ class UnaryFPSpecial(UnaryFP):\n class BinaryFP(_AbstractBinary):\n     params = [\n         [np.maximum, np.minimum, np.fmax, np.fmin, np.ldexp],\n-        [1, 2, 4], [1, 2, 4], [1, 2, 4], ['f', 'd']\n+        [1, 2], [1, 4], [1, 2, 4], ['f', 'd']\n     ]\n \n class BinaryFPSpecial(BinaryFP):"
            },
            {
                "filename": "benchmarks/benchmarks/common.py",
                "patch": "@@ -22,10 +22,8 @@\n     'int16', 'float16',\n     'int32', 'float32',\n     'int64', 'float64',  'complex64',\n-    'longdouble', 'complex128',\n+    'complex128',\n ]\n-if 'complex256' in np.core.sctypeDict:\n-    TYPES1.append('clongdouble')\n \n DLPACK_TYPES = [\n     'int16', 'float16',"
            }
        ],
        "diff": "diff --git a/.github/workflows/linux.yml b/.github/workflows/linux.yml\nindex 8b944899304..17f9e000db0 100644\n--- a/.github/workflows/linux.yml\n+++ b/.github/workflows/linux.yml\n@@ -64,15 +64,10 @@ jobs:\n         python-version: '3.9'\n     - uses: ./.github/meson_actions\n \n-  basic:\n+  pypy:\n     needs: [smoke_test]\n     runs-on: ubuntu-latest\n     if: github.event_name != 'push'\n-    strategy:\n-      matrix:\n-        python-version: [\"3.9\", \"pypy3.9-v7.3.12\"]\n-    env:\n-      EXPECT_CPU_FEATURES: \"SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_KNL AVX512_KNM AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL\"\n     steps:\n     - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3.6.0\n       with:\n@@ -80,25 +75,39 @@ jobs:\n         fetch-depth: 0\n     - uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1 # v4.7.0\n       with:\n-        python-version: ${{ matrix.python-version }}\n-    - uses: ./.github/actions\n+        python-version: 'pypy3.9-v7.3.12'\n+    - name: Install system dependencies\n+      run: |\n+        sudo apt-get install libopenblas-dev ninja-build\n+    - uses: ./.github/meson_actions\n \n   debug:\n     needs: [smoke_test]\n     runs-on: ubuntu-latest\n     if: github.event_name != 'push'\n-    env:\n-      USE_DEBUG: 1\n     steps:\n     - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3.6.0\n       with:\n         submodules: recursive\n         fetch-depth: 0\n-    - uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1 # v4.7.0\n-      with:\n-        python-version: '3.11'\n-\n-    - uses: ./.github/actions\n+    - name: Install debug Python\n+      run: |\n+        sudo apt-get install python3-dbg ninja-build\n+    - name: Build NumPy and install into venv\n+      run: |\n+        python3-dbg -m venv venv\n+        source venv/bin/activate\n+        pip install -U pip\n+        pip install . -v -Csetup-args=-Dbuildtype=debug -Csetup-args=-Dallow-noblas=true\n+    - name: Install test dependencies\n+      run: |\n+        source venv/bin/activate\n+        pip install -r test_requirements.txt\n+    - name: Run test suite\n+      run: |\n+        source venv/bin/activate\n+        cd tools\n+        pytest --pyargs numpy -m \"not slow\"\n \n   full:\n     # Build a wheel, install it, then run the full test suite with code coverage\n@@ -137,14 +146,6 @@ jobs:\n     needs: [smoke_test]\n     runs-on: ubuntu-latest\n     if: github.event_name != 'push'\n-    env:\n-      PYTHONOPTIMIZE: 2\n-      BLAS: None\n-      LAPACK: None\n-      ATLAS: None\n-      NPY_BLAS_ORDER: mkl,blis,openblas,atlas,blas\n-      NPY_LAPACK_ORDER: MKL,OPENBLAS,ATLAS,LAPACK\n-      USE_ASV: 1\n     steps:\n     - uses: actions/checkout@f43a0e5ff2bd294095638e18286ca9a3d1956744 # v3.6.0\n       with:\n@@ -153,7 +154,23 @@ jobs:\n     - uses: actions/setup-python@61a6322f88396a6271a6ee3565807d608ecaddd1 # v4.7.0\n       with:\n         python-version: '3.9'\n-    - uses: ./.github/actions\n+    - name: Install build and benchmarking dependencies\n+      run: |\n+        sudo apt-get install libopenblas-dev ninja-build\n+        pip install spin cython asv virtualenv packaging\n+    - name: Install NumPy\n+      run: |\n+        spin build -- -Dcpu-dispatch=none\n+    # Ensure to keep the below steps as single-line bash commands (it's a\n+    # workaround for asv#1333, and it may have side-effects on multi-line commands)\n+    - name: Appease asv's need for machine info\n+      shell: 'script -q -e -c \"bash --noprofile --norc -eo pipefail {0}\"'\n+      run: |\n+        asv machine --yes --config benchmarks/asv.conf.json\n+    - name: Run benchmarks\n+      shell: 'script -q -e -c \"bash --noprofile --norc -eo pipefail {0}\"'\n+      run: |\n+        spin bench --quick\n \n   relaxed_strides_debug:\n     needs: [smoke_test]\ndiff --git a/.spin/cmds.py b/.spin/cmds.py\nindex f97292edecd..81cfb9d22cf 100644\n--- a/.spin/cmds.py\n+++ b/.spin/cmds.py\n@@ -303,19 +303,7 @@ def _run_asv(cmd):\n     except (ImportError, RuntimeError):\n         pass\n \n-    try:\n-        util.run(cmd, cwd='benchmarks', env=env, sys_exit=False)\n-    except FileNotFoundError:\n-        click.secho((\n-            \"Cannot find `asv`. \"\n-            \"Please install Airspeed Velocity:\\n\\n\"\n-            \"  https://asv.readthedocs.io/en/latest/installing.html\\n\"\n-            \"\\n\"\n-            \"Depending on your system, one of the following should work:\\n\\n\"\n-            \"  pip install asv\\n\"\n-            \"  conda install asv\\n\"\n-        ), fg=\"red\")\n-        sys.exit(1)\n+    util.run(cmd, cwd='benchmarks', env=env)\n \n \n @click.command()\n@@ -336,13 +324,17 @@ def _run_asv(cmd):\n @click.option(\n     '--verbose', '-v', is_flag=True, default=False\n )\n+@click.option(\n+    '--quick', '-q', is_flag=True, default=False,\n+    help=\"Run each benchmark only once (timings won't be accurate)\"\n+)\n @click.argument(\n     'commits', metavar='',\n     required=False,\n     nargs=-1\n )\n @click.pass_context\n-def bench(ctx, tests, compare, verbose, commits):\n+def bench(ctx, tests, compare, verbose, quick, commits):\n     \"\"\"\ud83c\udfcb Run benchmarks.\n \n     \\b\n@@ -382,6 +374,9 @@ def bench(ctx, tests, compare, verbose, commits):\n     if verbose:\n         bench_args = ['-v'] + bench_args\n \n+    if quick:\n+        bench_args = ['--quick'] + bench_args\n+\n     if not compare:\n         # No comparison requested; we build and benchmark the current version\n \n@@ -409,27 +404,21 @@ def bench(ctx, tests, compare, verbose, commits):\n         cmd = [\n             'asv', 'run', '--dry-run', '--show-stderr', '--python=same'\n         ] + bench_args\n-\n         _run_asv(cmd)\n-\n     else:\n-        # Benchmark comparison\n-\n         # Ensure that we don't have uncommited changes\n         commit_a, commit_b = [_commit_to_sha(c) for c in commits]\n \n-        if commit_b == 'HEAD':\n-            if _dirty_git_working_dir():\n-                click.secho(\n-                    \"WARNING: you have uncommitted changes --- \"\n-                    \"these will NOT be benchmarked!\",\n-                    fg=\"red\"\n-                )\n+        if commit_b == 'HEAD' and _dirty_git_working_dir():\n+            click.secho(\n+                \"WARNING: you have uncommitted changes --- \"\n+                \"these will NOT be benchmarked!\",\n+                fg=\"red\"\n+            )\n \n         cmd_compare = [\n             'asv', 'continuous', '--factor', '1.05',\n         ] + bench_args + [commit_a, commit_b]\n-\n         _run_asv(cmd_compare)\n \n \ndiff --git a/benchmarks/benchmarks/bench_core.py b/benchmarks/benchmarks/bench_core.py\nindex fe1cd37b6fd..ba51a194a8d 100644\n--- a/benchmarks/benchmarks/bench_core.py\n+++ b/benchmarks/benchmarks/bench_core.py\n@@ -217,19 +217,13 @@ def time_indices(self):\n \n \n class StatsMethods(Benchmark):\n-    # Not testing, but in array_api (redundant)\n-    # 8, 16, 32 bit variants, and 128 complexes\n-    params = [['int64', 'uint64', 'float64', 'intp',\n-               'complex64', 'bool', 'float', 'int',\n-               'complex', 'complex256'],\n-              [100**n for n in range(0, 2)]]\n+    params = [['int64', 'uint64', 'float32', 'float64',\n+               'complex64', 'bool_'],\n+              [100, 10000]]\n     param_names = ['dtype', 'size']\n \n     def setup(self, dtype, size):\n-        try:\n-            self.data = np.ones(size, dtype=getattr(np, dtype))\n-        except AttributeError:  # builtins throw AttributeError after 1.20\n-            self.data = np.ones(size, dtype=dtype)\n+        self.data = np.ones(size, dtype=dtype)\n         if dtype.startswith('complex'):\n             self.data = np.random.randn(size) + 1j * np.random.randn(size)\n \ndiff --git a/benchmarks/benchmarks/bench_creation.py b/benchmarks/benchmarks/bench_creation.py\nindex 3a577df7a1f..76d871e2d41 100644\n--- a/benchmarks/benchmarks/bench_creation.py\n+++ b/benchmarks/benchmarks/bench_creation.py\n@@ -1,4 +1,4 @@\n-from .common import Benchmark, TYPES1\n+from .common import Benchmark, TYPES1, get_squares_\n \n import numpy as np\n \n@@ -23,57 +23,49 @@ def time_meshgrid(self, size, ndims, ind, ndtype):\n class Create(Benchmark):\n     \"\"\" Benchmark for creation functions\n     \"\"\"\n-    # (64, 64), (128, 128), (256, 256)\n-    # , (512, 512), (1024, 1024)\n-    params = [[16, 32, 128, 256, 512,\n-               (16, 16), (32, 32)],\n-              ['C', 'F'],\n+    params = [[16, 512, (32, 32)],\n               TYPES1]\n-    param_names = ['shape', 'order', 'npdtypes']\n+    param_names = ['shape', 'npdtypes']\n     timeout = 10\n \n-    def setup(self, shape, order, npdtypes):\n+    def setup(self, shape, npdtypes):\n         values = get_squares_()\n         self.xarg = values.get(npdtypes)[0]\n \n-    def time_full(self, shape, order, npdtypes):\n-        np.full(shape, self.xarg[1], dtype=npdtypes, order=order)\n+    def time_full(self, shape, npdtypes):\n+        np.full(shape, self.xarg[1], dtype=npdtypes)\n \n-    def time_full_like(self, shape, order, npdtypes):\n-        np.full_like(self.xarg, self.xarg[0], order=order)\n+    def time_full_like(self, shape, npdtypes):\n+        np.full_like(self.xarg, self.xarg[0])\n \n-    def time_ones(self, shape, order, npdtypes):\n-        np.ones(shape, dtype=npdtypes, order=order)\n+    def time_ones(self, shape, npdtypes):\n+        np.ones(shape, dtype=npdtypes)\n \n-    def time_ones_like(self, shape, order, npdtypes):\n-        np.ones_like(self.xarg, order=order)\n+    def time_ones_like(self, shape, npdtypes):\n+        np.ones_like(self.xarg)\n \n-    def time_zeros(self, shape, order, npdtypes):\n-        np.zeros(shape, dtype=npdtypes, order=order)\n+    def time_zeros(self, shape, npdtypes):\n+        np.zeros(shape, dtype=npdtypes)\n \n-    def time_zeros_like(self, shape, order, npdtypes):\n-        np.zeros_like(self.xarg, order=order)\n+    def time_zeros_like(self, shape, npdtypes):\n+        np.zeros_like(self.xarg)\n \n-    def time_empty(self, shape, order, npdtypes):\n-        np.empty(shape, dtype=npdtypes, order=order)\n+    def time_empty(self, shape, npdtypes):\n+        np.empty(shape, dtype=npdtypes)\n \n-    def time_empty_like(self, shape, order, npdtypes):\n-        np.empty_like(self.xarg, order=order)\n+    def time_empty_like(self, shape, npdtypes):\n+        np.empty_like(self.xarg)\n \n \n class UfuncsFromDLP(Benchmark):\n     \"\"\" Benchmark for creation functions\n     \"\"\"\n-    params = [[16, 32, (16, 16),\n-               (32, 32), (64, 64)],\n+    params = [[16, 32, (16, 16), (64, 64)],\n               TYPES1]\n     param_names = ['shape', 'npdtypes']\n     timeout = 10\n \n     def setup(self, shape, npdtypes):\n-        if npdtypes in ['longdouble', 'clongdouble']:\n-            raise NotImplementedError(\n-                'Only IEEE dtypes are supported')\n         values = get_squares_()\n         self.xarg = values.get(npdtypes)[0]\n \ndiff --git a/benchmarks/benchmarks/bench_itemselection.py b/benchmarks/benchmarks/bench_itemselection.py\nindex 46a39372ccc..c6c74da569c 100644\n--- a/benchmarks/benchmarks/bench_itemselection.py\n+++ b/benchmarks/benchmarks/bench_itemselection.py\n@@ -5,7 +5,7 @@\n \n class Take(Benchmark):\n     params = [\n-        [(1000, 1), (1000, 2), (2, 1000, 1), (1000, 3)],\n+        [(1000, 1), (2, 1000, 1), (1000, 3)],\n         [\"raise\", \"wrap\", \"clip\"],\n         TYPES1 + [\"O\", \"i,O\"]]\n     param_names = [\"shape\", \"mode\", \"dtype\"]\ndiff --git a/benchmarks/benchmarks/bench_linalg.py b/benchmarks/benchmarks/bench_linalg.py\nindex c3e73db3dc1..30773572370 100644\n--- a/benchmarks/benchmarks/bench_linalg.py\n+++ b/benchmarks/benchmarks/bench_linalg.py\n@@ -72,37 +72,39 @@ def time_tensordot_a_b_axes_1_0_0_1(self):\n \n \n class Linalg(Benchmark):\n-    params = [['svd', 'pinv', 'det', 'norm'],\n-              TYPES1]\n-    param_names = ['op', 'type']\n+    params = set(TYPES1) - set(['float16'])\n+    param_names = ['dtype']\n \n-    def setup(self, op, typename):\n+    def setup(self, typename):\n         np.seterr(all='ignore')\n+        self.a = get_squares_()[typename]\n+\n+    def time_svd(self, typename):\n+        np.linalg.svd(self.a)\n+\n+    def time_pinv(self, typename):\n+        np.linalg.pinv(self.a)\n \n-        self.func = getattr(np.linalg, op)\n+    def time_det(self, typename):\n+        np.linalg.det(self.a)\n \n-        if op == 'cholesky':\n-            # we need a positive definite\n-            self.a = np.dot(get_squares_()[typename],\n-                            get_squares_()[typename].T)\n-        else:\n-            self.a = get_squares_()[typename]\n \n-        # check that dtype is supported at all\n-        try:\n-            self.func(self.a[:2, :2])\n-        except TypeError as e:\n-            raise NotImplementedError() from e\n+class LinalgNorm(Benchmark):\n+    params = TYPES1\n+    param_names = ['dtype']\n+\n+    def setup(self, typename):\n+        self.a = get_squares_()[typename]\n \n-    def time_op(self, op, typename):\n-        self.func(self.a)\n+    def time_norm(self, typename):\n+        np.linalg.norm(self.a)\n \n \n class LinalgSmallArrays(Benchmark):\n     \"\"\" Test overhead of linalg methods for small arrays \"\"\"\n     def setup(self):\n         self.array_5 = np.arange(5.)\n-        self.array_5_5 = np.reshape(np.arange(25.), (5., 5.))\n+        self.array_5_5 = np.reshape(np.arange(25.), (5, 5))\n \n     def time_norm_small_array(self):\n         np.linalg.norm(self.array_5)\ndiff --git a/benchmarks/benchmarks/bench_ma.py b/benchmarks/benchmarks/bench_ma.py\nindex 49ccf92fefc..26c977c9748 100644\n--- a/benchmarks/benchmarks/bench_ma.py\n+++ b/benchmarks/benchmarks/bench_ma.py\n@@ -128,10 +128,10 @@ class MAFunctions1v(Benchmark):\n               ['small', 'big']]\n \n     def setup(self, mtype, func, msize):\n-        xs = np.random.uniform(-1, 1, 6).reshape(2, 3)\n+        xs = 2.0 + np.random.uniform(-1, 1, 6).reshape(2, 3)\n         m1 = [[True, False, False], [False, False, True]]\n-        xl = np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n-        maskx = xl > 0.8\n+        xl = 2.0 + np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n+        maskx = xl > 2.8\n         self.nmxs = np.ma.array(xs, mask=m1)\n         self.nmxl = np.ma.array(xl, mask=maskx)\n \n@@ -173,17 +173,17 @@ class MAFunctions2v(Benchmark):\n \n     def setup(self, mtype, func, msize):\n         # Small arrays\n-        xs = np.random.uniform(-1, 1, 6).reshape(2, 3)\n-        ys = np.random.uniform(-1, 1, 6).reshape(2, 3)\n+        xs = 2.0 + np.random.uniform(-1, 1, 6).reshape(2, 3)\n+        ys = 2.0 + np.random.uniform(-1, 1, 6).reshape(2, 3)\n         m1 = [[True, False, False], [False, False, True]]\n         m2 = [[True, False, True], [False, False, True]]\n         self.nmxs = np.ma.array(xs, mask=m1)\n         self.nmys = np.ma.array(ys, mask=m2)\n         # Big arrays\n-        xl = np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n-        yl = np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n-        maskx = xl > 0.8\n-        masky = yl < -0.8\n+        xl = 2.0 + np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n+        yl = 2.0 + np.random.uniform(-1, 1, 100*100).reshape(100, 100)\n+        maskx = xl > 2.8\n+        masky = yl < 1.8\n         self.nmxl = np.ma.array(xl, mask=maskx)\n         self.nmyl = np.ma.array(yl, mask=masky)\n \ndiff --git a/benchmarks/benchmarks/bench_manipulate.py b/benchmarks/benchmarks/bench_manipulate.py\nindex 0a312479cd0..e8d696b1135 100644\n--- a/benchmarks/benchmarks/bench_manipulate.py\n+++ b/benchmarks/benchmarks/bench_manipulate.py\n@@ -4,9 +4,7 @@\n from collections import deque\n \n class BroadcastArrays(Benchmark):\n-    params = [[(16, 32), (32, 64),\n-               (64, 128), (128, 256),\n-               (256, 512), (512, 1024)],\n+    params = [[(16, 32), (128, 256), (512, 1024)],\n               TYPES1]\n     param_names = ['shape', 'ndtype']\n     timeout = 10\n@@ -22,7 +20,7 @@ def time_broadcast_arrays(self, shape, ndtype):\n \n \n class BroadcastArraysTo(Benchmark):\n-    params = [[16, 32, 64, 128, 256, 512],\n+    params = [[16, 64, 512],\n               TYPES1]\n     param_names = ['size', 'ndtype']\n     timeout = 10\n@@ -39,9 +37,8 @@ def time_broadcast_to(self, size, ndtype):\n \n \n class ConcatenateStackArrays(Benchmark):\n-    # (64, 128), (128, 256), (256, 512)\n     params = [[(16, 32), (32, 64)],\n-              [2, 3, 4, 5],\n+              [2, 5],\n               TYPES1]\n     param_names = ['shape', 'narrays', 'ndtype']\n     timeout = 10\ndiff --git a/benchmarks/benchmarks/bench_reduce.py b/benchmarks/benchmarks/bench_reduce.py\nindex 040b5ca73ce..53016f238b4 100644\n--- a/benchmarks/benchmarks/bench_reduce.py\n+++ b/benchmarks/benchmarks/bench_reduce.py\n@@ -46,18 +46,11 @@ def time_any_slow(self):\n \n \n class StatsReductions(Benchmark):\n-    # Not testing, but in array_api (redundant)\n-    # 8, 16, 32 bit variants, and 128 complexes\n-    params = ['int64', 'uint64', 'float64', 'intp',\n-               'complex64', 'bool', 'float', 'int',\n-               'complex', 'complex256'],\n+    params = ['int64', 'uint64', 'float32', 'float64', 'complex64', 'bool_'],\n     param_names = ['dtype']\n \n     def setup(self, dtype):\n-        try:\n-            self.data = np.ones(200, dtype=getattr(np, dtype))\n-        except AttributeError:  # builtins throw AttributeError after 1.20\n-            self.data = np.ones(200, dtype=dtype)\n+        self.data = np.ones(200, dtype=dtype)\n         if dtype.startswith('complex'):\n             self.data = self.data * self.data.T*1j\n \ndiff --git a/benchmarks/benchmarks/bench_shape_base.py b/benchmarks/benchmarks/bench_shape_base.py\nindex 7d7195ed818..72c2a6132e4 100644\n--- a/benchmarks/benchmarks/bench_shape_base.py\n+++ b/benchmarks/benchmarks/bench_shape_base.py\n@@ -68,7 +68,7 @@ def time_no_lists(self, n):\n \n \n class Block2D(Benchmark):\n-    params = [[(16, 16), (32, 32), (64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)],\n+    params = [[(16, 16), (64, 64), (256, 256), (1024, 1024)],\n               ['uint8', 'uint16', 'uint32', 'uint64'],\n               [(2, 2), (4, 4)]]\n     param_names = ['shape', 'dtype', 'n_chunks']\ndiff --git a/benchmarks/benchmarks/bench_ufunc.py b/benchmarks/benchmarks/bench_ufunc.py\nindex 8b18663ff92..f3a600a3279 100644\n--- a/benchmarks/benchmarks/bench_ufunc.py\n+++ b/benchmarks/benchmarks/bench_ufunc.py\n@@ -135,47 +135,98 @@ def time_ndarray_meth(self, methname, npdtypes):\n         getattr(operator, methname)(*[self.vals, 2])\n \n \n-class Methods0D(Benchmark):\n+class Methods0DBoolComplex(Benchmark):\n     \"\"\"Zero dimension array methods\n     \"\"\"\n-    params = [['__bool__', '__complex__', '__invert__',\n-               '__float__', '__int__'], TYPES1]\n+    params = [['__bool__', '__complex__'],\n+              TYPES1]\n+    param_names = ['methods', 'npdtypes']\n+    timeout = 10\n+\n+    def setup(self, methname, npdtypes):\n+        self.xarg = np.array(3, dtype=npdtypes)\n+\n+    def time_ndarray__0d__(self, methname, npdtypes):\n+        meth = getattr(self.xarg, methname)\n+        meth()\n+\n+\n+class Methods0DFloatInt(Benchmark):\n+    \"\"\"Zero dimension array methods\n+    \"\"\"\n+    params = [['__int__', '__float__'],\n+              [dt for dt in TYPES1 if not dt.startswith('complex')]]\n     param_names = ['methods', 'npdtypes']\n     timeout = 10\n \n     def setup(self, methname, npdtypes):\n         self.xarg = np.array(3, dtype=npdtypes)\n-        if (npdtypes.startswith('complex') and\n-           methname in ['__float__', '__int__']) or \\\n-           (npdtypes.startswith('int') and methname == '__invert__'):\n-            # Skip\n-            raise NotImplementedError\n \n     def time_ndarray__0d__(self, methname, npdtypes):\n         meth = getattr(self.xarg, methname)\n         meth()\n \n \n+class Methods0DInvert(Benchmark):\n+    \"\"\"Zero dimension array methods\n+    \"\"\"\n+    params = ['int16', 'int32', 'int64']\n+    param_names = ['npdtypes']\n+    timeout = 10\n+\n+    def setup(self, npdtypes):\n+        self.xarg = np.array(3, dtype=npdtypes)\n+\n+    def time_ndarray__0d__(self, npdtypes):\n+        self.xarg.__invert__()\n+\n+\n class MethodsV1(Benchmark):\n     \"\"\" Benchmark for the methods which take an argument\n     \"\"\"\n-    params = [['__and__', '__add__', '__eq__', '__floordiv__', '__ge__',\n-               '__gt__', '__le__', '__lt__', '__matmul__',\n-               '__mod__', '__mul__', '__ne__', '__or__',\n-               '__pow__', '__sub__', '__truediv__', '__xor__'],\n+    params = [['__add__', '__eq__', '__ge__', '__gt__', '__le__',\n+               '__lt__', '__matmul__', '__mul__', '__ne__',\n+               '__pow__', '__sub__', '__truediv__'],\n               TYPES1]\n     param_names = ['methods', 'npdtypes']\n     timeout = 10\n \n     def setup(self, methname, npdtypes):\n-        if (\n-            npdtypes.startswith(\"complex\")\n-                and methname in [\"__floordiv__\", \"__mod__\"]\n-        ) or (\n-            not npdtypes.startswith(\"int\")\n-            and methname in [\"__and__\", \"__or__\", \"__xor__\"]\n-        ):\n-            raise NotImplementedError  # skip\n+        values = get_squares_().get(npdtypes)\n+        self.xargs = [values[0], values[1]]\n+        if np.issubdtype(npdtypes, np.inexact):\n+            # avoid overflow in __pow__/__matmul__ for low-precision dtypes\n+            self.xargs[1] *= 0.01\n+\n+    def time_ndarray_meth(self, methname, npdtypes):\n+        getattr(operator, methname)(*self.xargs)\n+\n+\n+class MethodsV1IntOnly(Benchmark):\n+    \"\"\" Benchmark for the methods which take an argument\n+    \"\"\"\n+    params = [['__and__', '__or__', '__xor__'],\n+              ['int16', 'int32', 'int64']]\n+    param_names = ['methods', 'npdtypes']\n+    timeout = 10\n+\n+    def setup(self, methname, npdtypes):\n+        values = get_squares_().get(npdtypes)\n+        self.xargs = [values[0], values[1]]\n+\n+    def time_ndarray_meth(self, methname, npdtypes):\n+        getattr(operator, methname)(*self.xargs)\n+\n+\n+class MethodsV1NoComplex(Benchmark):\n+    \"\"\" Benchmark for the methods which take an argument\n+    \"\"\"\n+    params = [['__floordiv__', '__mod__'],\n+              [dt for dt in TYPES1 if not dt.startswith('complex')]]\n+    param_names = ['methods', 'npdtypes']\n+    timeout = 10\n+\n+    def setup(self, methname, npdtypes):\n         values = get_squares_().get(npdtypes)\n         self.xargs = [values[0], values[1]]\n \n@@ -391,15 +442,11 @@ def time_less_than_scalar2(self, dtype):\n \n \n class CustomScalarFloorDivideInt(Benchmark):\n-    params = (np.core.sctypes['int'] + \n-              np.core.sctypes['uint'], [8, -8, 43, -43])\n+    params = (np.core.sctypes['int'],\n+              [8, -8, 43, -43])\n     param_names = ['dtype', 'divisors']\n \n     def setup(self, dtype, divisor):\n-        if dtype in np.core.sctypes['uint'] and divisor < 0:\n-            raise NotImplementedError(\n-                    \"Skipping test for negative divisor with unsigned type\")\n-\n         iinfo = np.iinfo(dtype)\n         self.x = np.random.randint(\n                     iinfo.min, iinfo.max, size=10000, dtype=dtype)\n@@ -407,9 +454,24 @@ def setup(self, dtype, divisor):\n     def time_floor_divide_int(self, dtype, divisor):\n         self.x // divisor\n \n+\n+class CustomScalarFloorDivideUInt(Benchmark):\n+    params = (np.core.sctypes['uint'],\n+              [8, 43])\n+    param_names = ['dtype', 'divisors']\n+\n+    def setup(self, dtype, divisor):\n+        iinfo = np.iinfo(dtype)\n+        self.x = np.random.randint(\n+                    iinfo.min, iinfo.max, size=10000, dtype=dtype)\n+\n+    def time_floor_divide_uint(self, dtype, divisor):\n+        self.x // divisor\n+\n+\n class CustomArrayFloorDivideInt(Benchmark):\n-    params = (np.core.sctypes['int'] + \n-              np.core.sctypes['uint'], [100, 10000, 1000000])\n+    params = (np.core.sctypes['int'] + np.core.sctypes['uint'],\n+              [100, 10000, 1000000])\n     param_names = ['dtype', 'size']\n \n     def setup(self, dtype, size):\ndiff --git a/benchmarks/benchmarks/bench_ufunc_strides.py b/benchmarks/benchmarks/bench_ufunc_strides.py\nindex 898cc0818ac..70c076dd798 100644\n--- a/benchmarks/benchmarks/bench_ufunc_strides.py\n+++ b/benchmarks/benchmarks/bench_ufunc_strides.py\n@@ -100,7 +100,10 @@ def time_unary(self, ufunc, stride_in, stride_out, dtype):\n         ufunc(*self.ufunc_args)\n \n class UnaryFP(_AbstractUnary):\n-    params = [UFUNCS_UNARY, [1, 2, 4], [1, 2, 4], ['e', 'f', 'd']]\n+    params = [[uf for uf in UFUNCS_UNARY if uf != np.invert],\n+              [1, 4],\n+              [1, 2],\n+              ['e', 'f', 'd']]\n \n     def setup(self, ufunc, stride_in, stride_out, dtype):\n         _AbstractUnary.setup(self, ufunc, stride_in, stride_out, dtype)\n@@ -115,7 +118,7 @@ class UnaryFPSpecial(UnaryFP):\n class BinaryFP(_AbstractBinary):\n     params = [\n         [np.maximum, np.minimum, np.fmax, np.fmin, np.ldexp],\n-        [1, 2, 4], [1, 2, 4], [1, 2, 4], ['f', 'd']\n+        [1, 2], [1, 4], [1, 2, 4], ['f', 'd']\n     ]\n \n class BinaryFPSpecial(BinaryFP):\ndiff --git a/benchmarks/benchmarks/common.py b/benchmarks/benchmarks/common.py\nindex 1f36f14e121..d4c1540ff20 100644\n--- a/benchmarks/benchmarks/common.py\n+++ b/benchmarks/benchmarks/common.py\n@@ -22,10 +22,8 @@\n     'int16', 'float16',\n     'int32', 'float32',\n     'int64', 'float64',  'complex64',\n-    'longdouble', 'complex128',\n+    'complex128',\n ]\n-if 'complex256' in np.core.sctypeDict:\n-    TYPES1.append('clongdouble')\n \n DLPACK_TYPES = [\n     'int16', 'float16',\n",
        "reviews": [],
        "comments": [
            {
                "commenter": "charris",
                "body": "Thanks Ralf."
            }
        ]
    },
    {
        "repo": "numpy/numpy",
        "pr_number": 24479,
        "body": "This patch implements cross-compile builds for armhf, ppc64le, and IBMZ architectures in the CI pipeline.\r\nIn this setup, QEMU manages the Python interpreter, meson, and runtime tests, while ninja,\r\nthe toolchain, and any binutils binaries are executed natively to speed up the build.\r\nWhile it might not be highly efficient due to qemu's quirks and slower performance,\r\nit still does extend testing to include multiarray, umath, ufunc, and simd operations.\r\n    \r\n",
        "changed_files": [
            {
                "filename": ".github/workflows/linux_qemu.yml",
                "patch": "@@ -0,0 +1,147 @@\n+# Meson's Python module doesn't support crosscompiling,\n+# and python dependencies may be another potential hurdle.\n+# There might also be a need to run runtime tests during configure time.\n+#\n+# The recommended practice is to rely on Docker to provide the x86_64 crosscompile toolchain,\n+# enabling native execution via binfmt.\n+#\n+# In simpler terms, everything except the crosscompile toolchain will be emulated.\n+\n+name: Linux Qemu tests\n+\n+on:\n+  pull_request:\n+    branches:\n+      - main\n+      - maintenance/**\n+\n+defaults:\n+  run:\n+    shell: bash\n+\n+concurrency:\n+  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n+  cancel-in-progress: true\n+\n+jobs:\n+  linux_qemu:\n+    if: \"github.repository == 'numpy/numpy'\"\n+    runs-on: ubuntu-22.04\n+    continue-on-error: true\n+    strategy:\n+      matrix:\n+        BUILD_PROP:\n+          - [\n+              \"armhf\",\n+              \"arm-linux-gnueabihf\",\n+              \"arm32v7/ubuntu:22.04\",\n+              \"-Dallow-noblas=true\",\n+              # test_unary_spurious_fpexception is currently skipped\n+              # FIXME(@seiko2plus): Requires confirmation for the following issue:\n+              # The presence of an FP invalid exception caused by sqrt. Unsure if this is a qemu bug or not.\n+              \"(test_kind or test_multiarray or test_simd or test_umath or test_ufunc) and not test_unary_spurious_fpexception\"\n+          ]\n+          - [\n+              \"ppc64le\",\n+              \"powerpc64le-linux-gnu\",\n+              \"ppc64le/ubuntu:22.04\",\n+              \"-Dallow-noblas=true\",\n+              \"test_kind or test_multiarray or test_simd or test_umath or test_ufunc\",\n+          ]\n+          - [\n+              \"s390x\",\n+              \"s390x-linux-gnu\",\n+              \"s390x/ubuntu:22.04\",\n+              \"-Dallow-noblas=true\",\n+              # Skipping TestRationalFunctions.test_gcd_overflow test\n+              # because of a possible qemu bug that appears to be related to int64 overflow in absolute operation.\n+              # TODO(@seiko2plus): Confirm the bug and provide a minimal reproducer, then report it to upstream.\n+              \"(test_kind or test_multiarray or test_simd or test_umath or test_ufunc) and not test_gcd_overflow\"\n+          ]\n+          - [\n+              \"s390x - baseline(Z13)\",\n+              \"s390x-linux-gnu\",\n+              \"s390x/ubuntu:22.04\",\n+              \"-Dallow-noblas=true -Dcpu-baseline=vx\",\n+              \"(test_kind or test_multiarray or test_simd or test_umath or test_ufunc) and not test_gcd_overflow\"\n+          ]\n+    env:\n+      TOOLCHAIN_NAME: ${{ matrix.BUILD_PROP[1] }}\n+      DOCKER_CONTAINER: ${{ matrix.BUILD_PROP[2] }}\n+      MESON_OPTIONS: ${{ matrix.BUILD_PROP[3] }}\n+      RUNTIME_TEST_FILTER: ${{ matrix.BUILD_PROP[4] }}\n+      TERM: xterm-256color\n+\n+    name: \"${{ matrix.BUILD_PROP[0] }}\"\n+    steps:\n+    - uses: actions/checkout@c85c95e3d7251135ab7dc9ce3241c5835cc595a9 # v3.5.3\n+      with:\n+        submodules: recursive\n+        fetch-depth: 0\n+\n+    - name: Initialize binfmt_misc for qemu-user-static\n+      run: |\n+        docker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n+\n+    - name: Install GCC cross-compilers\n+      run: |\n+        sudo apt update\n+        sudo apt install -y ninja-build gcc-${TOOLCHAIN_NAME} g++-${TOOLCHAIN_NAME} gfortran-${TOOLCHAIN_NAME}\n+\n+    - name: Cache docker container\n+      uses: actions/cache@v3\n+      id: container-cache\n+      with:\n+        path: ~/docker_${{ matrix.BUILD_PROP[1] }}\n+        key: container-${{ runner.os }}-${{ matrix.BUILD_PROP[1] }}-${{ matrix.BUILD_PROP[2] }}-${{ hashFiles('build_requirements.txt') }}\n+\n+    - name: Creates new container\n+      if: steps.container-cache.outputs.cache-hit != 'true'\n+      run: |\n+        docker run --name the_container --interactive -v /:/host -v $(pwd):/numpy ${DOCKER_CONTAINER} /bin/bash -c \"\n+          apt update &&\n+          apt install -y cmake git python3 python-is-python3 python3-dev python3-pip &&\n+          mkdir -p /lib64 && ln -s /host/lib64/ld-* /lib64/ &&\n+          ln -s /host/lib/x86_64-linux-gnu /lib/x86_64-linux-gnu &&\n+          rm -rf /usr/${TOOLCHAIN_NAME} && ln -s /host/usr/${TOOLCHAIN_NAME} /usr/${TOOLCHAIN_NAME} &&\n+          rm -rf /usr/lib/gcc/${TOOLCHAIN_NAME} && ln -s /host/usr/lib/gcc-cross/${TOOLCHAIN_NAME} /usr/lib/gcc/${TOOLCHAIN_NAME} &&\n+          rm -f /usr/bin/gcc && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-gcc /usr/bin/gcc &&\n+          rm -f /usr/bin/g++ && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-g++ /usr/bin/g++ &&\n+          rm -f /usr/bin/gfortran && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-gfortran /usr/bin/gfortran &&\n+          rm -f /usr/bin/ar && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-ar /usr/bin/ar &&\n+          rm -f /usr/bin/as && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-as /usr/bin/as &&\n+          rm -f /usr/bin/ld && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-ld /usr/bin/ld &&\n+          rm -f /usr/bin/ld.bfd && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-ld.bfd /usr/bin/ld.bfd &&\n+          rm -f /usr/bin/ninja && ln -s /host/usr/bin/ninja /usr/bin/ninja &&\n+          git config --global --add safe.directory /numpy &&\n+          python -m pip install -r /numpy/build_requirements.txt &&\n+          python -m pip install pytest pytest-xdist hypothesis typing_extensions &&\n+          rm -f /usr/local/bin/ninja && mkdir -p /usr/local/bin && ln -s /host/usr/bin/ninja /usr/local/bin/ninja\n+        \"\n+        docker commit the_container the_container\n+        mkdir -p \"~/docker_${TOOLCHAIN_NAME}\"\n+        docker save -o \"~/docker_${TOOLCHAIN_NAME}/the_container.tar\" the_container\n+\n+    - name: Load container from cache\n+      if: steps.container-cache.outputs.cache-hit == 'true'\n+      run: docker load -i \"~/docker_${TOOLCHAIN_NAME}/the_container.tar\"\n+\n+    - name: Meson Build\n+      run: |\n+        docker run --rm -e \"TERM=xterm-256color\" -v $(pwd):/numpy -v /:/host the_container \\\n+        /bin/script -e -q -c \"/bin/bash --noprofile --norc -eo pipefail -c '\n+          cd /numpy && spin build --clean -- ${MESON_OPTIONS}\n+        '\"\n+\n+    - name: Meson Log\n+      if: always()\n+      run: 'cat build/meson-logs/meson-log.txt'\n+\n+    - name: Run Tests\n+      run: |\n+        docker run --rm -e \"TERM=xterm-256color\" -v $(pwd):/numpy -v /:/host the_container \\\n+        /bin/script -e -q -c \"/bin/bash --noprofile --norc -eo pipefail -c '\n+          export F90=/usr/bin/gfortran\n+          cd /numpy && spin test -- -k \\\"${RUNTIME_TEST_FILTER}\\\"\n+        '\"\n+"
            },
            {
                "filename": "numpy/core/tests/test_simd_module.py",
                "patch": "@@ -86,6 +86,8 @@ def test_signed_overflow(self, sfx):\n         assert lanes == [0] * nlanes\n \n     def test_truncate_f32(self):\n+        if not npyv.simd_f32:\n+            pytest.skip(\"F32 isn't support by the SIMD extension\")\n         f32 = npyv.setall_f32(0.1)[0]\n         assert f32 != 0.1\n         assert round(f32, 1) == 0.1"
            }
        ],
        "diff": "diff --git a/.github/workflows/linux_qemu.yml b/.github/workflows/linux_qemu.yml\nnew file mode 100644\nindex 00000000000..6d560e0b0f4\n--- /dev/null\n+++ b/.github/workflows/linux_qemu.yml\n@@ -0,0 +1,147 @@\n+# Meson's Python module doesn't support crosscompiling,\n+# and python dependencies may be another potential hurdle.\n+# There might also be a need to run runtime tests during configure time.\n+#\n+# The recommended practice is to rely on Docker to provide the x86_64 crosscompile toolchain,\n+# enabling native execution via binfmt.\n+#\n+# In simpler terms, everything except the crosscompile toolchain will be emulated.\n+\n+name: Linux Qemu tests\n+\n+on:\n+  pull_request:\n+    branches:\n+      - main\n+      - maintenance/**\n+\n+defaults:\n+  run:\n+    shell: bash\n+\n+concurrency:\n+  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n+  cancel-in-progress: true\n+\n+jobs:\n+  linux_qemu:\n+    if: \"github.repository == 'numpy/numpy'\"\n+    runs-on: ubuntu-22.04\n+    continue-on-error: true\n+    strategy:\n+      matrix:\n+        BUILD_PROP:\n+          - [\n+              \"armhf\",\n+              \"arm-linux-gnueabihf\",\n+              \"arm32v7/ubuntu:22.04\",\n+              \"-Dallow-noblas=true\",\n+              # test_unary_spurious_fpexception is currently skipped\n+              # FIXME(@seiko2plus): Requires confirmation for the following issue:\n+              # The presence of an FP invalid exception caused by sqrt. Unsure if this is a qemu bug or not.\n+              \"(test_kind or test_multiarray or test_simd or test_umath or test_ufunc) and not test_unary_spurious_fpexception\"\n+          ]\n+          - [\n+              \"ppc64le\",\n+              \"powerpc64le-linux-gnu\",\n+              \"ppc64le/ubuntu:22.04\",\n+              \"-Dallow-noblas=true\",\n+              \"test_kind or test_multiarray or test_simd or test_umath or test_ufunc\",\n+          ]\n+          - [\n+              \"s390x\",\n+              \"s390x-linux-gnu\",\n+              \"s390x/ubuntu:22.04\",\n+              \"-Dallow-noblas=true\",\n+              # Skipping TestRationalFunctions.test_gcd_overflow test\n+              # because of a possible qemu bug that appears to be related to int64 overflow in absolute operation.\n+              # TODO(@seiko2plus): Confirm the bug and provide a minimal reproducer, then report it to upstream.\n+              \"(test_kind or test_multiarray or test_simd or test_umath or test_ufunc) and not test_gcd_overflow\"\n+          ]\n+          - [\n+              \"s390x - baseline(Z13)\",\n+              \"s390x-linux-gnu\",\n+              \"s390x/ubuntu:22.04\",\n+              \"-Dallow-noblas=true -Dcpu-baseline=vx\",\n+              \"(test_kind or test_multiarray or test_simd or test_umath or test_ufunc) and not test_gcd_overflow\"\n+          ]\n+    env:\n+      TOOLCHAIN_NAME: ${{ matrix.BUILD_PROP[1] }}\n+      DOCKER_CONTAINER: ${{ matrix.BUILD_PROP[2] }}\n+      MESON_OPTIONS: ${{ matrix.BUILD_PROP[3] }}\n+      RUNTIME_TEST_FILTER: ${{ matrix.BUILD_PROP[4] }}\n+      TERM: xterm-256color\n+\n+    name: \"${{ matrix.BUILD_PROP[0] }}\"\n+    steps:\n+    - uses: actions/checkout@c85c95e3d7251135ab7dc9ce3241c5835cc595a9 # v3.5.3\n+      with:\n+        submodules: recursive\n+        fetch-depth: 0\n+\n+    - name: Initialize binfmt_misc for qemu-user-static\n+      run: |\n+        docker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n+\n+    - name: Install GCC cross-compilers\n+      run: |\n+        sudo apt update\n+        sudo apt install -y ninja-build gcc-${TOOLCHAIN_NAME} g++-${TOOLCHAIN_NAME} gfortran-${TOOLCHAIN_NAME}\n+\n+    - name: Cache docker container\n+      uses: actions/cache@v3\n+      id: container-cache\n+      with:\n+        path: ~/docker_${{ matrix.BUILD_PROP[1] }}\n+        key: container-${{ runner.os }}-${{ matrix.BUILD_PROP[1] }}-${{ matrix.BUILD_PROP[2] }}-${{ hashFiles('build_requirements.txt') }}\n+\n+    - name: Creates new container\n+      if: steps.container-cache.outputs.cache-hit != 'true'\n+      run: |\n+        docker run --name the_container --interactive -v /:/host -v $(pwd):/numpy ${DOCKER_CONTAINER} /bin/bash -c \"\n+          apt update &&\n+          apt install -y cmake git python3 python-is-python3 python3-dev python3-pip &&\n+          mkdir -p /lib64 && ln -s /host/lib64/ld-* /lib64/ &&\n+          ln -s /host/lib/x86_64-linux-gnu /lib/x86_64-linux-gnu &&\n+          rm -rf /usr/${TOOLCHAIN_NAME} && ln -s /host/usr/${TOOLCHAIN_NAME} /usr/${TOOLCHAIN_NAME} &&\n+          rm -rf /usr/lib/gcc/${TOOLCHAIN_NAME} && ln -s /host/usr/lib/gcc-cross/${TOOLCHAIN_NAME} /usr/lib/gcc/${TOOLCHAIN_NAME} &&\n+          rm -f /usr/bin/gcc && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-gcc /usr/bin/gcc &&\n+          rm -f /usr/bin/g++ && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-g++ /usr/bin/g++ &&\n+          rm -f /usr/bin/gfortran && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-gfortran /usr/bin/gfortran &&\n+          rm -f /usr/bin/ar && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-ar /usr/bin/ar &&\n+          rm -f /usr/bin/as && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-as /usr/bin/as &&\n+          rm -f /usr/bin/ld && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-ld /usr/bin/ld &&\n+          rm -f /usr/bin/ld.bfd && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-ld.bfd /usr/bin/ld.bfd &&\n+          rm -f /usr/bin/ninja && ln -s /host/usr/bin/ninja /usr/bin/ninja &&\n+          git config --global --add safe.directory /numpy &&\n+          python -m pip install -r /numpy/build_requirements.txt &&\n+          python -m pip install pytest pytest-xdist hypothesis typing_extensions &&\n+          rm -f /usr/local/bin/ninja && mkdir -p /usr/local/bin && ln -s /host/usr/bin/ninja /usr/local/bin/ninja\n+        \"\n+        docker commit the_container the_container\n+        mkdir -p \"~/docker_${TOOLCHAIN_NAME}\"\n+        docker save -o \"~/docker_${TOOLCHAIN_NAME}/the_container.tar\" the_container\n+\n+    - name: Load container from cache\n+      if: steps.container-cache.outputs.cache-hit == 'true'\n+      run: docker load -i \"~/docker_${TOOLCHAIN_NAME}/the_container.tar\"\n+\n+    - name: Meson Build\n+      run: |\n+        docker run --rm -e \"TERM=xterm-256color\" -v $(pwd):/numpy -v /:/host the_container \\\n+        /bin/script -e -q -c \"/bin/bash --noprofile --norc -eo pipefail -c '\n+          cd /numpy && spin build --clean -- ${MESON_OPTIONS}\n+        '\"\n+\n+    - name: Meson Log\n+      if: always()\n+      run: 'cat build/meson-logs/meson-log.txt'\n+\n+    - name: Run Tests\n+      run: |\n+        docker run --rm -e \"TERM=xterm-256color\" -v $(pwd):/numpy -v /:/host the_container \\\n+        /bin/script -e -q -c \"/bin/bash --noprofile --norc -eo pipefail -c '\n+          export F90=/usr/bin/gfortran\n+          cd /numpy && spin test -- -k \\\"${RUNTIME_TEST_FILTER}\\\"\n+        '\"\n+\ndiff --git a/numpy/core/tests/test_simd_module.py b/numpy/core/tests/test_simd_module.py\nindex 44dc58dac09..4fbaa9f3008 100644\n--- a/numpy/core/tests/test_simd_module.py\n+++ b/numpy/core/tests/test_simd_module.py\n@@ -86,6 +86,8 @@ def test_signed_overflow(self, sfx):\n         assert lanes == [0] * nlanes\n \n     def test_truncate_f32(self):\n+        if not npyv.simd_f32:\n+            pytest.skip(\"F32 isn't support by the SIMD extension\")\n         f32 = npyv.setall_f32(0.1)[0]\n         assert f32 != 0.1\n         assert round(f32, 1) == 0.1\n",
        "reviews": [],
        "comments": [
            {
                "commenter": "andyfaff",
                "body": "@seiko2plus, cibuildwheel has an example CI setup that seems to cover what you're trying to do here,https://cibuildwheel.readthedocs.io/en/stable/faq/#emulation. It uses a [GH Action](https://github.com/docker/setup-qemu-action) to setup the emulation. It's probably worth investigating that path before iterating too much here. \r\n\r\nIt may be easier to iterate CI configs on your personal fork, it saves a lot of CI triggering on the main repo."
            },
            {
                "commenter": "seiko2plus",
                "body": "> cibuildwheel has an example CI setup that seems to cover what you're trying to do\r\n\r\nI couldn't find a guide for native cross-compiling. What I'm trying to do is use binaries cross-compiled on the host system, which includes the \"ninja\" tool, while building. This mixes binaries from emulated architectures with the host's x86_64 architecture via binfmt.\r\n\r\n> It may be easier to iterate CI configs on your personal fork, it saves a lot of CI triggering on the main repo.\r\n\r\nMy bad, I have moved the tests to my local machine"
            },
            {
                "commenter": "andyfaff",
                "body": ">  Meson's Python module doesn't support crosscompiling\r\n\r\nWe've built macosx_arm64 wheels for scipy on an intel build machine using cibuildwheel+meson. So I'm not sure if this statement is true.\r\n\r\nHmm. Do you mean that you have a cross compiler that builds on x86_64, but produces output for an armhf host? If so, then it's not clear why you have to use QEMU.\r\n\r\nIf you're using QEMU aren't you using emulation to run a native armhf compiler to build for an armhf host? If this is the case then why not use https://github.com/docker/setup-qemu-action to start the docker container?"
            },
            {
                "commenter": "andyfaff",
                "body": "https://github.com/scipy/scipy/pull/17580/files shows the changeset for macosx cross compilation with scipy."
            },
            {
                "commenter": "rgommers",
                "body": "macOS x86-64 to arm64 cross-compilation support is a special case, because Apple makes it extraordinarily easy. Beyond that, `cibuildwheel` has no support. Meson does, but there are still problems to resolve that are specific to the `python` module in Meson mostly (see https://github.com/mesonbuild/meson-python/issues/321#issuecomment-1532559940).\r\n\r\nI think this `binfmt` approach works for now, however we should aim to replace it with a regular Meson cross file once the Python-specific cross build issue is resolved. And then we'd like the workflow to be to build a wheel for armhf & co on x86-64 with something like `python -m build --wnx -Csetup-args=\"--cross-file=x86toarmhf.txt\"`. And then still install and run tests for that in a similar way as in this PR with `qemu-user-static`."
            },
            {
                "commenter": "rgommers",
                "body": "Also: it'd be great to get this to work, so we can retire Travis CI usage. Thanks for working on it @seiko2plus."
            },
            {
                "commenter": "seiko2plus",
                "body": "@andyfaff, Congratulation, welcome to the team!\r\n\r\n> Hmm. Do you mean that you have a cross compiler that builds on x86_64, but produces output for an armhf host? If so, then it's not clear why you have to use QEMU.\r\n\r\nQEMU is used to execute the python interpreter including meson and running the tests, while ninja, compile, link and any binutils calls are executed natively.\r\n\r\n> If you're using QEMU aren't you using emulation to run a native armhf compiler to build for an armhf host?\r\n\r\nThe current setup is hybrid; the host must share x86_64 binaries with the container. Various architecture binaries can coexist within a single container, and the binfmt hook primarily channels exotic binaries to QEMU while bypassing native calls.\r\n\r\n> If this is the case then why not use https://github.com/docker/setup-qemu-action to start the docker container?\r\n\r\nIsn't equivalent to the following or there's something I'm messing :\r\n```Bash\r\ndocker run --rm --privileged multiarch/qemu-user-static --reset -p yes\r\n```\r\n\r\n> I think this binfmt approach works for now, however we should aim to replace it with a regular Meson cross file once the Python-specific cross build issue is resolved.\r\n\r\n\"Hybrid\" binfmt approach seems more reliable, executing meson over qemu isn't a big deal as long as the compile calls are executed natively.\r\n"
            },
            {
                "commenter": "rgommers",
                "body": "> \"Hybrid\" binfmt approach seems more reliable, executing meson over qemu isn't a big deal as long as the compile calls are executed natively.\r\n\r\nBoth approaches should work, and agreed that running Meson under QEMU should be fine. But the build part of the CI jobs will be one-liners when we use regular cross files, rather than needing a ton of `rm -f /usr/bin/gcc && ln -s /host/usr/bin/${TOOLCHAIN_NAME}-gcc /usr/bin/gcc &&` type lines. So maintainability improves quite a bit.\r\n\r\nAnyway, that's a concern for later."
            },
            {
                "commenter": "seiko2plus",
                "body": "> But the build part of the CI jobs will be one-liners when we use regular cross files, rather than needing a ton of rm -f /usr/bin/gcc && ln -s /host/usr\r\n\r\nAgreed, my main concern right now is find a fast solution to verify powerpc64 builds since Travis CI Power machines seems to not work any more."
            },
            {
                "commenter": "andyfaff",
                "body": "Thank you for the explanation of what you're doing, it's very enlightening."
            },
            {
                "commenter": "seiko2plus",
                "body": "All green, the runtime tests only covers \"test_kind, test_multiarray, test_simd, test_umath and test_ufunc\" which is good enough I suppose. The full test takes up to 25m without container cache involved, not sure how to test the cache yet. "
            },
            {
                "commenter": "seiko2plus",
                "body": "I made a manual re-run for armhf with debug enabled but still missed the cache:\r\n```Bash\r\n ##[debug]Resolved Keys:\r\n##[debug][\"container-Linux-arm-linux-gnueabihf-arm32v7/ubuntu:22.04-8bc1d1beea3ee08d8a0df5594ff514fb36a313213aaada747cc83e9ba243a8e6\"]\r\n##[debug]Checking zstd --quiet --version\r\n##[debug]1.5.5\r\n##[debug]zstd version: 1.5.5\r\n##[debug]Resource Url: https://acghubeus2.actions.githubusercontent.com/sH05vHzoTO8FskJ61ZFM2de2fOtiqhFE8SSrZeKfiH7OXqclo7/_apis/artifactcache/cache?keys=container-Linux-arm-linux-gnueabihf-arm32v7%2Fubuntu%3A22.04-8bc1d1beea3ee08d8a0df5594ff514fb36a313213aaada747cc83e9ba243a8e6&version=82cace457337bec689d5d2c52d6ee729c5a67a454f53c4372afbe7269f7d18f6\r\n##[debug]Resource Url: https://acghubeus2.actions.githubusercontent.com/sH05vHzoTO8FskJ61ZFM2de2fOtiqhFE8SSrZeKfiH7OXqclo7/_apis/artifactcache/caches?key=container-Linux-arm-linux-gnueabihf-arm32v7%2Fubuntu%3A22.04-8bc1d1beea3ee08d8a0df5594ff514fb36a313213aaada747cc83e9ba243a8e6\r\n##[debug]Failed to delete archive: Error: ENOENT: no such file or directory, unlink ''\r\nCache not found for input keys: container-Linux-arm-linux-gnueabihf-arm32v7/ubuntu:22.04-8bc1d1beea3ee08d8a0df5594ff514fb36a313213aaada747cc83e9ba243a8e6\r\n##[debug]Node Action run completed with exit code 0\r\n##[debug]Save intra-action state CACHE_KEY = container-Linux-arm-linux-gnueabihf-arm32v7/ubuntu:22.04-8bc1d1beea3ee08d8a0df5594ff514fb36a313213aaada747cc83e9ba243a8e6\r\n##[debug]Finishing: Cache docker container\r\n```"
            },
            {
                "commenter": "rgommers",
                "body": "> I made a manual re-run for armhf with debug enabled but still missed the cache:\r\n\r\nThe _Post Cache docker container_ step contains:\r\n```\r\nWarning: Path Validation Error: Path(s) specified in the action for caching do(es) not exist, hence no cache is being saved.\r\n```\r\n\r\nThe path it's looking for is:\r\n```\r\npath: /docker_s390x-linux-gnu\r\n```\r\nand it's being saved to:\r\n```\r\n  mkdir -p \"~/docker_${TOOLCHAIN_NAME}\"\r\n  docker save -o \"~/docker_${TOOLCHAIN_NAME}/the_container.tar\" the_container\r\n```\r\nwith `TOOLCHAIN_NAME: s390x-linux-gnu`. So it mostly looks right, but is the `~/docker` vs `/docker` correct here?"
            },
            {
                "commenter": "seiko2plus",
                "body": "@rgommers, oh nice catch you made my day!"
            },
            {
                "commenter": "seiko2plus",
                "body": "Another thing we have a limit of 10GB cache currently about 8.5GB is been used, is there away to increase it?"
            },
            {
                "commenter": "rgommers",
                "body": "No, it's 10 GB per repository (https://github.blog/changelog/2021-11-23-github-actions-cache-size-is-now-increased-to-10gb-per-repository/) and you can't even pay to increase it. \r\n\r\nHow much more do we need with these new jobs? Or is it 8.5 GB including these jobs, and you're worried about cache evictions on re-runs?"
            },
            {
                "commenter": "seiko2plus",
                "body": "> How much more do we need with these new jobs? \r\n\r\nCurrently three containers one for each architecture, all of them may exceed 1.5GB and we may need to adds support for risc-v, and ppc64(big-endian).\r\n\r\n>  Or is it 8.5 GB including these jobs,\r\n\r\nwithout including these jobs.\r\n\r\n> you're worried about cache evictions on re-runs?\r\n\r\nyes, saving about 8 minutes on each run may allow us to extend the current runtime tests to cover more unites.\r\n\r\n\r\n"
            },
            {
                "commenter": "andyfaff",
                "body": "Can we cache in a third party location, akin to nightly wheels? E g. Dockerhub. An account for OSS projects can have up to 200 image pulls every six hours."
            },
            {
                "commenter": "seiko2plus",
                "body": "> Can we cache in a third party location, akin to nightly wheels?\r\n\r\nYes, we can since the cache hit can be detected to enable/disable steps.\r\n\r\n> E g. Dockerhub. An account for OSS projects can have up to 200 image pulls every six hours.\r\n\r\nLGTM, lets just see first how github manages the cache storage once its exceed 10GB."
            },
            {
                "commenter": "rgommers",
                "body": "> Can we cache in a third party location, akin to nightly wheels? E g. Dockerhub. An account for OSS projects can have up to 200 image pulls every six hours.\r\n\r\nIt's possible, but caching outside of GitHub is way slower. We used Docker Hub for the Gitpod images, which were also ~1.5GB and those took a couple of minutes to transfer and load. Plus we got rid of a lot of images after Docker Hub made changes to their free team plan. So I'm not very eager to look at it now.\r\n\r\n> LGTM, lets just see first how github manages the cache storage once its exceed 10GB.\r\n\r\n+1, we can reassess after merging this."
            },
            {
                "commenter": "seiko2plus",
                "body": "I made a re-run but it doesn't work, and it seems the cache will never hit, so after checking the debugging URLs, I just realized that its seem to be only allowed through the default branch maybe due to security concerns:\r\n```Json\r\n{\"$id\":\"1\",\"innerException\":null,\"message\":\"The user 'System:PublicAccess;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' is not authorized to access this resource.\",\"typeName\":\"Microsoft.TeamFoundation.Framework.Server.UnauthorizedRequestException, Microsoft.TeamFoundation.Framework.Server\",\"typeKey\":\"UnauthorizedRequestException\",\"errorCode\":0,\"eventId\":3000}\r\n```\r\n\r\n> The user 'System:PublicAccess;aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa' is not authorized to access this resource\r\n\r\nSo it seem there's no way to handle it through github."
            },
            {
                "commenter": "seiko2plus",
                "body": "According to the github doc https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows#restrictions-for-accessing-a-cache, there's still chance to works after the merge in order to gain the write access.\r\n"
            },
            {
                "commenter": "mattip",
                "body": "Let's put this in and iterate on the caching setup as needed."
            },
            {
                "commenter": "mattip",
                "body": "Thanks @seiko2plus "
            },
            {
                "commenter": "rgommers",
                "body": "Awesome! @seiko2plus can we delete `.travis.yml` now, or do you still need it for something?"
            },
            {
                "commenter": "mattip",
                "body": "[The cache page](https://github.com/numpy/numpy/actions/caches) seems to show we have only one cached image: a 390MB one named `3.1.32-linux-x64-master` that is built quite often."
            },
            {
                "commenter": "rgommers",
                "body": "That's from the Emscripten job, and it's because the `mymindstorm` action caching is broken:\r\n```\r\nRun mymindstorm/setup-emsdk@ab889da2abbcbb280f91ec4c215d3bb4f3a8f775\r\nWarning: No cached files found at path \"/home/runner/work/numpy/numpy/emsdk-cache\" - downloading and caching emsdk.\r\n```\r\n\r\nWe have nothing else that uses a cache right now, so we should be fine space-wise."
            },
            {
                "commenter": "seiko2plus",
                "body": ">  can we delete .travis.yml now, or do you still need it for something?\r\n\r\nI just left it for testing distutils, no other reason for keeping it.\r\n"
            }
        ]
    },
    {
        "repo": "numpy/numpy",
        "pr_number": 24473,
        "body": "* The docstring of `numpy.polynomial.polyutils.trimseq` stated \"This routine fails for empty sequences.\". This is incorrect, as `trimseq` works fine on empty sequences (there is in fact an if statement especially for this case). In this PR we modify the docstring and add tests to make sure the `trimseq` works fine on empty sequences.\r\n* The most common case for `trimseq` are non-empty sequences (the coefficients of polynomials are non-empty by construction) with final coefficient non-zero. We add a fast path for the case where the final coefficient is non-zero.\r\n\r\nBenchmark\r\n```\r\nfrom numpy.polynomial import Polynomial\r\nfrom numpy.polynomial.polyutils import trimseq\r\n\r\np = Polynomial([1,2,3])\r\n\r\n%timeit trimseq(p.coef)\r\n``` \r\nResults:\r\n```\r\nmain: 565 ns \u00b1 36 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\r\nPR: 224 ns \u00b1 21.1 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\r\n```\r\n<!--         ----------------------------------------------------------------\r\n                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!\r\n                ----------------------------------------------------------------\r\n\r\n*  FORMAT IT RIGHT:\r\n      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message\r\n\r\n*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:\r\n      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion\r\n\r\n*  HIT ALL THE GUIDELINES:\r\n      https://numpy.org/devdocs/dev/index.html#guidelines\r\n\r\n*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:\r\n      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed\r\n-->\r\n",
        "changed_files": [
            {
                "filename": "numpy/polynomial/polyutils.py",
                "patch": "@@ -57,8 +57,7 @@ def trimseq(seq):\n     Parameters\n     ----------\n     seq : sequence\n-        Sequence of Poly series coefficients. This routine fails for\n-        empty sequences.\n+        Sequence of Poly series coefficients.\n \n     Returns\n     -------\n@@ -72,7 +71,7 @@ def trimseq(seq):\n     Do not lose the type info if the sequence contains unknown objects.\n \n     \"\"\"\n-    if len(seq) == 0:\n+    if len(seq) == 0 or seq[-1] != 0:\n         return seq\n     else:\n         for i in range(len(seq) - 1, -1, -1):"
            },
            {
                "filename": "numpy/polynomial/tests/test_polyutils.py",
                "patch": "@@ -11,11 +11,15 @@\n class TestMisc:\n \n     def test_trimseq(self):\n-        for i in range(5):\n-            tgt = [1]\n-            res = pu.trimseq([1] + [0]*5)\n+        tgt = [1]\n+        for num_trailing_zeros in range(5):\n+            res = pu.trimseq([1] + [0] * num_trailing_zeros)\n             assert_equal(res, tgt)\n \n+    def test_trimseq_empty_input(self):\n+        for empty_seq in [[], np.array([], dtype=np.int32)]:\n+            assert_equal(pu.trimseq(empty_seq), empty_seq)\n+\n     def test_as_series(self):\n         # check exceptions\n         assert_raises(ValueError, pu.as_series, [[]])"
            }
        ],
        "diff": "diff --git a/numpy/polynomial/polyutils.py b/numpy/polynomial/polyutils.py\nindex 48291389201..83f3aeb7e5b 100644\n--- a/numpy/polynomial/polyutils.py\n+++ b/numpy/polynomial/polyutils.py\n@@ -57,8 +57,7 @@ def trimseq(seq):\n     Parameters\n     ----------\n     seq : sequence\n-        Sequence of Poly series coefficients. This routine fails for\n-        empty sequences.\n+        Sequence of Poly series coefficients.\n \n     Returns\n     -------\n@@ -72,7 +71,7 @@ def trimseq(seq):\n     Do not lose the type info if the sequence contains unknown objects.\n \n     \"\"\"\n-    if len(seq) == 0:\n+    if len(seq) == 0 or seq[-1] != 0:\n         return seq\n     else:\n         for i in range(len(seq) - 1, -1, -1):\ndiff --git a/numpy/polynomial/tests/test_polyutils.py b/numpy/polynomial/tests/test_polyutils.py\nindex cc630790da1..e5143ed5c3e 100644\n--- a/numpy/polynomial/tests/test_polyutils.py\n+++ b/numpy/polynomial/tests/test_polyutils.py\n@@ -11,11 +11,15 @@\n class TestMisc:\n \n     def test_trimseq(self):\n-        for i in range(5):\n-            tgt = [1]\n-            res = pu.trimseq([1] + [0]*5)\n+        tgt = [1]\n+        for num_trailing_zeros in range(5):\n+            res = pu.trimseq([1] + [0] * num_trailing_zeros)\n             assert_equal(res, tgt)\n \n+    def test_trimseq_empty_input(self):\n+        for empty_seq in [[], np.array([], dtype=np.int32)]:\n+            assert_equal(pu.trimseq(empty_seq), empty_seq)\n+\n     def test_as_series(self):\n         # check exceptions\n         assert_raises(ValueError, pu.as_series, [[]])\n",
        "reviews": [
            {
                "reviewer": "rossbar",
                "state": "APPROVED",
                "body": "Seems fine to me - the implementation change is not likely to have performance implications in practice, but AFAICT it doesn't hurt! +1 for aligning the docstring with the behavior.\r\n\r\nAny objections @charris ?\r\n\r\nWhile we're at it - I took the liberty of correcting a minor defect in `test_trimseq`. I suspect the intention was to test with varying numbers of trailing zeros rather than run the same test 5 times."
            }
        ],
        "comments": [
            {
                "commenter": "eendebakpt",
                "body": "> Seems fine to me - the implementation change is not likely to have performance implications in practice, but AFAICT it doesn't hurt! +1 for aligning the docstring with the behavior.\r\n> \r\n> Any objections @charris ?\r\n> \r\n> While we're at it - I took the liberty of correcting a minor defect in `test_trimseq`. I suspect the intention was to test with varying numbers of trailing zeros rather than run the same test 5 times.\r\n\r\nThanks for fixing the test in `test_trimseq`. I agree that performance gains on the polynomial operations itself are small (but they are measurable), together with several other improvements I hope to make some gains."
            },
            {
                "commenter": "charris",
                "body": "Thanks @eendebakpt . I'm not sure and empty sequence is useful, but at least the documentation is consistent :)"
            }
        ]
    }
]